# Dataset

The dataset used for this model is called PPE dataset. This dataset consists of people wearing protective gear like Hardhat, Vest, Mask and Boots. About 3570 number of images of this kind was randomly picked from the internet and was used as input data. For each input image, we have corresponding Bounding box coordinates for 4 classes, Depth image, Surface Plane image, Plane parameters and Plane mask as the ground truth.
 - The bounding box coordinates was created using Yolo annotation tool and the results were saved in a text file.
 - The Depth image was generated from the [MIDAS](https://github.com/intel-isl/MiDaS) network by running the model in evaluation mode and infering the depth output for given image.
 - The Surface Plane image, Plane parameters and Plane mask were again generated by running the pretrained [PlaneRCNN model](https://github.com/NVlabs/planercnn) in evaluation mode
Go to this link to view the [Input Images and Ground Truth](https://drive.google.com/drive/u/0/folders/1ijNY2BA2UHhNWuzu5b9WCCOz40v3gzvh)

## Preview

### Input Image

![](Images/InputImages.jpg)

### Depth Image

![](Images/Depth_Inputs.jpg)

### Plane Segmentation Image

![](Images/PlaneRCNN_Inputs.jpg)

## Data Augumentation
- The input images are resized to 448 x448, Letter box augumentation is applied.
- The Bounding Box values are normalized and resized according the resized input image.
- No augmentation are applied to the ground truth images as it would distort them from their corresponding labels.

## Data Loading

