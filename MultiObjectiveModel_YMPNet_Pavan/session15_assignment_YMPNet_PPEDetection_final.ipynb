{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"session15_assignment_YMPNet_PPEDetection_final.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"ki9ivMurR4Jr","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606669269546,"user_tz":-330,"elapsed":1138,"user":{"displayName":"Naga Pavan Kumar","photoUrl":"https://lh3.googleusercontent.com/-Z9D3lcihg5g/AAAAAAAAAAI/AAAAAAAAAJ4/SJlaj7Z_Qqk/s64/photo.jpg","userId":"05295613010131139318"}},"outputId":"a6a53e92-d3ae-49c3-b94d-5dea9a01ac83"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"4boJppRm5UaX"},"source":["# !ls /content/drive/My\\ Drive/computer_vision/capstone_project/yolo_v3/data/customdata/capstone_dataset/inputs/ppe_input_images/ | wc -l"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8891yGMYSGaU"},"source":["# !ls /content/drive/My\\ Drive/computer_vision/capstone_project/yolo_v3/data/customdata/capstone_dataset/ground_truths/ppe_gt_bbox_labels | wc -l"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"oJWPCDSv0gw3","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606669270627,"user_tz":-330,"elapsed":1178,"user":{"displayName":"Naga Pavan Kumar","photoUrl":"https://lh3.googleusercontent.com/-Z9D3lcihg5g/AAAAAAAAAAI/AAAAAAAAAJ4/SJlaj7Z_Qqk/s64/photo.jpg","userId":"05295613010131139318"}},"outputId":"9e989f9f-73d9-4565-96d7-0ad77837aea5"},"source":["import time\n","import glob\n","import torch\n","import os\n","import PIL\n","\n","from IPython.display import Image, clear_output \n","print('PyTorch %s %s' % (torch.__version__, torch.cuda.get_device_properties(0) if torch.cuda.is_available() else 'CPU'))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["PyTorch 1.7.0+cu101 _CudaDeviceProperties(name='Tesla P100-PCIE-16GB', major=6, minor=0, total_memory=16280MB, multi_processor_count=56)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"zjh9bbjKTKl3"},"source":["os.chdir(\"/content/drive/My Drive/computer_vision/capstone_project/yolo_v3/\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"p_qex_O8A9wx"},"source":["def are_files_exist(meta_data, files_location):\n","  not_found_files = []\n","  file_names = open(meta_data).readlines()\n","  for file_path in file_names:\n","    if not os.path.exists(file_path.strip()):\n","      not_found_files.append(file_path.strip())\n","  print(f'{len(not_found_files)} number of files not found')\n","  return not_found_files"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rfBM5it_Eu7B"},"source":["# are_files_exist('/content/drive/My Drive/computer_vision/capstone_project/yolo_v3/data/customdata/train.txt', '/content/drive/My Drive/computer_vision/capstone_project/yolo_v3/data/customdata/capstone_dataset/inputs/ppe_input_images')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Y7RxGL-SB-xO"},"source":["# are_files_exist('/content/drive/My Drive/computer_vision/capstone_project/yolo_v3/data/customdata/test.txt', '/content/drive/My Drive/computer_vision/capstone_project/yolo_v3/data/customdata/capstone_dataset/inputs/ppe_input_images')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fWCtlZ6WjVX_"},"source":["def write_image_shapes(image_paths_file, target_filepath):\n","  file_names = open(image_paths_file).readlines()\n","  with open(target_filepath, 'a') as file_handler:\n","    for image_path in file_names:\n","      im = PIL.Image.open(image_path.strip())\n","      img_width, img_height = [float(dim) for dim in im.size]\n","      file_handler.write(f'{img_width} {img_height}\\n')\n","  print(\"Done\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"knOEdY5xwmj_"},"source":["# len(open('./data/customdata/custom_train.txt').readlines()), len(open('./data/customdata/custom_train.shapes').readlines())"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3pcHcSeoxxjU"},"source":["# len(open('./data/customdata/custom_test.txt').readlines()), len(open('./data/customdata/custom_test.shapes').readlines())"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_YFRcnYwkoBu"},"source":["# write_image_shapes('./data/customdata/custom_train.txt', './data/customdata/custom_train.shapes')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"A4UgXxh2l669"},"source":["# write_image_shapes('./data/customdata/custom_test.txt', './data/customdata/custom_test.shapes')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"oH8vDmfVHv8-"},"source":["def get_device_type():\n","  use_cuda = torch.cuda.is_available()\n","  device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n","  return device"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"HYd66bI2HXSE"},"source":["#weights_yolo = 'weights/yolov3-spp-ultralytics.pt'\n","#weights_midas = 'weights/model-f46da743.pt'\n","#device = get_device_type()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Zj2DN4nbHVxe"},"source":["# chkpt_yolo = torch.load(weights_yolo, map_location=device)\n","# chkpt_midas = torch.load(weights_midas, map_location=device)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"CzhsHNM5HZ4s"},"source":["# chkpt_yolo.keys() # it saved as entire model"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"u-gHoBQHbLfJ"},"source":["#chkpt_midas.keys() # it saved as only weights"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3tpJBcJDmzyR"},"source":["#chkpt_yolo[\"model\"]['module_list.106.BatchNorm2d.weight'].shape"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"oQ9d1zWGsasm"},"source":["# for item in chkpt_midas.keys():\n","#   print(item)\n","#   print(chkpt_midas[item].size())"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"FKSE6KtsISBr"},"source":["# for item in chkpt_midas.keys():\n","  # print(item)\n","\n","# for item in chkpt_yolo[\"model\"].keys():\n","#   print(item)\n","#   print(chkpt_yolo[\"model\"][item].size())"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"406ITdBc9OsM"},"source":["## Training yolo branch only by freezing the midas layers on 64x64 resolution"]},{"cell_type":"code","metadata":{"id":"SIsxd4SuoxYI","colab":{"base_uri":"https://localhost:8080/"},"outputId":"16992131-1a70-4207-f537-3d68dcee51e3"},"source":["## Ignore the model summary in the below output - as it is summary on dummy input (3, 416,416) and before freezing the midas layers. But you can observe img_size attribute though as 64.\n","# Training yolo branch only by freezing the midas layers on 64x64 resolution\n","!python train.py --data data/customdata/custom.data --batch 32 --cache --cfg cfg/yolov3-custom.cfg --epochs 50 --midas_weights='weights/model-f46da743.pt' --yolo_weights='weights/last_ppe.pt' --init_train='True' --img-size=64 --midasnet_freeze='True'"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Namespace(accumulate=4, adam=False, batch_size=32, bucket='', cache_images=True, cfg='cfg/yolov3-custom.cfg', data='data/customdata/custom.data', device='', epochs=50, evolve=False, img_size=[64], init_train='True', midas_weights='weights/model-f46da743.pt', midasnet_freeze='True', multi_scale=False, name='', nosave=False, notest=False, rect=False, resume=False, single_cls=False, weights='', yolo_weights='weights/last_ppe.pt')\n","Using CUDA device0 _CudaDeviceProperties(name='Tesla V100-SXM2-16GB', total_memory=16130MB)\n","\n","2020-11-13 23:27:02.084096: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n","Run 'tensorboard --logdir=runs' to view tensorboard at http://localhost:6006/\n","cfg - cfg/yolov3-custom.cfg\n","data - data/customdata/custom.data\n","epochs - 50\n","batch_size - 32\n","accumulate - 4\n","yolo weights - weights/last_ppe.pt\n","midas weights - weights/model-f46da743.pt\n","imgsz_min- 64, imgsz_max- 64, imgsz_test- 64\n","opt.rect - False\n","train_path - data/customdata/train.txt\n","test_path - data/customdata/test.txt\n","init_train - True\n","weights - \n","midasnet_freeze - True\n","Using cache found in /root/.cache/torch/hub/facebookresearch_WSL-Images_master\n","Loaded Midas Encoder weights successfully\n","Loaded Yolo Decoder weights successfully\n","YMP Model Summary\n","----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","            Conv2d-1         [-1, 64, 208, 208]           9,408\n","       BatchNorm2d-2         [-1, 64, 208, 208]             128\n","              ReLU-3         [-1, 64, 208, 208]               0\n","         MaxPool2d-4         [-1, 64, 104, 104]               0\n","            Conv2d-5        [-1, 256, 104, 104]          16,384\n","       BatchNorm2d-6        [-1, 256, 104, 104]             512\n","              ReLU-7        [-1, 256, 104, 104]               0\n","            Conv2d-8        [-1, 256, 104, 104]          18,432\n","       BatchNorm2d-9        [-1, 256, 104, 104]             512\n","             ReLU-10        [-1, 256, 104, 104]               0\n","           Conv2d-11        [-1, 256, 104, 104]          65,536\n","      BatchNorm2d-12        [-1, 256, 104, 104]             512\n","           Conv2d-13        [-1, 256, 104, 104]          16,384\n","      BatchNorm2d-14        [-1, 256, 104, 104]             512\n","             ReLU-15        [-1, 256, 104, 104]               0\n","       Bottleneck-16        [-1, 256, 104, 104]               0\n","           Conv2d-17        [-1, 256, 104, 104]          65,536\n","      BatchNorm2d-18        [-1, 256, 104, 104]             512\n","             ReLU-19        [-1, 256, 104, 104]               0\n","           Conv2d-20        [-1, 256, 104, 104]          18,432\n","      BatchNorm2d-21        [-1, 256, 104, 104]             512\n","             ReLU-22        [-1, 256, 104, 104]               0\n","           Conv2d-23        [-1, 256, 104, 104]          65,536\n","      BatchNorm2d-24        [-1, 256, 104, 104]             512\n","             ReLU-25        [-1, 256, 104, 104]               0\n","       Bottleneck-26        [-1, 256, 104, 104]               0\n","           Conv2d-27        [-1, 256, 104, 104]          65,536\n","      BatchNorm2d-28        [-1, 256, 104, 104]             512\n","             ReLU-29        [-1, 256, 104, 104]               0\n","           Conv2d-30        [-1, 256, 104, 104]          18,432\n","      BatchNorm2d-31        [-1, 256, 104, 104]             512\n","             ReLU-32        [-1, 256, 104, 104]               0\n","           Conv2d-33        [-1, 256, 104, 104]          65,536\n","      BatchNorm2d-34        [-1, 256, 104, 104]             512\n","             ReLU-35        [-1, 256, 104, 104]               0\n","       Bottleneck-36        [-1, 256, 104, 104]               0\n","           Conv2d-37        [-1, 512, 104, 104]         131,072\n","      BatchNorm2d-38        [-1, 512, 104, 104]           1,024\n","             ReLU-39        [-1, 512, 104, 104]               0\n","           Conv2d-40          [-1, 512, 52, 52]          73,728\n","      BatchNorm2d-41          [-1, 512, 52, 52]           1,024\n","             ReLU-42          [-1, 512, 52, 52]               0\n","           Conv2d-43          [-1, 512, 52, 52]         262,144\n","      BatchNorm2d-44          [-1, 512, 52, 52]           1,024\n","           Conv2d-45          [-1, 512, 52, 52]         131,072\n","      BatchNorm2d-46          [-1, 512, 52, 52]           1,024\n","             ReLU-47          [-1, 512, 52, 52]               0\n","       Bottleneck-48          [-1, 512, 52, 52]               0\n","           Conv2d-49          [-1, 512, 52, 52]         262,144\n","      BatchNorm2d-50          [-1, 512, 52, 52]           1,024\n","             ReLU-51          [-1, 512, 52, 52]               0\n","           Conv2d-52          [-1, 512, 52, 52]          73,728\n","      BatchNorm2d-53          [-1, 512, 52, 52]           1,024\n","             ReLU-54          [-1, 512, 52, 52]               0\n","           Conv2d-55          [-1, 512, 52, 52]         262,144\n","      BatchNorm2d-56          [-1, 512, 52, 52]           1,024\n","             ReLU-57          [-1, 512, 52, 52]               0\n","       Bottleneck-58          [-1, 512, 52, 52]               0\n","           Conv2d-59          [-1, 512, 52, 52]         262,144\n","      BatchNorm2d-60          [-1, 512, 52, 52]           1,024\n","             ReLU-61          [-1, 512, 52, 52]               0\n","           Conv2d-62          [-1, 512, 52, 52]          73,728\n","      BatchNorm2d-63          [-1, 512, 52, 52]           1,024\n","             ReLU-64          [-1, 512, 52, 52]               0\n","           Conv2d-65          [-1, 512, 52, 52]         262,144\n","      BatchNorm2d-66          [-1, 512, 52, 52]           1,024\n","             ReLU-67          [-1, 512, 52, 52]               0\n","       Bottleneck-68          [-1, 512, 52, 52]               0\n","           Conv2d-69          [-1, 512, 52, 52]         262,144\n","      BatchNorm2d-70          [-1, 512, 52, 52]           1,024\n","             ReLU-71          [-1, 512, 52, 52]               0\n","           Conv2d-72          [-1, 512, 52, 52]          73,728\n","      BatchNorm2d-73          [-1, 512, 52, 52]           1,024\n","             ReLU-74          [-1, 512, 52, 52]               0\n","           Conv2d-75          [-1, 512, 52, 52]         262,144\n","      BatchNorm2d-76          [-1, 512, 52, 52]           1,024\n","             ReLU-77          [-1, 512, 52, 52]               0\n","       Bottleneck-78          [-1, 512, 52, 52]               0\n","           Conv2d-79         [-1, 1024, 52, 52]         524,288\n","      BatchNorm2d-80         [-1, 1024, 52, 52]           2,048\n","             ReLU-81         [-1, 1024, 52, 52]               0\n","           Conv2d-82         [-1, 1024, 26, 26]         294,912\n","      BatchNorm2d-83         [-1, 1024, 26, 26]           2,048\n","             ReLU-84         [-1, 1024, 26, 26]               0\n","           Conv2d-85         [-1, 1024, 26, 26]       1,048,576\n","      BatchNorm2d-86         [-1, 1024, 26, 26]           2,048\n","           Conv2d-87         [-1, 1024, 26, 26]         524,288\n","      BatchNorm2d-88         [-1, 1024, 26, 26]           2,048\n","             ReLU-89         [-1, 1024, 26, 26]               0\n","       Bottleneck-90         [-1, 1024, 26, 26]               0\n","           Conv2d-91         [-1, 1024, 26, 26]       1,048,576\n","      BatchNorm2d-92         [-1, 1024, 26, 26]           2,048\n","             ReLU-93         [-1, 1024, 26, 26]               0\n","           Conv2d-94         [-1, 1024, 26, 26]         294,912\n","      BatchNorm2d-95         [-1, 1024, 26, 26]           2,048\n","             ReLU-96         [-1, 1024, 26, 26]               0\n","           Conv2d-97         [-1, 1024, 26, 26]       1,048,576\n","      BatchNorm2d-98         [-1, 1024, 26, 26]           2,048\n","             ReLU-99         [-1, 1024, 26, 26]               0\n","      Bottleneck-100         [-1, 1024, 26, 26]               0\n","          Conv2d-101         [-1, 1024, 26, 26]       1,048,576\n","     BatchNorm2d-102         [-1, 1024, 26, 26]           2,048\n","            ReLU-103         [-1, 1024, 26, 26]               0\n","          Conv2d-104         [-1, 1024, 26, 26]         294,912\n","     BatchNorm2d-105         [-1, 1024, 26, 26]           2,048\n","            ReLU-106         [-1, 1024, 26, 26]               0\n","          Conv2d-107         [-1, 1024, 26, 26]       1,048,576\n","     BatchNorm2d-108         [-1, 1024, 26, 26]           2,048\n","            ReLU-109         [-1, 1024, 26, 26]               0\n","      Bottleneck-110         [-1, 1024, 26, 26]               0\n","          Conv2d-111         [-1, 1024, 26, 26]       1,048,576\n","     BatchNorm2d-112         [-1, 1024, 26, 26]           2,048\n","            ReLU-113         [-1, 1024, 26, 26]               0\n","          Conv2d-114         [-1, 1024, 26, 26]         294,912\n","     BatchNorm2d-115         [-1, 1024, 26, 26]           2,048\n","            ReLU-116         [-1, 1024, 26, 26]               0\n","          Conv2d-117         [-1, 1024, 26, 26]       1,048,576\n","     BatchNorm2d-118         [-1, 1024, 26, 26]           2,048\n","            ReLU-119         [-1, 1024, 26, 26]               0\n","      Bottleneck-120         [-1, 1024, 26, 26]               0\n","          Conv2d-121         [-1, 1024, 26, 26]       1,048,576\n","     BatchNorm2d-122         [-1, 1024, 26, 26]           2,048\n","            ReLU-123         [-1, 1024, 26, 26]               0\n","          Conv2d-124         [-1, 1024, 26, 26]         294,912\n","     BatchNorm2d-125         [-1, 1024, 26, 26]           2,048\n","            ReLU-126         [-1, 1024, 26, 26]               0\n","          Conv2d-127         [-1, 1024, 26, 26]       1,048,576\n","     BatchNorm2d-128         [-1, 1024, 26, 26]           2,048\n","            ReLU-129         [-1, 1024, 26, 26]               0\n","      Bottleneck-130         [-1, 1024, 26, 26]               0\n","          Conv2d-131         [-1, 1024, 26, 26]       1,048,576\n","     BatchNorm2d-132         [-1, 1024, 26, 26]           2,048\n","            ReLU-133         [-1, 1024, 26, 26]               0\n","          Conv2d-134         [-1, 1024, 26, 26]         294,912\n","     BatchNorm2d-135         [-1, 1024, 26, 26]           2,048\n","            ReLU-136         [-1, 1024, 26, 26]               0\n","          Conv2d-137         [-1, 1024, 26, 26]       1,048,576\n","     BatchNorm2d-138         [-1, 1024, 26, 26]           2,048\n","            ReLU-139         [-1, 1024, 26, 26]               0\n","      Bottleneck-140         [-1, 1024, 26, 26]               0\n","          Conv2d-141         [-1, 1024, 26, 26]       1,048,576\n","     BatchNorm2d-142         [-1, 1024, 26, 26]           2,048\n","            ReLU-143         [-1, 1024, 26, 26]               0\n","          Conv2d-144         [-1, 1024, 26, 26]         294,912\n","     BatchNorm2d-145         [-1, 1024, 26, 26]           2,048\n","            ReLU-146         [-1, 1024, 26, 26]               0\n","          Conv2d-147         [-1, 1024, 26, 26]       1,048,576\n","     BatchNorm2d-148         [-1, 1024, 26, 26]           2,048\n","            ReLU-149         [-1, 1024, 26, 26]               0\n","      Bottleneck-150         [-1, 1024, 26, 26]               0\n","          Conv2d-151         [-1, 1024, 26, 26]       1,048,576\n","     BatchNorm2d-152         [-1, 1024, 26, 26]           2,048\n","            ReLU-153         [-1, 1024, 26, 26]               0\n","          Conv2d-154         [-1, 1024, 26, 26]         294,912\n","     BatchNorm2d-155         [-1, 1024, 26, 26]           2,048\n","            ReLU-156         [-1, 1024, 26, 26]               0\n","          Conv2d-157         [-1, 1024, 26, 26]       1,048,576\n","     BatchNorm2d-158         [-1, 1024, 26, 26]           2,048\n","            ReLU-159         [-1, 1024, 26, 26]               0\n","      Bottleneck-160         [-1, 1024, 26, 26]               0\n","          Conv2d-161         [-1, 1024, 26, 26]       1,048,576\n","     BatchNorm2d-162         [-1, 1024, 26, 26]           2,048\n","            ReLU-163         [-1, 1024, 26, 26]               0\n","          Conv2d-164         [-1, 1024, 26, 26]         294,912\n","     BatchNorm2d-165         [-1, 1024, 26, 26]           2,048\n","            ReLU-166         [-1, 1024, 26, 26]               0\n","          Conv2d-167         [-1, 1024, 26, 26]       1,048,576\n","     BatchNorm2d-168         [-1, 1024, 26, 26]           2,048\n","            ReLU-169         [-1, 1024, 26, 26]               0\n","      Bottleneck-170         [-1, 1024, 26, 26]               0\n","          Conv2d-171         [-1, 1024, 26, 26]       1,048,576\n","     BatchNorm2d-172         [-1, 1024, 26, 26]           2,048\n","            ReLU-173         [-1, 1024, 26, 26]               0\n","          Conv2d-174         [-1, 1024, 26, 26]         294,912\n","     BatchNorm2d-175         [-1, 1024, 26, 26]           2,048\n","            ReLU-176         [-1, 1024, 26, 26]               0\n","          Conv2d-177         [-1, 1024, 26, 26]       1,048,576\n","     BatchNorm2d-178         [-1, 1024, 26, 26]           2,048\n","            ReLU-179         [-1, 1024, 26, 26]               0\n","      Bottleneck-180         [-1, 1024, 26, 26]               0\n","          Conv2d-181         [-1, 1024, 26, 26]       1,048,576\n","     BatchNorm2d-182         [-1, 1024, 26, 26]           2,048\n","            ReLU-183         [-1, 1024, 26, 26]               0\n","          Conv2d-184         [-1, 1024, 26, 26]         294,912\n","     BatchNorm2d-185         [-1, 1024, 26, 26]           2,048\n","            ReLU-186         [-1, 1024, 26, 26]               0\n","          Conv2d-187         [-1, 1024, 26, 26]       1,048,576\n","     BatchNorm2d-188         [-1, 1024, 26, 26]           2,048\n","            ReLU-189         [-1, 1024, 26, 26]               0\n","      Bottleneck-190         [-1, 1024, 26, 26]               0\n","          Conv2d-191         [-1, 1024, 26, 26]       1,048,576\n","     BatchNorm2d-192         [-1, 1024, 26, 26]           2,048\n","            ReLU-193         [-1, 1024, 26, 26]               0\n","          Conv2d-194         [-1, 1024, 26, 26]         294,912\n","     BatchNorm2d-195         [-1, 1024, 26, 26]           2,048\n","            ReLU-196         [-1, 1024, 26, 26]               0\n","          Conv2d-197         [-1, 1024, 26, 26]       1,048,576\n","     BatchNorm2d-198         [-1, 1024, 26, 26]           2,048\n","            ReLU-199         [-1, 1024, 26, 26]               0\n","      Bottleneck-200         [-1, 1024, 26, 26]               0\n","          Conv2d-201         [-1, 1024, 26, 26]       1,048,576\n","     BatchNorm2d-202         [-1, 1024, 26, 26]           2,048\n","            ReLU-203         [-1, 1024, 26, 26]               0\n","          Conv2d-204         [-1, 1024, 26, 26]         294,912\n","     BatchNorm2d-205         [-1, 1024, 26, 26]           2,048\n","            ReLU-206         [-1, 1024, 26, 26]               0\n","          Conv2d-207         [-1, 1024, 26, 26]       1,048,576\n","     BatchNorm2d-208         [-1, 1024, 26, 26]           2,048\n","            ReLU-209         [-1, 1024, 26, 26]               0\n","      Bottleneck-210         [-1, 1024, 26, 26]               0\n","          Conv2d-211         [-1, 1024, 26, 26]       1,048,576\n","     BatchNorm2d-212         [-1, 1024, 26, 26]           2,048\n","            ReLU-213         [-1, 1024, 26, 26]               0\n","          Conv2d-214         [-1, 1024, 26, 26]         294,912\n","     BatchNorm2d-215         [-1, 1024, 26, 26]           2,048\n","            ReLU-216         [-1, 1024, 26, 26]               0\n","          Conv2d-217         [-1, 1024, 26, 26]       1,048,576\n","     BatchNorm2d-218         [-1, 1024, 26, 26]           2,048\n","            ReLU-219         [-1, 1024, 26, 26]               0\n","      Bottleneck-220         [-1, 1024, 26, 26]               0\n","          Conv2d-221         [-1, 1024, 26, 26]       1,048,576\n","     BatchNorm2d-222         [-1, 1024, 26, 26]           2,048\n","            ReLU-223         [-1, 1024, 26, 26]               0\n","          Conv2d-224         [-1, 1024, 26, 26]         294,912\n","     BatchNorm2d-225         [-1, 1024, 26, 26]           2,048\n","            ReLU-226         [-1, 1024, 26, 26]               0\n","          Conv2d-227         [-1, 1024, 26, 26]       1,048,576\n","     BatchNorm2d-228         [-1, 1024, 26, 26]           2,048\n","            ReLU-229         [-1, 1024, 26, 26]               0\n","      Bottleneck-230         [-1, 1024, 26, 26]               0\n","          Conv2d-231         [-1, 1024, 26, 26]       1,048,576\n","     BatchNorm2d-232         [-1, 1024, 26, 26]           2,048\n","            ReLU-233         [-1, 1024, 26, 26]               0\n","          Conv2d-234         [-1, 1024, 26, 26]         294,912\n","     BatchNorm2d-235         [-1, 1024, 26, 26]           2,048\n","            ReLU-236         [-1, 1024, 26, 26]               0\n","          Conv2d-237         [-1, 1024, 26, 26]       1,048,576\n","     BatchNorm2d-238         [-1, 1024, 26, 26]           2,048\n","            ReLU-239         [-1, 1024, 26, 26]               0\n","      Bottleneck-240         [-1, 1024, 26, 26]               0\n","          Conv2d-241         [-1, 1024, 26, 26]       1,048,576\n","     BatchNorm2d-242         [-1, 1024, 26, 26]           2,048\n","            ReLU-243         [-1, 1024, 26, 26]               0\n","          Conv2d-244         [-1, 1024, 26, 26]         294,912\n","     BatchNorm2d-245         [-1, 1024, 26, 26]           2,048\n","            ReLU-246         [-1, 1024, 26, 26]               0\n","          Conv2d-247         [-1, 1024, 26, 26]       1,048,576\n","     BatchNorm2d-248         [-1, 1024, 26, 26]           2,048\n","            ReLU-249         [-1, 1024, 26, 26]               0\n","      Bottleneck-250         [-1, 1024, 26, 26]               0\n","          Conv2d-251         [-1, 1024, 26, 26]       1,048,576\n","     BatchNorm2d-252         [-1, 1024, 26, 26]           2,048\n","            ReLU-253         [-1, 1024, 26, 26]               0\n","          Conv2d-254         [-1, 1024, 26, 26]         294,912\n","     BatchNorm2d-255         [-1, 1024, 26, 26]           2,048\n","            ReLU-256         [-1, 1024, 26, 26]               0\n","          Conv2d-257         [-1, 1024, 26, 26]       1,048,576\n","     BatchNorm2d-258         [-1, 1024, 26, 26]           2,048\n","            ReLU-259         [-1, 1024, 26, 26]               0\n","      Bottleneck-260         [-1, 1024, 26, 26]               0\n","          Conv2d-261         [-1, 1024, 26, 26]       1,048,576\n","     BatchNorm2d-262         [-1, 1024, 26, 26]           2,048\n","            ReLU-263         [-1, 1024, 26, 26]               0\n","          Conv2d-264         [-1, 1024, 26, 26]         294,912\n","     BatchNorm2d-265         [-1, 1024, 26, 26]           2,048\n","            ReLU-266         [-1, 1024, 26, 26]               0\n","          Conv2d-267         [-1, 1024, 26, 26]       1,048,576\n","     BatchNorm2d-268         [-1, 1024, 26, 26]           2,048\n","            ReLU-269         [-1, 1024, 26, 26]               0\n","      Bottleneck-270         [-1, 1024, 26, 26]               0\n","          Conv2d-271         [-1, 1024, 26, 26]       1,048,576\n","     BatchNorm2d-272         [-1, 1024, 26, 26]           2,048\n","            ReLU-273         [-1, 1024, 26, 26]               0\n","          Conv2d-274         [-1, 1024, 26, 26]         294,912\n","     BatchNorm2d-275         [-1, 1024, 26, 26]           2,048\n","            ReLU-276         [-1, 1024, 26, 26]               0\n","          Conv2d-277         [-1, 1024, 26, 26]       1,048,576\n","     BatchNorm2d-278         [-1, 1024, 26, 26]           2,048\n","            ReLU-279         [-1, 1024, 26, 26]               0\n","      Bottleneck-280         [-1, 1024, 26, 26]               0\n","          Conv2d-281         [-1, 1024, 26, 26]       1,048,576\n","     BatchNorm2d-282         [-1, 1024, 26, 26]           2,048\n","            ReLU-283         [-1, 1024, 26, 26]               0\n","          Conv2d-284         [-1, 1024, 26, 26]         294,912\n","     BatchNorm2d-285         [-1, 1024, 26, 26]           2,048\n","            ReLU-286         [-1, 1024, 26, 26]               0\n","          Conv2d-287         [-1, 1024, 26, 26]       1,048,576\n","     BatchNorm2d-288         [-1, 1024, 26, 26]           2,048\n","            ReLU-289         [-1, 1024, 26, 26]               0\n","      Bottleneck-290         [-1, 1024, 26, 26]               0\n","          Conv2d-291         [-1, 1024, 26, 26]       1,048,576\n","     BatchNorm2d-292         [-1, 1024, 26, 26]           2,048\n","            ReLU-293         [-1, 1024, 26, 26]               0\n","          Conv2d-294         [-1, 1024, 26, 26]         294,912\n","     BatchNorm2d-295         [-1, 1024, 26, 26]           2,048\n","            ReLU-296         [-1, 1024, 26, 26]               0\n","          Conv2d-297         [-1, 1024, 26, 26]       1,048,576\n","     BatchNorm2d-298         [-1, 1024, 26, 26]           2,048\n","            ReLU-299         [-1, 1024, 26, 26]               0\n","      Bottleneck-300         [-1, 1024, 26, 26]               0\n","          Conv2d-301         [-1, 1024, 26, 26]       1,048,576\n","     BatchNorm2d-302         [-1, 1024, 26, 26]           2,048\n","            ReLU-303         [-1, 1024, 26, 26]               0\n","          Conv2d-304         [-1, 1024, 26, 26]         294,912\n","     BatchNorm2d-305         [-1, 1024, 26, 26]           2,048\n","            ReLU-306         [-1, 1024, 26, 26]               0\n","          Conv2d-307         [-1, 1024, 26, 26]       1,048,576\n","     BatchNorm2d-308         [-1, 1024, 26, 26]           2,048\n","            ReLU-309         [-1, 1024, 26, 26]               0\n","      Bottleneck-310         [-1, 1024, 26, 26]               0\n","          Conv2d-311         [-1, 2048, 26, 26]       2,097,152\n","     BatchNorm2d-312         [-1, 2048, 26, 26]           4,096\n","            ReLU-313         [-1, 2048, 26, 26]               0\n","          Conv2d-314         [-1, 2048, 13, 13]       1,179,648\n","     BatchNorm2d-315         [-1, 2048, 13, 13]           4,096\n","            ReLU-316         [-1, 2048, 13, 13]               0\n","          Conv2d-317         [-1, 2048, 13, 13]       4,194,304\n","     BatchNorm2d-318         [-1, 2048, 13, 13]           4,096\n","          Conv2d-319         [-1, 2048, 13, 13]       2,097,152\n","     BatchNorm2d-320         [-1, 2048, 13, 13]           4,096\n","            ReLU-321         [-1, 2048, 13, 13]               0\n","      Bottleneck-322         [-1, 2048, 13, 13]               0\n","          Conv2d-323         [-1, 2048, 13, 13]       4,194,304\n","     BatchNorm2d-324         [-1, 2048, 13, 13]           4,096\n","            ReLU-325         [-1, 2048, 13, 13]               0\n","          Conv2d-326         [-1, 2048, 13, 13]       1,179,648\n","     BatchNorm2d-327         [-1, 2048, 13, 13]           4,096\n","            ReLU-328         [-1, 2048, 13, 13]               0\n","          Conv2d-329         [-1, 2048, 13, 13]       4,194,304\n","     BatchNorm2d-330         [-1, 2048, 13, 13]           4,096\n","            ReLU-331         [-1, 2048, 13, 13]               0\n","      Bottleneck-332         [-1, 2048, 13, 13]               0\n","          Conv2d-333         [-1, 2048, 13, 13]       4,194,304\n","     BatchNorm2d-334         [-1, 2048, 13, 13]           4,096\n","            ReLU-335         [-1, 2048, 13, 13]               0\n","          Conv2d-336         [-1, 2048, 13, 13]       1,179,648\n","     BatchNorm2d-337         [-1, 2048, 13, 13]           4,096\n","            ReLU-338         [-1, 2048, 13, 13]               0\n","          Conv2d-339         [-1, 2048, 13, 13]       4,194,304\n","     BatchNorm2d-340         [-1, 2048, 13, 13]           4,096\n","            ReLU-341         [-1, 2048, 13, 13]               0\n","      Bottleneck-342         [-1, 2048, 13, 13]               0\n","          Conv2d-343        [-1, 256, 104, 104]         589,824\n","          Conv2d-344          [-1, 256, 52, 52]       1,179,648\n","          Conv2d-345          [-1, 256, 26, 26]       2,359,296\n","          Conv2d-346          [-1, 256, 13, 13]       4,718,592\n","            ReLU-347          [-1, 256, 13, 13]               0\n","          Conv2d-348          [-1, 256, 13, 13]         590,080\n","            ReLU-349          [-1, 256, 13, 13]               0\n","          Conv2d-350          [-1, 256, 13, 13]         590,080\n","ResidualConvUnit-351          [-1, 256, 13, 13]               0\n","FeatureFusionBlock-352          [-1, 256, 26, 26]               0\n","            ReLU-353          [-1, 256, 26, 26]               0\n","          Conv2d-354          [-1, 256, 26, 26]         590,080\n","            ReLU-355          [-1, 256, 26, 26]               0\n","          Conv2d-356          [-1, 256, 26, 26]         590,080\n","ResidualConvUnit-357          [-1, 256, 26, 26]               0\n","            ReLU-358          [-1, 256, 26, 26]               0\n","          Conv2d-359          [-1, 256, 26, 26]         590,080\n","            ReLU-360          [-1, 256, 26, 26]               0\n","          Conv2d-361          [-1, 256, 26, 26]         590,080\n","ResidualConvUnit-362          [-1, 256, 26, 26]               0\n","FeatureFusionBlock-363          [-1, 256, 52, 52]               0\n","            ReLU-364          [-1, 256, 52, 52]               0\n","          Conv2d-365          [-1, 256, 52, 52]         590,080\n","            ReLU-366          [-1, 256, 52, 52]               0\n","          Conv2d-367          [-1, 256, 52, 52]         590,080\n","ResidualConvUnit-368          [-1, 256, 52, 52]               0\n","            ReLU-369          [-1, 256, 52, 52]               0\n","          Conv2d-370          [-1, 256, 52, 52]         590,080\n","            ReLU-371          [-1, 256, 52, 52]               0\n","          Conv2d-372          [-1, 256, 52, 52]         590,080\n","ResidualConvUnit-373          [-1, 256, 52, 52]               0\n","FeatureFusionBlock-374        [-1, 256, 104, 104]               0\n","            ReLU-375        [-1, 256, 104, 104]               0\n","          Conv2d-376        [-1, 256, 104, 104]         590,080\n","            ReLU-377        [-1, 256, 104, 104]               0\n","          Conv2d-378        [-1, 256, 104, 104]         590,080\n","ResidualConvUnit-379        [-1, 256, 104, 104]               0\n","            ReLU-380        [-1, 256, 104, 104]               0\n","          Conv2d-381        [-1, 256, 104, 104]         590,080\n","            ReLU-382        [-1, 256, 104, 104]               0\n","          Conv2d-383        [-1, 256, 104, 104]         590,080\n","ResidualConvUnit-384        [-1, 256, 104, 104]               0\n","FeatureFusionBlock-385        [-1, 256, 208, 208]               0\n","          Conv2d-386        [-1, 128, 208, 208]         295,040\n","     Interpolate-387        [-1, 128, 416, 416]               0\n","          Conv2d-388         [-1, 32, 416, 416]          36,896\n","            ReLU-389         [-1, 32, 416, 416]               0\n","          Conv2d-390          [-1, 1, 416, 416]              33\n","            ReLU-391          [-1, 1, 416, 416]               0\n","          Conv2d-392        [-1, 256, 208, 208]           6,912\n","     BatchNorm2d-393        [-1, 256, 208, 208]             512\n","            ReLU-394        [-1, 256, 208, 208]               0\n","          Conv2d-395        [-1, 256, 104, 104]         589,824\n","     BatchNorm2d-396        [-1, 256, 104, 104]             512\n","            ReLU-397        [-1, 256, 104, 104]               0\n","          Conv2d-398          [-1, 256, 52, 52]         589,824\n","     BatchNorm2d-399          [-1, 256, 52, 52]             512\n","            ReLU-400          [-1, 256, 52, 52]               0\n","          Conv2d-401          [-1, 512, 26, 26]       1,179,648\n","     BatchNorm2d-402          [-1, 512, 26, 26]           1,024\n","            ReLU-403          [-1, 512, 26, 26]               0\n","          Conv2d-404         [-1, 1024, 13, 13]       4,718,592\n","     BatchNorm2d-405         [-1, 1024, 13, 13]           2,048\n","            ReLU-406         [-1, 1024, 13, 13]               0\n","          Conv2d-407         [-1, 1024, 13, 13]       2,097,152\n","     BatchNorm2d-408         [-1, 1024, 13, 13]           2,048\n","            ReLU-409         [-1, 1024, 13, 13]               0\n","          Conv2d-410           [-1, 27, 13, 13]          27,675\n","       YOLOLayer-411         [-1, 3, 13, 13, 9]               0\n","     Interpolate-412         [-1, 1024, 26, 26]               0\n","          Conv2d-413          [-1, 256, 26, 26]         262,144\n","     BatchNorm2d-414          [-1, 256, 26, 26]             512\n","            ReLU-415          [-1, 256, 26, 26]               0\n","          Conv2d-416          [-1, 512, 26, 26]         524,288\n","     BatchNorm2d-417          [-1, 512, 26, 26]           1,024\n","            ReLU-418          [-1, 512, 26, 26]               0\n","          Conv2d-419          [-1, 256, 26, 26]         196,608\n","     BatchNorm2d-420          [-1, 256, 26, 26]             512\n","            ReLU-421          [-1, 256, 26, 26]               0\n","          Conv2d-422          [-1, 512, 26, 26]       1,179,648\n","     BatchNorm2d-423          [-1, 512, 26, 26]           1,024\n","            ReLU-424          [-1, 512, 26, 26]               0\n","          Conv2d-425          [-1, 256, 26, 26]         131,072\n","     BatchNorm2d-426          [-1, 256, 26, 26]             512\n","            ReLU-427          [-1, 256, 26, 26]               0\n","          Conv2d-428          [-1, 512, 26, 26]       1,179,648\n","     BatchNorm2d-429          [-1, 512, 26, 26]           1,024\n","            ReLU-430          [-1, 512, 26, 26]               0\n","          Conv2d-431          [-1, 256, 26, 26]         131,072\n","     BatchNorm2d-432          [-1, 256, 26, 26]             512\n","            ReLU-433          [-1, 256, 26, 26]               0\n","          Conv2d-434          [-1, 512, 26, 26]       1,179,648\n","     BatchNorm2d-435          [-1, 512, 26, 26]           1,024\n","            ReLU-436          [-1, 512, 26, 26]               0\n","          Conv2d-437           [-1, 27, 26, 26]          13,851\n","       YOLOLayer-438         [-1, 3, 26, 26, 9]               0\n","          Conv2d-439          [-1, 256, 52, 52]         131,072\n","     BatchNorm2d-440          [-1, 256, 52, 52]             512\n","            ReLU-441          [-1, 256, 52, 52]               0\n","     Interpolate-442          [-1, 512, 52, 52]               0\n","          Conv2d-443          [-1, 128, 52, 52]          65,536\n","     BatchNorm2d-444          [-1, 128, 52, 52]             256\n","            ReLU-445          [-1, 128, 52, 52]               0\n","          Conv2d-446          [-1, 128, 52, 52]          49,152\n","     BatchNorm2d-447          [-1, 128, 52, 52]             256\n","            ReLU-448          [-1, 128, 52, 52]               0\n","          Conv2d-449          [-1, 256, 52, 52]         294,912\n","     BatchNorm2d-450          [-1, 256, 52, 52]             512\n","            ReLU-451          [-1, 256, 52, 52]               0\n","          Conv2d-452          [-1, 128, 52, 52]          32,768\n","     BatchNorm2d-453          [-1, 128, 52, 52]             256\n","            ReLU-454          [-1, 128, 52, 52]               0\n","          Conv2d-455          [-1, 256, 52, 52]         294,912\n","     BatchNorm2d-456          [-1, 256, 52, 52]             512\n","            ReLU-457          [-1, 256, 52, 52]               0\n","          Conv2d-458          [-1, 128, 52, 52]          32,768\n","     BatchNorm2d-459          [-1, 128, 52, 52]             256\n","            ReLU-460          [-1, 128, 52, 52]               0\n","          Conv2d-461          [-1, 256, 52, 52]         294,912\n","     BatchNorm2d-462          [-1, 256, 52, 52]             512\n","            ReLU-463          [-1, 256, 52, 52]               0\n","          Conv2d-464           [-1, 27, 52, 52]           6,939\n","       YOLOLayer-465         [-1, 3, 52, 52, 9]               0\n","================================================================\n","Total params: 119,409,234\n","Trainable params: 119,409,234\n","Non-trainable params: 0\n","----------------------------------------------------------------\n","Input size (MB): 1.98\n","Forward/backward pass size (MB): 3890.44\n","Params size (MB): 455.51\n","Estimated Total Size (MB): 4347.93\n","----------------------------------------------------------------\n","Caching labels (2623 found, 114 missing, 30 empty, 0 duplicate, for 2767 images): 100% 2767/2767 [21:26<00:00,  2.15it/s]\n","Caching images (0.0GB): 100% 2767/2767 [2:05:18<00:00,  2.72s/it]\n","Caching labels (657 found, 27 missing, 8 empty, 0 duplicate, for 692 images): 100% 692/692 [05:42<00:00,  2.02it/s]\n","Caching images (0.0GB): 100% 692/692 [29:48<00:00,  2.58s/it]\n","Freezing the midasnet\n","Image sizes 64 - 64 train, 64 test\n","Using 4 dataloader workers\n","Starting training for 50 epochs...\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","  0% 0/87 [00:00<?, ?it/s]/usr/local/lib/python3.6/dist-packages/torch/cuda/memory.py:346: FutureWarning: torch.cuda.memory_cached has been renamed to torch.cuda.memory_reserved\n","  FutureWarning)\n","      0/49     3.91G      5.22      48.4       3.7      57.3       166        64:   1% 1/87 [00:07<10:44,  7.50s/it]/usr/local/lib/python3.6/dist-packages/torch/cuda/memory.py:346: FutureWarning: torch.cuda.memory_cached has been renamed to torch.cuda.memory_reserved\n","  FutureWarning)\n","      0/49     3.92G      4.46      14.8      2.35      21.6        58        64: 100% 87/87 [01:53<00:00,  1.31s/it]\n","               Class    Images   Targets         P         R   mAP@0.5        F1:   0% 0/22 [00:00<?, ?it/s]/content/drive/My Drive/computer_vision/capstone_project/yolo_v3/utils/utils.py:544: UserWarning: This overload of nonzero is deprecated:\n","\tnonzero()\n","Consider using one of the following signatures instead:\n","\tnonzero(*, bool as_tuple) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:882.)\n","  i, j = (x[:, 5:] > conf_thres).nonzero().t()\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 22/22 [00:09<00:00,  2.25it/s]\n","                 all       692  3.06e+03         0         0  0.000219         0\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","  0% 0/87 [00:00<?, ?it/s]/usr/local/lib/python3.6/dist-packages/torch/cuda/memory.py:346: FutureWarning: torch.cuda.memory_cached has been renamed to torch.cuda.memory_reserved\n","  FutureWarning)\n","      1/49     3.92G      4.16      9.02      1.64      14.8        77        64: 100% 87/87 [01:53<00:00,  1.31s/it]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 22/22 [00:09<00:00,  2.41it/s]\n","                 all       692  3.06e+03    0.0273   0.00199   0.00145   0.00261\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","      2/49     3.92G      4.02       7.9      1.51      13.4        61        64: 100% 87/87 [01:54<00:00,  1.31s/it]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 22/22 [00:09<00:00,  2.42it/s]\n","                 all       692  3.06e+03   0.00199    0.0023  0.000815   0.00212\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","      3/49     3.92G      4.26      7.24       1.4      12.9        57        64: 100% 87/87 [01:51<00:00,  1.28s/it]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 22/22 [00:09<00:00,  2.40it/s]\n","                 all       692  3.06e+03    0.0115    0.0248   0.00182    0.0154\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","      4/49     3.92G      3.53      6.78      1.26      11.6        64        64: 100% 87/87 [01:53<00:00,  1.30s/it]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 22/22 [00:09<00:00,  2.44it/s]\n","                 all       692  3.06e+03     0.013    0.0229   0.00199    0.0161\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","      5/49     3.92G      3.45      6.56      1.21      11.2       139        64:  75% 65/87 [01:27<00:36,  1.64s/it]\n","Model Bias Summary:    layer        regression        objectness    classification\n","      5/49     3.92G      3.46      6.46      1.21      11.1        59        64: 100% 87/87 [01:52<00:00,  1.29s/it]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 22/22 [00:09<00:00,  2.44it/s]\n","                 all       692  3.06e+03    0.0114    0.0227   0.00166    0.0146\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","      6/49     3.92G       3.3      6.26      1.12      10.7        88        64: 100% 87/87 [01:52<00:00,  1.29s/it]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 22/22 [00:09<00:00,  2.40it/s]\n","                 all       692  3.06e+03    0.0156    0.0333   0.00265    0.0201\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","      7/49     3.92G      3.32      5.95      1.05      10.3        49        64: 100% 87/87 [01:53<00:00,  1.31s/it]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 22/22 [00:09<00:00,  2.42it/s]\n","                 all       692  3.06e+03    0.0119    0.0213   0.00202    0.0149\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","      8/49     3.92G      3.53      5.63      1.21      10.4        75        64: 100% 87/87 [01:51<00:00,  1.28s/it]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 22/22 [00:09<00:00,  2.41it/s]\n","                 all       692  3.06e+03    0.0191    0.0261   0.00298    0.0212\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","      9/49     3.92G      3.17      5.34      1.03      9.54        48        64: 100% 87/87 [01:55<00:00,  1.33s/it]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 22/22 [00:09<00:00,  2.41it/s]\n","                 all       692  3.06e+03    0.0191    0.0301   0.00367    0.0227\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","     10/49     3.92G      3.16      5.08     0.967       9.2        64        64: 100% 87/87 [01:53<00:00,  1.31s/it]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 22/22 [00:09<00:00,  2.43it/s]\n","                 all       692  3.06e+03    0.0177    0.0316   0.00269    0.0219\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","     11/49     3.92G      2.97      5.01     0.952      8.93        58        64: 100% 87/87 [01:50<00:00,  1.27s/it]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 22/22 [00:09<00:00,  2.44it/s]\n","                 all       692  3.06e+03    0.0209    0.0297   0.00439    0.0238\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","     12/49     3.92G      3.05      4.83      1.21       9.1        50        64: 100% 87/87 [01:53<00:00,  1.31s/it]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 22/22 [00:09<00:00,  2.42it/s]\n","                 all       692  3.06e+03     0.023    0.0285   0.00346    0.0248\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","     13/49     3.92G       3.1      4.75     0.944      8.79        80        64: 100% 87/87 [01:52<00:00,  1.29s/it]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 22/22 [00:09<00:00,  2.43it/s]\n","                 all       692  3.06e+03    0.0261    0.0345   0.00496    0.0287\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","     14/49     3.92G      3.04      4.72     0.891      8.65        64        64: 100% 87/87 [01:53<00:00,  1.31s/it]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 22/22 [00:09<00:00,  2.41it/s]\n","                 all       692  3.06e+03    0.0223    0.0357    0.0035    0.0264\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","     15/49     3.92G      2.87      4.81     0.925      8.61        59        64: 100% 87/87 [01:52<00:00,  1.30s/it]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 22/22 [00:09<00:00,  2.44it/s]\n","                 all       692  3.06e+03    0.0293    0.0414   0.00656     0.033\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","     16/49     3.92G      2.87      4.75      0.94      8.57        52        64: 100% 87/87 [01:53<00:00,  1.31s/it]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 22/22 [00:09<00:00,  2.41it/s]\n","                 all       692  3.06e+03    0.0284    0.0387   0.00529    0.0312\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","     17/49     3.92G      2.97      4.72      0.93      8.62        54        64: 100% 87/87 [01:52<00:00,  1.30s/it]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 22/22 [00:09<00:00,  2.41it/s]\n","                 all       692  3.06e+03     0.031    0.0394   0.00575    0.0333\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","     18/49     3.92G      2.72      4.72         1      8.44        65        64: 100% 87/87 [01:52<00:00,  1.29s/it]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 22/22 [00:09<00:00,  2.40it/s]\n","                 all       692  3.06e+03    0.0279    0.0382   0.00567    0.0315\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","     19/49     3.92G      2.91      4.68      1.04      8.63        47        64: 100% 87/87 [01:52<00:00,  1.29s/it]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 22/22 [00:09<00:00,  2.37it/s]\n","                 all       692  3.06e+03    0.0342    0.0457   0.00586    0.0384\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","     20/49     3.92G      2.77      4.78       0.9      8.44        63        64: 100% 87/87 [01:52<00:00,  1.29s/it]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 22/22 [00:09<00:00,  2.42it/s]\n","                 all       692  3.06e+03    0.0329    0.0433    0.0058    0.0363\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","     21/49     3.92G      2.76      4.63     0.927      8.32        62        64: 100% 87/87 [01:52<00:00,  1.29s/it]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 22/22 [00:09<00:00,  2.42it/s]\n","                 all       692  3.06e+03    0.0361    0.0456   0.00789    0.0393\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","     22/49     3.92G      2.76      4.76     0.863      8.38        48        64: 100% 87/87 [01:53<00:00,  1.31s/it]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 22/22 [00:09<00:00,  2.42it/s]\n","                 all       692  3.06e+03    0.0318    0.0422   0.00605    0.0355\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","     23/49     3.92G      2.76      4.65     0.823      8.24        39        64: 100% 87/87 [01:53<00:00,  1.30s/it]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 22/22 [00:09<00:00,  2.39it/s]\n","                 all       692  3.06e+03    0.0325    0.0443   0.00678    0.0365\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","     24/49     3.92G      2.89      4.63     0.816      8.34        57        64: 100% 87/87 [01:52<00:00,  1.29s/it]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 22/22 [00:09<00:00,  2.32it/s]\n","                 all       692  3.06e+03    0.0386    0.0471    0.0071    0.0414\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","     25/49     3.92G      2.84      4.59     0.889      8.32        61        64: 100% 87/87 [01:52<00:00,  1.29s/it]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 22/22 [00:09<00:00,  2.41it/s]\n","                 all       692  3.06e+03    0.0313    0.0382   0.00523    0.0337\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","     26/49     3.92G      2.69      4.64     0.845      8.18        55        64: 100% 87/87 [01:52<00:00,  1.30s/it]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 22/22 [00:09<00:00,  2.40it/s]\n","                 all       692  3.06e+03    0.0354    0.0443   0.00667    0.0385\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","     27/49     3.92G      2.62      4.66     0.815       8.1        82        64: 100% 87/87 [01:53<00:00,  1.30s/it]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 22/22 [00:09<00:00,  2.40it/s]\n","                 all       692  3.06e+03    0.0359    0.0409   0.00548    0.0371\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","     28/49     3.92G      2.68      4.55     0.791      8.02        67        64: 100% 87/87 [01:53<00:00,  1.30s/it]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 22/22 [00:09<00:00,  2.36it/s]\n","                 all       692  3.06e+03    0.0371    0.0447   0.00732    0.0393\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","     29/49     3.92G      2.72       4.6     0.817      8.14        48        64: 100% 87/87 [01:52<00:00,  1.30s/it]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 22/22 [00:09<00:00,  2.29it/s]\n","                 all       692  3.06e+03    0.0366    0.0472   0.00727    0.0401\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","     30/49     3.92G      2.74      4.61     0.796      8.15        61        64: 100% 87/87 [01:54<00:00,  1.31s/it]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 22/22 [00:09<00:00,  2.41it/s]\n","                 all       692  3.06e+03    0.0359    0.0419   0.00696    0.0376\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","     31/49     3.92G      2.59      4.66     0.805      8.05        70        64: 100% 87/87 [01:51<00:00,  1.29s/it]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 22/22 [00:09<00:00,  2.39it/s]\n","                 all       692  3.06e+03    0.0359    0.0454   0.00625    0.0391\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","     32/49     3.92G      2.61      4.52     0.767       7.9        75        64: 100% 87/87 [01:52<00:00,  1.30s/it]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 22/22 [00:09<00:00,  2.40it/s]\n","                 all       692  3.06e+03    0.0396    0.0482   0.00852    0.0426\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","     33/49     3.92G      2.55      4.48      0.75      7.78        63        64: 100% 87/87 [01:53<00:00,  1.31s/it]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 22/22 [00:09<00:00,  2.39it/s]\n","                 all       692  3.06e+03    0.0357    0.0436   0.00695    0.0384\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","     34/49     3.92G      2.68      4.72     0.738      8.14        56        64: 100% 87/87 [01:52<00:00,  1.29s/it]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 22/22 [00:09<00:00,  2.37it/s]\n","                 all       692  3.06e+03    0.0355    0.0435   0.00847    0.0379\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","     35/49     3.92G      2.69      4.53      0.73      7.95        52        64: 100% 87/87 [01:53<00:00,  1.30s/it]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 22/22 [00:09<00:00,  2.43it/s]\n","                 all       692  3.06e+03    0.0343    0.0433   0.00631    0.0377\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","     36/49     3.92G      2.61      4.57     0.745      7.92        61        64: 100% 87/87 [01:52<00:00,  1.29s/it]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 22/22 [00:09<00:00,  2.41it/s]\n","                 all       692  3.06e+03    0.0324     0.042   0.00693    0.0358\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","     37/49     3.92G      2.59      4.51     0.736      7.83       100        64: 100% 87/87 [01:53<00:00,  1.30s/it]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 22/22 [00:09<00:00,  2.42it/s]\n","                 all       692  3.06e+03    0.0396    0.0485   0.00854    0.0426\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","     38/49     3.92G      2.37      4.45     0.756      7.57        65        64: 100% 87/87 [01:51<00:00,  1.28s/it]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 22/22 [00:09<00:00,  2.43it/s]\n","                 all       692  3.06e+03    0.0362    0.0434   0.00766    0.0385\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","     39/49     3.92G      2.72      4.47      1.13      8.31        64        64: 100% 87/87 [01:52<00:00,  1.29s/it]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 22/22 [00:09<00:00,  2.39it/s]\n","                 all       692  3.06e+03    0.0357    0.0428   0.00707    0.0381\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","     40/49     3.92G      2.47      4.41     0.757      7.64        63        64: 100% 87/87 [01:52<00:00,  1.29s/it]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 22/22 [00:09<00:00,  2.43it/s]\n","                 all       692  3.06e+03    0.0398    0.0483   0.00873    0.0426\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","     41/49     3.92G      2.47      4.42     0.759      7.65        62        64: 100% 87/87 [01:52<00:00,  1.29s/it]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 22/22 [00:09<00:00,  2.42it/s]\n","                 all       692  3.06e+03    0.0379    0.0465   0.00823     0.041\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","     42/49     3.92G      2.63      4.46     0.765      7.85        58        64: 100% 87/87 [01:52<00:00,  1.29s/it]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 22/22 [00:09<00:00,  2.40it/s]\n","                 all       692  3.06e+03    0.0372    0.0435   0.00733    0.0394\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","     43/49     3.92G      2.57      4.37     0.731      7.66        55        64: 100% 87/87 [01:51<00:00,  1.29s/it]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 22/22 [00:09<00:00,  2.43it/s]\n","                 all       692  3.06e+03    0.0365    0.0458   0.00732    0.0396\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","     44/49     3.92G      2.51      4.53     0.717      7.75        77        64: 100% 87/87 [01:52<00:00,  1.30s/it]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 22/22 [00:09<00:00,  2.41it/s]\n","                 all       692  3.06e+03    0.0377    0.0492   0.00775    0.0418\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","     45/49     3.92G      2.51      4.34     0.788      7.64        63        64: 100% 87/87 [01:51<00:00,  1.28s/it]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 22/22 [00:09<00:00,  2.44it/s]\n","                 all       692  3.06e+03    0.0392    0.0491   0.00836    0.0426\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","     46/49     3.92G      2.42      4.43     0.701      7.56        68        64: 100% 87/87 [01:51<00:00,  1.28s/it]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 22/22 [00:09<00:00,  2.40it/s]\n","                 all       692  3.06e+03    0.0398    0.0506   0.00858    0.0436\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","     47/49     3.92G      2.37      4.46     0.755      7.59        64        64: 100% 87/87 [01:52<00:00,  1.29s/it]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 22/22 [00:09<00:00,  2.42it/s]\n","                 all       692  3.06e+03    0.0399    0.0521   0.00885    0.0442\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","     48/49     3.92G      2.41      4.41     0.751      7.57        59        64: 100% 87/87 [01:51<00:00,  1.29s/it]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 22/22 [00:09<00:00,  2.41it/s]\n","                 all       692  3.06e+03    0.0409    0.0507   0.00899    0.0445\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","     49/49     3.92G      2.49      4.55      0.82      7.86        68        64: 100% 87/87 [01:54<00:00,  1.31s/it]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 22/22 [00:09<00:00,  2.42it/s]\n","                 all       692  3.06e+03    0.0397     0.052   0.00904     0.044\n","50 epochs completed in 1.743 hours.\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"SmS4GZxQ3Kgu","colab":{"base_uri":"https://localhost:8080/"},"outputId":"44830411-60a9-4b8e-80e0-64b6f2816ee5"},"source":["# !ls /content/drive/My\\ Drive/computer_vision/capstone_project/yolo_v3/data/customdata/capstone_dataset/ground_truths/depthmap_gt_images/K25.png\n","!ls /content/drive/My\\ Drive/computer_vision/capstone_project/yolo_v3/data/customdata/capstone_dataset/ground_truths/planar_surface_gt_images/K25_segmentation_final.png\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["'/content/drive/My Drive/computer_vision/capstone_project/yolo_v3/data/customdata/capstone_dataset/ground_truths/planar_surface_gt_images/K25_segmentation_final.png'\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"fvIUFB639FP8"},"source":["# !python train.py --data data/customdata/custom.data --batch 10 --cache --cfg cfg/yolov3-custom.cfg --epochs 50 --midas_weights='weights/model-f46da743.pt' --yolo_weights='weights/last.pt' --init_train='True' --img-size=64"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"j51df4Kj9Sl2"},"source":["## Training yolo branch only by freezing the midas layers on 64x64 resolution for few more epochs"]},{"cell_type":"code","metadata":{"id":"S5fn_G66kWpR","colab":{"base_uri":"https://localhost:8080/"},"outputId":"7128be7a-a02e-4b6e-8c23-6e5a0f32aae4"},"source":["## Ignore the model summary in the below output - as it is summary on dummy input (3, 416,416) and before freezing the midas layers. But you can observe img_size attribute though as 64.\n","# Training yolo branch only by freezing the midas layers on 64x64 resolution\n","!python train.py --data data/customdata/custom.data --batch 32  --cache --cfg cfg/yolov3-custom.cfg --epochs 300 --weights 'weights/best.pt'  --img-size=64 --midasnet_freeze='True'"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Namespace(accumulate=4, adam=False, batch_size=32, bucket='', cache_images=True, cfg='cfg/yolov3-custom.cfg', data='data/customdata/custom.data', device='', epochs=300, evolve=False, img_size=[64], init_train='False', midas_weights='', midasnet_freeze='True', multi_scale=False, name='', nosave=False, notest=False, rect=False, resume=False, single_cls=False, weights='weights/best.pt', yolo_weights='')\n","Using CUDA device0 _CudaDeviceProperties(name='Tesla P100-PCIE-16GB', total_memory=16280MB)\n","\n","2020-11-14 05:53:42.864898: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n","Run 'tensorboard --logdir=runs' to view tensorboard at http://localhost:6006/\n","cfg - cfg/yolov3-custom.cfg\n","data - data/customdata/custom.data\n","epochs - 300\n","batch_size - 32\n","accumulate - 4\n","yolo weights - \n","midas weights - \n","imgsz_min- 64, imgsz_max- 64, imgsz_test- 64\n","opt.rect - False\n","train_path - data/customdata/train.txt\n","test_path - data/customdata/test.txt\n","init_train - False\n","weights - weights/best.pt\n","midasnet_freeze - True\n","Downloading: \"https://github.com/facebookresearch/WSL-Images/archive/master.zip\" to /root/.cache/torch/hub/master.zip\n","Downloading: \"https://download.pytorch.org/models/ig_resnext101_32x8-c38310e5.pth\" to /root/.cache/torch/hub/checkpoints/ig_resnext101_32x8-c38310e5.pth\n","100% 340M/340M [00:04<00:00, 79.1MB/s]\n","YMP Model Summary\n","----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","            Conv2d-1         [-1, 64, 208, 208]           9,408\n","       BatchNorm2d-2         [-1, 64, 208, 208]             128\n","              ReLU-3         [-1, 64, 208, 208]               0\n","         MaxPool2d-4         [-1, 64, 104, 104]               0\n","            Conv2d-5        [-1, 256, 104, 104]          16,384\n","       BatchNorm2d-6        [-1, 256, 104, 104]             512\n","              ReLU-7        [-1, 256, 104, 104]               0\n","            Conv2d-8        [-1, 256, 104, 104]          18,432\n","       BatchNorm2d-9        [-1, 256, 104, 104]             512\n","             ReLU-10        [-1, 256, 104, 104]               0\n","           Conv2d-11        [-1, 256, 104, 104]          65,536\n","      BatchNorm2d-12        [-1, 256, 104, 104]             512\n","           Conv2d-13        [-1, 256, 104, 104]          16,384\n","      BatchNorm2d-14        [-1, 256, 104, 104]             512\n","             ReLU-15        [-1, 256, 104, 104]               0\n","       Bottleneck-16        [-1, 256, 104, 104]               0\n","           Conv2d-17        [-1, 256, 104, 104]          65,536\n","      BatchNorm2d-18        [-1, 256, 104, 104]             512\n","             ReLU-19        [-1, 256, 104, 104]               0\n","           Conv2d-20        [-1, 256, 104, 104]          18,432\n","      BatchNorm2d-21        [-1, 256, 104, 104]             512\n","             ReLU-22        [-1, 256, 104, 104]               0\n","           Conv2d-23        [-1, 256, 104, 104]          65,536\n","      BatchNorm2d-24        [-1, 256, 104, 104]             512\n","             ReLU-25        [-1, 256, 104, 104]               0\n","       Bottleneck-26        [-1, 256, 104, 104]               0\n","           Conv2d-27        [-1, 256, 104, 104]          65,536\n","      BatchNorm2d-28        [-1, 256, 104, 104]             512\n","             ReLU-29        [-1, 256, 104, 104]               0\n","           Conv2d-30        [-1, 256, 104, 104]          18,432\n","      BatchNorm2d-31        [-1, 256, 104, 104]             512\n","             ReLU-32        [-1, 256, 104, 104]               0\n","           Conv2d-33        [-1, 256, 104, 104]          65,536\n","      BatchNorm2d-34        [-1, 256, 104, 104]             512\n","             ReLU-35        [-1, 256, 104, 104]               0\n","       Bottleneck-36        [-1, 256, 104, 104]               0\n","           Conv2d-37        [-1, 512, 104, 104]         131,072\n","      BatchNorm2d-38        [-1, 512, 104, 104]           1,024\n","             ReLU-39        [-1, 512, 104, 104]               0\n","           Conv2d-40          [-1, 512, 52, 52]          73,728\n","      BatchNorm2d-41          [-1, 512, 52, 52]           1,024\n","             ReLU-42          [-1, 512, 52, 52]               0\n","           Conv2d-43          [-1, 512, 52, 52]         262,144\n","      BatchNorm2d-44          [-1, 512, 52, 52]           1,024\n","           Conv2d-45          [-1, 512, 52, 52]         131,072\n","      BatchNorm2d-46          [-1, 512, 52, 52]           1,024\n","             ReLU-47          [-1, 512, 52, 52]               0\n","       Bottleneck-48          [-1, 512, 52, 52]               0\n","           Conv2d-49          [-1, 512, 52, 52]         262,144\n","      BatchNorm2d-50          [-1, 512, 52, 52]           1,024\n","             ReLU-51          [-1, 512, 52, 52]               0\n","           Conv2d-52          [-1, 512, 52, 52]          73,728\n","      BatchNorm2d-53          [-1, 512, 52, 52]           1,024\n","             ReLU-54          [-1, 512, 52, 52]               0\n","           Conv2d-55          [-1, 512, 52, 52]         262,144\n","      BatchNorm2d-56          [-1, 512, 52, 52]           1,024\n","             ReLU-57          [-1, 512, 52, 52]               0\n","       Bottleneck-58          [-1, 512, 52, 52]               0\n","           Conv2d-59          [-1, 512, 52, 52]         262,144\n","      BatchNorm2d-60          [-1, 512, 52, 52]           1,024\n","             ReLU-61          [-1, 512, 52, 52]               0\n","           Conv2d-62          [-1, 512, 52, 52]          73,728\n","      BatchNorm2d-63          [-1, 512, 52, 52]           1,024\n","             ReLU-64          [-1, 512, 52, 52]               0\n","           Conv2d-65          [-1, 512, 52, 52]         262,144\n","      BatchNorm2d-66          [-1, 512, 52, 52]           1,024\n","             ReLU-67          [-1, 512, 52, 52]               0\n","       Bottleneck-68          [-1, 512, 52, 52]               0\n","           Conv2d-69          [-1, 512, 52, 52]         262,144\n","      BatchNorm2d-70          [-1, 512, 52, 52]           1,024\n","             ReLU-71          [-1, 512, 52, 52]               0\n","           Conv2d-72          [-1, 512, 52, 52]          73,728\n","      BatchNorm2d-73          [-1, 512, 52, 52]           1,024\n","             ReLU-74          [-1, 512, 52, 52]               0\n","           Conv2d-75          [-1, 512, 52, 52]         262,144\n","      BatchNorm2d-76          [-1, 512, 52, 52]           1,024\n","             ReLU-77          [-1, 512, 52, 52]               0\n","       Bottleneck-78          [-1, 512, 52, 52]               0\n","           Conv2d-79         [-1, 1024, 52, 52]         524,288\n","      BatchNorm2d-80         [-1, 1024, 52, 52]           2,048\n","             ReLU-81         [-1, 1024, 52, 52]               0\n","           Conv2d-82         [-1, 1024, 26, 26]         294,912\n","      BatchNorm2d-83         [-1, 1024, 26, 26]           2,048\n","             ReLU-84         [-1, 1024, 26, 26]               0\n","           Conv2d-85         [-1, 1024, 26, 26]       1,048,576\n","      BatchNorm2d-86         [-1, 1024, 26, 26]           2,048\n","           Conv2d-87         [-1, 1024, 26, 26]         524,288\n","      BatchNorm2d-88         [-1, 1024, 26, 26]           2,048\n","             ReLU-89         [-1, 1024, 26, 26]               0\n","       Bottleneck-90         [-1, 1024, 26, 26]               0\n","           Conv2d-91         [-1, 1024, 26, 26]       1,048,576\n","      BatchNorm2d-92         [-1, 1024, 26, 26]           2,048\n","             ReLU-93         [-1, 1024, 26, 26]               0\n","           Conv2d-94         [-1, 1024, 26, 26]         294,912\n","      BatchNorm2d-95         [-1, 1024, 26, 26]           2,048\n","             ReLU-96         [-1, 1024, 26, 26]               0\n","           Conv2d-97         [-1, 1024, 26, 26]       1,048,576\n","      BatchNorm2d-98         [-1, 1024, 26, 26]           2,048\n","             ReLU-99         [-1, 1024, 26, 26]               0\n","      Bottleneck-100         [-1, 1024, 26, 26]               0\n","          Conv2d-101         [-1, 1024, 26, 26]       1,048,576\n","     BatchNorm2d-102         [-1, 1024, 26, 26]           2,048\n","            ReLU-103         [-1, 1024, 26, 26]               0\n","          Conv2d-104         [-1, 1024, 26, 26]         294,912\n","     BatchNorm2d-105         [-1, 1024, 26, 26]           2,048\n","            ReLU-106         [-1, 1024, 26, 26]               0\n","          Conv2d-107         [-1, 1024, 26, 26]       1,048,576\n","     BatchNorm2d-108         [-1, 1024, 26, 26]           2,048\n","            ReLU-109         [-1, 1024, 26, 26]               0\n","      Bottleneck-110         [-1, 1024, 26, 26]               0\n","          Conv2d-111         [-1, 1024, 26, 26]       1,048,576\n","     BatchNorm2d-112         [-1, 1024, 26, 26]           2,048\n","            ReLU-113         [-1, 1024, 26, 26]               0\n","          Conv2d-114         [-1, 1024, 26, 26]         294,912\n","     BatchNorm2d-115         [-1, 1024, 26, 26]           2,048\n","            ReLU-116         [-1, 1024, 26, 26]               0\n","          Conv2d-117         [-1, 1024, 26, 26]       1,048,576\n","     BatchNorm2d-118         [-1, 1024, 26, 26]           2,048\n","            ReLU-119         [-1, 1024, 26, 26]               0\n","      Bottleneck-120         [-1, 1024, 26, 26]               0\n","          Conv2d-121         [-1, 1024, 26, 26]       1,048,576\n","     BatchNorm2d-122         [-1, 1024, 26, 26]           2,048\n","            ReLU-123         [-1, 1024, 26, 26]               0\n","          Conv2d-124         [-1, 1024, 26, 26]         294,912\n","     BatchNorm2d-125         [-1, 1024, 26, 26]           2,048\n","            ReLU-126         [-1, 1024, 26, 26]               0\n","          Conv2d-127         [-1, 1024, 26, 26]       1,048,576\n","     BatchNorm2d-128         [-1, 1024, 26, 26]           2,048\n","            ReLU-129         [-1, 1024, 26, 26]               0\n","      Bottleneck-130         [-1, 1024, 26, 26]               0\n","          Conv2d-131         [-1, 1024, 26, 26]       1,048,576\n","     BatchNorm2d-132         [-1, 1024, 26, 26]           2,048\n","            ReLU-133         [-1, 1024, 26, 26]               0\n","          Conv2d-134         [-1, 1024, 26, 26]         294,912\n","     BatchNorm2d-135         [-1, 1024, 26, 26]           2,048\n","            ReLU-136         [-1, 1024, 26, 26]               0\n","          Conv2d-137         [-1, 1024, 26, 26]       1,048,576\n","     BatchNorm2d-138         [-1, 1024, 26, 26]           2,048\n","            ReLU-139         [-1, 1024, 26, 26]               0\n","      Bottleneck-140         [-1, 1024, 26, 26]               0\n","          Conv2d-141         [-1, 1024, 26, 26]       1,048,576\n","     BatchNorm2d-142         [-1, 1024, 26, 26]           2,048\n","            ReLU-143         [-1, 1024, 26, 26]               0\n","          Conv2d-144         [-1, 1024, 26, 26]         294,912\n","     BatchNorm2d-145         [-1, 1024, 26, 26]           2,048\n","            ReLU-146         [-1, 1024, 26, 26]               0\n","          Conv2d-147         [-1, 1024, 26, 26]       1,048,576\n","     BatchNorm2d-148         [-1, 1024, 26, 26]           2,048\n","            ReLU-149         [-1, 1024, 26, 26]               0\n","      Bottleneck-150         [-1, 1024, 26, 26]               0\n","          Conv2d-151         [-1, 1024, 26, 26]       1,048,576\n","     BatchNorm2d-152         [-1, 1024, 26, 26]           2,048\n","            ReLU-153         [-1, 1024, 26, 26]               0\n","          Conv2d-154         [-1, 1024, 26, 26]         294,912\n","     BatchNorm2d-155         [-1, 1024, 26, 26]           2,048\n","            ReLU-156         [-1, 1024, 26, 26]               0\n","          Conv2d-157         [-1, 1024, 26, 26]       1,048,576\n","     BatchNorm2d-158         [-1, 1024, 26, 26]           2,048\n","            ReLU-159         [-1, 1024, 26, 26]               0\n","      Bottleneck-160         [-1, 1024, 26, 26]               0\n","          Conv2d-161         [-1, 1024, 26, 26]       1,048,576\n","     BatchNorm2d-162         [-1, 1024, 26, 26]           2,048\n","            ReLU-163         [-1, 1024, 26, 26]               0\n","          Conv2d-164         [-1, 1024, 26, 26]         294,912\n","     BatchNorm2d-165         [-1, 1024, 26, 26]           2,048\n","            ReLU-166         [-1, 1024, 26, 26]               0\n","          Conv2d-167         [-1, 1024, 26, 26]       1,048,576\n","     BatchNorm2d-168         [-1, 1024, 26, 26]           2,048\n","            ReLU-169         [-1, 1024, 26, 26]               0\n","      Bottleneck-170         [-1, 1024, 26, 26]               0\n","          Conv2d-171         [-1, 1024, 26, 26]       1,048,576\n","     BatchNorm2d-172         [-1, 1024, 26, 26]           2,048\n","            ReLU-173         [-1, 1024, 26, 26]               0\n","          Conv2d-174         [-1, 1024, 26, 26]         294,912\n","     BatchNorm2d-175         [-1, 1024, 26, 26]           2,048\n","            ReLU-176         [-1, 1024, 26, 26]               0\n","          Conv2d-177         [-1, 1024, 26, 26]       1,048,576\n","     BatchNorm2d-178         [-1, 1024, 26, 26]           2,048\n","            ReLU-179         [-1, 1024, 26, 26]               0\n","      Bottleneck-180         [-1, 1024, 26, 26]               0\n","          Conv2d-181         [-1, 1024, 26, 26]       1,048,576\n","     BatchNorm2d-182         [-1, 1024, 26, 26]           2,048\n","            ReLU-183         [-1, 1024, 26, 26]               0\n","          Conv2d-184         [-1, 1024, 26, 26]         294,912\n","     BatchNorm2d-185         [-1, 1024, 26, 26]           2,048\n","            ReLU-186         [-1, 1024, 26, 26]               0\n","          Conv2d-187         [-1, 1024, 26, 26]       1,048,576\n","     BatchNorm2d-188         [-1, 1024, 26, 26]           2,048\n","            ReLU-189         [-1, 1024, 26, 26]               0\n","      Bottleneck-190         [-1, 1024, 26, 26]               0\n","          Conv2d-191         [-1, 1024, 26, 26]       1,048,576\n","     BatchNorm2d-192         [-1, 1024, 26, 26]           2,048\n","            ReLU-193         [-1, 1024, 26, 26]               0\n","          Conv2d-194         [-1, 1024, 26, 26]         294,912\n","     BatchNorm2d-195         [-1, 1024, 26, 26]           2,048\n","            ReLU-196         [-1, 1024, 26, 26]               0\n","          Conv2d-197         [-1, 1024, 26, 26]       1,048,576\n","     BatchNorm2d-198         [-1, 1024, 26, 26]           2,048\n","            ReLU-199         [-1, 1024, 26, 26]               0\n","      Bottleneck-200         [-1, 1024, 26, 26]               0\n","          Conv2d-201         [-1, 1024, 26, 26]       1,048,576\n","     BatchNorm2d-202         [-1, 1024, 26, 26]           2,048\n","            ReLU-203         [-1, 1024, 26, 26]               0\n","          Conv2d-204         [-1, 1024, 26, 26]         294,912\n","     BatchNorm2d-205         [-1, 1024, 26, 26]           2,048\n","            ReLU-206         [-1, 1024, 26, 26]               0\n","          Conv2d-207         [-1, 1024, 26, 26]       1,048,576\n","     BatchNorm2d-208         [-1, 1024, 26, 26]           2,048\n","            ReLU-209         [-1, 1024, 26, 26]               0\n","      Bottleneck-210         [-1, 1024, 26, 26]               0\n","          Conv2d-211         [-1, 1024, 26, 26]       1,048,576\n","     BatchNorm2d-212         [-1, 1024, 26, 26]           2,048\n","            ReLU-213         [-1, 1024, 26, 26]               0\n","          Conv2d-214         [-1, 1024, 26, 26]         294,912\n","     BatchNorm2d-215         [-1, 1024, 26, 26]           2,048\n","            ReLU-216         [-1, 1024, 26, 26]               0\n","          Conv2d-217         [-1, 1024, 26, 26]       1,048,576\n","     BatchNorm2d-218         [-1, 1024, 26, 26]           2,048\n","            ReLU-219         [-1, 1024, 26, 26]               0\n","      Bottleneck-220         [-1, 1024, 26, 26]               0\n","          Conv2d-221         [-1, 1024, 26, 26]       1,048,576\n","     BatchNorm2d-222         [-1, 1024, 26, 26]           2,048\n","            ReLU-223         [-1, 1024, 26, 26]               0\n","          Conv2d-224         [-1, 1024, 26, 26]         294,912\n","     BatchNorm2d-225         [-1, 1024, 26, 26]           2,048\n","            ReLU-226         [-1, 1024, 26, 26]               0\n","          Conv2d-227         [-1, 1024, 26, 26]       1,048,576\n","     BatchNorm2d-228         [-1, 1024, 26, 26]           2,048\n","            ReLU-229         [-1, 1024, 26, 26]               0\n","      Bottleneck-230         [-1, 1024, 26, 26]               0\n","          Conv2d-231         [-1, 1024, 26, 26]       1,048,576\n","     BatchNorm2d-232         [-1, 1024, 26, 26]           2,048\n","            ReLU-233         [-1, 1024, 26, 26]               0\n","          Conv2d-234         [-1, 1024, 26, 26]         294,912\n","     BatchNorm2d-235         [-1, 1024, 26, 26]           2,048\n","            ReLU-236         [-1, 1024, 26, 26]               0\n","          Conv2d-237         [-1, 1024, 26, 26]       1,048,576\n","     BatchNorm2d-238         [-1, 1024, 26, 26]           2,048\n","            ReLU-239         [-1, 1024, 26, 26]               0\n","      Bottleneck-240         [-1, 1024, 26, 26]               0\n","          Conv2d-241         [-1, 1024, 26, 26]       1,048,576\n","     BatchNorm2d-242         [-1, 1024, 26, 26]           2,048\n","            ReLU-243         [-1, 1024, 26, 26]               0\n","          Conv2d-244         [-1, 1024, 26, 26]         294,912\n","     BatchNorm2d-245         [-1, 1024, 26, 26]           2,048\n","            ReLU-246         [-1, 1024, 26, 26]               0\n","          Conv2d-247         [-1, 1024, 26, 26]       1,048,576\n","     BatchNorm2d-248         [-1, 1024, 26, 26]           2,048\n","            ReLU-249         [-1, 1024, 26, 26]               0\n","      Bottleneck-250         [-1, 1024, 26, 26]               0\n","          Conv2d-251         [-1, 1024, 26, 26]       1,048,576\n","     BatchNorm2d-252         [-1, 1024, 26, 26]           2,048\n","            ReLU-253         [-1, 1024, 26, 26]               0\n","          Conv2d-254         [-1, 1024, 26, 26]         294,912\n","     BatchNorm2d-255         [-1, 1024, 26, 26]           2,048\n","            ReLU-256         [-1, 1024, 26, 26]               0\n","          Conv2d-257         [-1, 1024, 26, 26]       1,048,576\n","     BatchNorm2d-258         [-1, 1024, 26, 26]           2,048\n","            ReLU-259         [-1, 1024, 26, 26]               0\n","      Bottleneck-260         [-1, 1024, 26, 26]               0\n","          Conv2d-261         [-1, 1024, 26, 26]       1,048,576\n","     BatchNorm2d-262         [-1, 1024, 26, 26]           2,048\n","            ReLU-263         [-1, 1024, 26, 26]               0\n","          Conv2d-264         [-1, 1024, 26, 26]         294,912\n","     BatchNorm2d-265         [-1, 1024, 26, 26]           2,048\n","            ReLU-266         [-1, 1024, 26, 26]               0\n","          Conv2d-267         [-1, 1024, 26, 26]       1,048,576\n","     BatchNorm2d-268         [-1, 1024, 26, 26]           2,048\n","            ReLU-269         [-1, 1024, 26, 26]               0\n","      Bottleneck-270         [-1, 1024, 26, 26]               0\n","          Conv2d-271         [-1, 1024, 26, 26]       1,048,576\n","     BatchNorm2d-272         [-1, 1024, 26, 26]           2,048\n","            ReLU-273         [-1, 1024, 26, 26]               0\n","          Conv2d-274         [-1, 1024, 26, 26]         294,912\n","     BatchNorm2d-275         [-1, 1024, 26, 26]           2,048\n","            ReLU-276         [-1, 1024, 26, 26]               0\n","          Conv2d-277         [-1, 1024, 26, 26]       1,048,576\n","     BatchNorm2d-278         [-1, 1024, 26, 26]           2,048\n","            ReLU-279         [-1, 1024, 26, 26]               0\n","      Bottleneck-280         [-1, 1024, 26, 26]               0\n","          Conv2d-281         [-1, 1024, 26, 26]       1,048,576\n","     BatchNorm2d-282         [-1, 1024, 26, 26]           2,048\n","            ReLU-283         [-1, 1024, 26, 26]               0\n","          Conv2d-284         [-1, 1024, 26, 26]         294,912\n","     BatchNorm2d-285         [-1, 1024, 26, 26]           2,048\n","            ReLU-286         [-1, 1024, 26, 26]               0\n","          Conv2d-287         [-1, 1024, 26, 26]       1,048,576\n","     BatchNorm2d-288         [-1, 1024, 26, 26]           2,048\n","            ReLU-289         [-1, 1024, 26, 26]               0\n","      Bottleneck-290         [-1, 1024, 26, 26]               0\n","          Conv2d-291         [-1, 1024, 26, 26]       1,048,576\n","     BatchNorm2d-292         [-1, 1024, 26, 26]           2,048\n","            ReLU-293         [-1, 1024, 26, 26]               0\n","          Conv2d-294         [-1, 1024, 26, 26]         294,912\n","     BatchNorm2d-295         [-1, 1024, 26, 26]           2,048\n","            ReLU-296         [-1, 1024, 26, 26]               0\n","          Conv2d-297         [-1, 1024, 26, 26]       1,048,576\n","     BatchNorm2d-298         [-1, 1024, 26, 26]           2,048\n","            ReLU-299         [-1, 1024, 26, 26]               0\n","      Bottleneck-300         [-1, 1024, 26, 26]               0\n","          Conv2d-301         [-1, 1024, 26, 26]       1,048,576\n","     BatchNorm2d-302         [-1, 1024, 26, 26]           2,048\n","            ReLU-303         [-1, 1024, 26, 26]               0\n","          Conv2d-304         [-1, 1024, 26, 26]         294,912\n","     BatchNorm2d-305         [-1, 1024, 26, 26]           2,048\n","            ReLU-306         [-1, 1024, 26, 26]               0\n","          Conv2d-307         [-1, 1024, 26, 26]       1,048,576\n","     BatchNorm2d-308         [-1, 1024, 26, 26]           2,048\n","            ReLU-309         [-1, 1024, 26, 26]               0\n","      Bottleneck-310         [-1, 1024, 26, 26]               0\n","          Conv2d-311         [-1, 2048, 26, 26]       2,097,152\n","     BatchNorm2d-312         [-1, 2048, 26, 26]           4,096\n","            ReLU-313         [-1, 2048, 26, 26]               0\n","          Conv2d-314         [-1, 2048, 13, 13]       1,179,648\n","     BatchNorm2d-315         [-1, 2048, 13, 13]           4,096\n","            ReLU-316         [-1, 2048, 13, 13]               0\n","          Conv2d-317         [-1, 2048, 13, 13]       4,194,304\n","     BatchNorm2d-318         [-1, 2048, 13, 13]           4,096\n","          Conv2d-319         [-1, 2048, 13, 13]       2,097,152\n","     BatchNorm2d-320         [-1, 2048, 13, 13]           4,096\n","            ReLU-321         [-1, 2048, 13, 13]               0\n","      Bottleneck-322         [-1, 2048, 13, 13]               0\n","          Conv2d-323         [-1, 2048, 13, 13]       4,194,304\n","     BatchNorm2d-324         [-1, 2048, 13, 13]           4,096\n","            ReLU-325         [-1, 2048, 13, 13]               0\n","          Conv2d-326         [-1, 2048, 13, 13]       1,179,648\n","     BatchNorm2d-327         [-1, 2048, 13, 13]           4,096\n","            ReLU-328         [-1, 2048, 13, 13]               0\n","          Conv2d-329         [-1, 2048, 13, 13]       4,194,304\n","     BatchNorm2d-330         [-1, 2048, 13, 13]           4,096\n","            ReLU-331         [-1, 2048, 13, 13]               0\n","      Bottleneck-332         [-1, 2048, 13, 13]               0\n","          Conv2d-333         [-1, 2048, 13, 13]       4,194,304\n","     BatchNorm2d-334         [-1, 2048, 13, 13]           4,096\n","            ReLU-335         [-1, 2048, 13, 13]               0\n","          Conv2d-336         [-1, 2048, 13, 13]       1,179,648\n","     BatchNorm2d-337         [-1, 2048, 13, 13]           4,096\n","            ReLU-338         [-1, 2048, 13, 13]               0\n","          Conv2d-339         [-1, 2048, 13, 13]       4,194,304\n","     BatchNorm2d-340         [-1, 2048, 13, 13]           4,096\n","            ReLU-341         [-1, 2048, 13, 13]               0\n","      Bottleneck-342         [-1, 2048, 13, 13]               0\n","          Conv2d-343        [-1, 256, 104, 104]         589,824\n","          Conv2d-344          [-1, 256, 52, 52]       1,179,648\n","          Conv2d-345          [-1, 256, 26, 26]       2,359,296\n","          Conv2d-346          [-1, 256, 13, 13]       4,718,592\n","            ReLU-347          [-1, 256, 13, 13]               0\n","          Conv2d-348          [-1, 256, 13, 13]         590,080\n","            ReLU-349          [-1, 256, 13, 13]               0\n","          Conv2d-350          [-1, 256, 13, 13]         590,080\n","ResidualConvUnit-351          [-1, 256, 13, 13]               0\n","FeatureFusionBlock-352          [-1, 256, 26, 26]               0\n","            ReLU-353          [-1, 256, 26, 26]               0\n","          Conv2d-354          [-1, 256, 26, 26]         590,080\n","            ReLU-355          [-1, 256, 26, 26]               0\n","          Conv2d-356          [-1, 256, 26, 26]         590,080\n","ResidualConvUnit-357          [-1, 256, 26, 26]               0\n","            ReLU-358          [-1, 256, 26, 26]               0\n","          Conv2d-359          [-1, 256, 26, 26]         590,080\n","            ReLU-360          [-1, 256, 26, 26]               0\n","          Conv2d-361          [-1, 256, 26, 26]         590,080\n","ResidualConvUnit-362          [-1, 256, 26, 26]               0\n","FeatureFusionBlock-363          [-1, 256, 52, 52]               0\n","            ReLU-364          [-1, 256, 52, 52]               0\n","          Conv2d-365          [-1, 256, 52, 52]         590,080\n","            ReLU-366          [-1, 256, 52, 52]               0\n","          Conv2d-367          [-1, 256, 52, 52]         590,080\n","ResidualConvUnit-368          [-1, 256, 52, 52]               0\n","            ReLU-369          [-1, 256, 52, 52]               0\n","          Conv2d-370          [-1, 256, 52, 52]         590,080\n","            ReLU-371          [-1, 256, 52, 52]               0\n","          Conv2d-372          [-1, 256, 52, 52]         590,080\n","ResidualConvUnit-373          [-1, 256, 52, 52]               0\n","FeatureFusionBlock-374        [-1, 256, 104, 104]               0\n","            ReLU-375        [-1, 256, 104, 104]               0\n","          Conv2d-376        [-1, 256, 104, 104]         590,080\n","            ReLU-377        [-1, 256, 104, 104]               0\n","          Conv2d-378        [-1, 256, 104, 104]         590,080\n","ResidualConvUnit-379        [-1, 256, 104, 104]               0\n","            ReLU-380        [-1, 256, 104, 104]               0\n","          Conv2d-381        [-1, 256, 104, 104]         590,080\n","            ReLU-382        [-1, 256, 104, 104]               0\n","          Conv2d-383        [-1, 256, 104, 104]         590,080\n","ResidualConvUnit-384        [-1, 256, 104, 104]               0\n","FeatureFusionBlock-385        [-1, 256, 208, 208]               0\n","          Conv2d-386        [-1, 128, 208, 208]         295,040\n","     Interpolate-387        [-1, 128, 416, 416]               0\n","          Conv2d-388         [-1, 32, 416, 416]          36,896\n","            ReLU-389         [-1, 32, 416, 416]               0\n","          Conv2d-390          [-1, 1, 416, 416]              33\n","            ReLU-391          [-1, 1, 416, 416]               0\n","          Conv2d-392        [-1, 256, 208, 208]           6,912\n","     BatchNorm2d-393        [-1, 256, 208, 208]             512\n","            ReLU-394        [-1, 256, 208, 208]               0\n","          Conv2d-395        [-1, 256, 104, 104]         589,824\n","     BatchNorm2d-396        [-1, 256, 104, 104]             512\n","            ReLU-397        [-1, 256, 104, 104]               0\n","          Conv2d-398          [-1, 256, 52, 52]         589,824\n","     BatchNorm2d-399          [-1, 256, 52, 52]             512\n","            ReLU-400          [-1, 256, 52, 52]               0\n","          Conv2d-401          [-1, 512, 26, 26]       1,179,648\n","     BatchNorm2d-402          [-1, 512, 26, 26]           1,024\n","            ReLU-403          [-1, 512, 26, 26]               0\n","          Conv2d-404         [-1, 1024, 13, 13]       4,718,592\n","     BatchNorm2d-405         [-1, 1024, 13, 13]           2,048\n","            ReLU-406         [-1, 1024, 13, 13]               0\n","          Conv2d-407         [-1, 1024, 13, 13]       2,097,152\n","     BatchNorm2d-408         [-1, 1024, 13, 13]           2,048\n","            ReLU-409         [-1, 1024, 13, 13]               0\n","          Conv2d-410           [-1, 27, 13, 13]          27,675\n","       YOLOLayer-411         [-1, 3, 13, 13, 9]               0\n","     Interpolate-412         [-1, 1024, 26, 26]               0\n","          Conv2d-413          [-1, 256, 26, 26]         262,144\n","     BatchNorm2d-414          [-1, 256, 26, 26]             512\n","            ReLU-415          [-1, 256, 26, 26]               0\n","          Conv2d-416          [-1, 512, 26, 26]         524,288\n","     BatchNorm2d-417          [-1, 512, 26, 26]           1,024\n","            ReLU-418          [-1, 512, 26, 26]               0\n","          Conv2d-419          [-1, 256, 26, 26]         196,608\n","     BatchNorm2d-420          [-1, 256, 26, 26]             512\n","            ReLU-421          [-1, 256, 26, 26]               0\n","          Conv2d-422          [-1, 512, 26, 26]       1,179,648\n","     BatchNorm2d-423          [-1, 512, 26, 26]           1,024\n","            ReLU-424          [-1, 512, 26, 26]               0\n","          Conv2d-425          [-1, 256, 26, 26]         131,072\n","     BatchNorm2d-426          [-1, 256, 26, 26]             512\n","            ReLU-427          [-1, 256, 26, 26]               0\n","          Conv2d-428          [-1, 512, 26, 26]       1,179,648\n","     BatchNorm2d-429          [-1, 512, 26, 26]           1,024\n","            ReLU-430          [-1, 512, 26, 26]               0\n","          Conv2d-431          [-1, 256, 26, 26]         131,072\n","     BatchNorm2d-432          [-1, 256, 26, 26]             512\n","            ReLU-433          [-1, 256, 26, 26]               0\n","          Conv2d-434          [-1, 512, 26, 26]       1,179,648\n","     BatchNorm2d-435          [-1, 512, 26, 26]           1,024\n","            ReLU-436          [-1, 512, 26, 26]               0\n","          Conv2d-437           [-1, 27, 26, 26]          13,851\n","       YOLOLayer-438         [-1, 3, 26, 26, 9]               0\n","          Conv2d-439          [-1, 256, 52, 52]         131,072\n","     BatchNorm2d-440          [-1, 256, 52, 52]             512\n","            ReLU-441          [-1, 256, 52, 52]               0\n","     Interpolate-442          [-1, 512, 52, 52]               0\n","          Conv2d-443          [-1, 128, 52, 52]          65,536\n","     BatchNorm2d-444          [-1, 128, 52, 52]             256\n","            ReLU-445          [-1, 128, 52, 52]               0\n","          Conv2d-446          [-1, 128, 52, 52]          49,152\n","     BatchNorm2d-447          [-1, 128, 52, 52]             256\n","            ReLU-448          [-1, 128, 52, 52]               0\n","          Conv2d-449          [-1, 256, 52, 52]         294,912\n","     BatchNorm2d-450          [-1, 256, 52, 52]             512\n","            ReLU-451          [-1, 256, 52, 52]               0\n","          Conv2d-452          [-1, 128, 52, 52]          32,768\n","     BatchNorm2d-453          [-1, 128, 52, 52]             256\n","            ReLU-454          [-1, 128, 52, 52]               0\n","          Conv2d-455          [-1, 256, 52, 52]         294,912\n","     BatchNorm2d-456          [-1, 256, 52, 52]             512\n","            ReLU-457          [-1, 256, 52, 52]               0\n","          Conv2d-458          [-1, 128, 52, 52]          32,768\n","     BatchNorm2d-459          [-1, 128, 52, 52]             256\n","            ReLU-460          [-1, 128, 52, 52]               0\n","          Conv2d-461          [-1, 256, 52, 52]         294,912\n","     BatchNorm2d-462          [-1, 256, 52, 52]             512\n","            ReLU-463          [-1, 256, 52, 52]               0\n","          Conv2d-464           [-1, 27, 52, 52]           6,939\n","       YOLOLayer-465         [-1, 3, 52, 52, 9]               0\n","================================================================\n","Total params: 119,409,234\n","Trainable params: 119,409,234\n","Non-trainable params: 0\n","----------------------------------------------------------------\n","Input size (MB): 1.98\n","Forward/backward pass size (MB): 3890.44\n","Params size (MB): 455.51\n","Estimated Total Size (MB): 4347.93\n","----------------------------------------------------------------\n","Caching labels (2623 found, 114 missing, 30 empty, 0 duplicate, for 2767 images): 100% 2767/2767 [10:26<00:00,  4.42it/s]\n","Caching images (0.0GB): 100% 2767/2767 [51:47<00:00,  1.12s/it]\n","Caching labels (657 found, 27 missing, 8 empty, 0 duplicate, for 692 images): 100% 692/692 [02:23<00:00,  4.84it/s]\n","Caching images (0.0GB): 100% 692/692 [12:59<00:00,  1.13s/it]\n","Freezing the midasnet\n","Image sizes 64 - 64 train, 64 test\n","Using 4 dataloader workers\n","Starting training for 300 epochs...\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","  0% 0/87 [00:00<?, ?it/s]/usr/local/lib/python3.6/dist-packages/torch/cuda/memory.py:346: FutureWarning: torch.cuda.memory_cached has been renamed to torch.cuda.memory_reserved\n","  FutureWarning)\n","    49/299      3.3G      2.86      4.53       1.5      8.89        58        64: 100% 87/87 [01:44<00:00,  1.20s/it]\n","               Class    Images   Targets         P         R   mAP@0.5        F1:   0% 0/22 [00:00<?, ?it/s]/content/drive/My Drive/computer_vision/capstone_project/yolo_v3/utils/utils.py:544: UserWarning: This overload of nonzero is deprecated:\n","\tnonzero()\n","Consider using one of the following signatures instead:\n","\tnonzero(*, bool as_tuple) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:882.)\n","  i, j = (x[:, 5:] > conf_thres).nonzero().t()\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 22/22 [00:09<00:00,  2.25it/s]\n","                 all       692  3.06e+03    0.0306     0.042   0.00658    0.0344\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","  0% 0/87 [00:00<?, ?it/s]/usr/local/lib/python3.6/dist-packages/torch/cuda/memory.py:346: FutureWarning: torch.cuda.memory_cached has been renamed to torch.cuda.memory_reserved\n","  FutureWarning)\n","    50/299      3.3G      2.69      4.53     0.833      8.05        77        64: 100% 87/87 [01:45<00:00,  1.22s/it]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 22/22 [00:08<00:00,  2.51it/s]\n","                 all       692  3.06e+03    0.0331    0.0437   0.00502    0.0366\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","    51/299      3.3G      2.78       4.5      0.83      8.11        61        64: 100% 87/87 [01:45<00:00,  1.21s/it]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 22/22 [00:08<00:00,  2.51it/s]\n","                 all       692  3.06e+03    0.0337    0.0424   0.00533    0.0365\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","    52/299      3.3G      2.95      4.44     0.838      8.23        57        64: 100% 87/87 [01:43<00:00,  1.19s/it]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 22/22 [00:08<00:00,  2.53it/s]\n","                 all       692  3.06e+03    0.0371    0.0476   0.00685    0.0401\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","    53/299      3.3G      2.59      4.47      0.79      7.85        64        64: 100% 87/87 [01:45<00:00,  1.21s/it]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 22/22 [00:08<00:00,  2.54it/s]\n","                 all       692  3.06e+03    0.0392    0.0476   0.00704    0.0416\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","    54/299      3.3G      2.64      4.45     0.788      7.88        59        64: 100% 87/87 [01:43<00:00,  1.19s/it]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 22/22 [00:08<00:00,  2.56it/s]\n","                 all       692  3.06e+03    0.0391     0.048   0.00682    0.0419\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","    55/299      3.3G      2.61      4.52     0.763      7.89        88        64: 100% 87/87 [01:44<00:00,  1.20s/it]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 22/22 [00:08<00:00,  2.53it/s]\n","                 all       692  3.06e+03     0.037    0.0522   0.00739    0.0425\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","    56/299      3.3G      2.71      4.47     0.707      7.88        49        64: 100% 87/87 [01:43<00:00,  1.19s/it]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 22/22 [00:08<00:00,  2.54it/s]\n","                 all       692  3.06e+03    0.0319    0.0454   0.00509    0.0364\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","    57/299      3.3G         3      4.45         1      8.45        75        64: 100% 87/87 [01:43<00:00,  1.19s/it]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 22/22 [00:08<00:00,  2.58it/s]\n","                 all       692  3.06e+03    0.0377    0.0422    0.0066     0.039\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","    58/299      3.3G       2.7      4.42     0.744      7.87        48        64: 100% 87/87 [01:45<00:00,  1.22s/it]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 22/22 [00:08<00:00,  2.55it/s]\n","                 all       692  3.06e+03    0.0407    0.0547   0.00817    0.0457\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","    59/299      3.3G      2.69      4.39     0.794      7.88        64        64: 100% 87/87 [01:45<00:00,  1.21s/it]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 22/22 [00:08<00:00,  2.52it/s]\n","                 all       692  3.06e+03    0.0313    0.0409   0.00501    0.0348\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","    60/299      3.3G      2.51      4.52     0.704      7.73        58        64: 100% 87/87 [01:44<00:00,  1.20s/it]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 22/22 [00:08<00:00,  2.56it/s]\n","                 all       692  3.06e+03    0.0374    0.0478   0.00695    0.0412\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","    61/299      3.3G      2.68      4.39     0.769      7.84        50        64: 100% 87/87 [01:46<00:00,  1.22s/it]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 22/22 [00:08<00:00,  2.53it/s]\n","                 all       692  3.06e+03    0.0317    0.0434   0.00515    0.0354\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","    62/299      3.3G      2.69      4.36      0.75       7.8        80        64: 100% 87/87 [01:43<00:00,  1.19s/it]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 22/22 [00:08<00:00,  2.55it/s]\n","                 all       692  3.06e+03    0.0331    0.0441    0.0063    0.0368\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","    63/299      3.3G      2.69       4.3     0.702      7.69        64        64: 100% 87/87 [01:44<00:00,  1.20s/it]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 22/22 [00:08<00:00,  2.56it/s]\n","                 all       692  3.06e+03    0.0357    0.0492    0.0063    0.0402\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","    64/299      3.3G      2.52      4.39     0.708      7.61        59        64: 100% 87/87 [01:44<00:00,  1.20s/it]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 22/22 [00:08<00:00,  2.54it/s]\n","                 all       692  3.06e+03    0.0406    0.0491   0.00679    0.0435\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","    65/299      3.3G      2.56      4.34     0.719      7.62        52        64: 100% 87/87 [01:44<00:00,  1.20s/it]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 22/22 [00:08<00:00,  2.53it/s]\n","                 all       692  3.06e+03    0.0365    0.0512   0.00729    0.0413\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","    66/299      3.3G       2.7      4.32     0.747      7.77        54        64: 100% 87/87 [01:43<00:00,  1.18s/it]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 22/22 [00:08<00:00,  2.57it/s]\n","                 all       692  3.06e+03    0.0393    0.0456   0.00609    0.0413\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","    67/299      3.3G      2.44      4.33      1.12      7.89        65        64: 100% 87/87 [01:42<00:00,  1.17s/it]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 22/22 [00:08<00:00,  2.60it/s]\n","                 all       692  3.06e+03    0.0338    0.0456   0.00657    0.0381\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","    68/299      3.3G      2.66      4.32     0.756      7.73        47        64: 100% 87/87 [01:43<00:00,  1.19s/it]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 22/22 [00:08<00:00,  2.55it/s]\n","                 all       692  3.06e+03      0.04    0.0509   0.00713     0.044\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","    69/299      3.3G      2.51      4.35     0.709      7.57        63        64: 100% 87/87 [01:43<00:00,  1.19s/it]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 22/22 [00:08<00:00,  2.58it/s]\n","                 all       692  3.06e+03     0.044    0.0534   0.00832    0.0476\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","    70/299      3.3G      2.48      4.25     0.713      7.44        62        64: 100% 87/87 [01:43<00:00,  1.19s/it]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 22/22 [00:08<00:00,  2.55it/s]\n","                 all       692  3.06e+03    0.0418    0.0568   0.00838    0.0467\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","    71/299      3.3G      2.52      4.38     0.678      7.58        48        64: 100% 87/87 [01:43<00:00,  1.19s/it]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 22/22 [00:08<00:00,  2.54it/s]\n","                 all       692  3.06e+03    0.0391    0.0557   0.00706    0.0446\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","    72/299      3.3G      2.53      4.32     0.673      7.51        39        64: 100% 87/87 [01:43<00:00,  1.19s/it]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 22/22 [00:08<00:00,  2.58it/s]\n","                 all       692  3.06e+03    0.0395    0.0496   0.00761    0.0431\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","    73/299      3.3G      2.69      4.28     0.664      7.63        57        64: 100% 87/87 [01:42<00:00,  1.18s/it]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 22/22 [00:08<00:00,  2.53it/s]\n","                 all       692  3.06e+03    0.0424    0.0578   0.00813     0.048\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","    74/299      3.3G      2.64      4.25     0.716      7.61        61        64: 100% 87/87 [01:44<00:00,  1.20s/it]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 22/22 [00:08<00:00,  2.57it/s]\n","                 all       692  3.06e+03    0.0415    0.0532   0.00794    0.0453\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","    75/299      3.3G      2.49       4.3     0.702      7.49        55        64: 100% 87/87 [01:42<00:00,  1.18s/it]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 22/22 [00:08<00:00,  2.57it/s]\n","                 all       692  3.06e+03    0.0382    0.0474   0.00705    0.0414\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","    76/299      3.3G      2.45      4.29     0.679      7.42        82        64: 100% 87/87 [01:42<00:00,  1.17s/it]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 22/22 [00:08<00:00,  2.57it/s]\n","                 all       692  3.06e+03    0.0422    0.0538   0.00811     0.046\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","    77/299      3.3G      2.49      4.23     0.651      7.37        67        64: 100% 87/87 [01:43<00:00,  1.19s/it]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 22/22 [00:08<00:00,  2.60it/s]\n","                 all       692  3.06e+03    0.0394    0.0502   0.00723    0.0431\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","    78/299      3.3G      2.58      4.28     0.659      7.52        48        64: 100% 87/87 [01:42<00:00,  1.18s/it]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 22/22 [00:08<00:00,  2.59it/s]\n","                 all       692  3.06e+03    0.0376    0.0542    0.0068    0.0428\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","    79/299      3.3G       2.6       4.3     0.661      7.57        61        64: 100% 87/87 [01:43<00:00,  1.19s/it]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 22/22 [00:08<00:00,  2.58it/s]\n","                 all       692  3.06e+03    0.0368    0.0465   0.00656    0.0399\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","    80/299      3.3G      2.43      4.36     0.675      7.47        70        64: 100% 87/87 [01:42<00:00,  1.17s/it]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 22/22 [00:08<00:00,  2.59it/s]\n","                 all       692  3.06e+03     0.041    0.0548   0.00869    0.0462\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","    81/299      3.3G      2.46      4.24     0.645      7.34        75        64: 100% 87/87 [01:40<00:00,  1.16s/it]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 22/22 [00:08<00:00,  2.57it/s]\n","                 all       692  3.06e+03    0.0408    0.0538   0.00786     0.045\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","    82/299      3.3G      2.42      4.22     0.622      7.26        63        64: 100% 87/87 [01:42<00:00,  1.18s/it]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 22/22 [00:08<00:00,  2.61it/s]\n","                 all       692  3.06e+03    0.0381    0.0492   0.00941    0.0419\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","    83/299      3.3G      2.58      4.38     0.611      7.57        56        64: 100% 87/87 [01:42<00:00,  1.17s/it]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 22/22 [00:08<00:00,  2.61it/s]\n","                 all       692  3.06e+03    0.0425    0.0502   0.00885    0.0443\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","    84/299      3.3G      2.57      4.31     0.609      7.49        52        64: 100% 87/87 [01:42<00:00,  1.18s/it]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 22/22 [00:08<00:00,  2.60it/s]\n","                 all       692  3.06e+03    0.0391    0.0515   0.00813    0.0433\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","    85/299      3.3G      2.51      4.29     0.633      7.43        61        64: 100% 87/87 [01:42<00:00,  1.18s/it]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 22/22 [00:08<00:00,  2.60it/s]\n","                 all       692  3.06e+03    0.0419    0.0492    0.0101    0.0438\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","    86/299      3.3G      2.51      4.22     0.624      7.35       100        64: 100% 87/87 [01:42<00:00,  1.18s/it]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 22/22 [00:08<00:00,  2.59it/s]\n","                 all       692  3.06e+03    0.0377     0.051   0.00683    0.0425\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","    87/299      3.3G      2.32      4.21     0.641      7.17        65        64: 100% 87/87 [01:41<00:00,  1.17s/it]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 22/22 [00:08<00:00,  2.60it/s]\n","                 all       692  3.06e+03    0.0408    0.0535   0.00853    0.0447\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","    88/299      3.3G      2.66      4.24      1.55      8.45        64        64: 100% 87/87 [01:41<00:00,  1.17s/it]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 22/22 [00:08<00:00,  2.63it/s]\n","                 all       692  3.06e+03    0.0428    0.0523   0.00904    0.0459\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","    89/299      3.3G      2.41      4.18     0.613       7.2        63        64: 100% 87/87 [01:42<00:00,  1.18s/it]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 22/22 [00:08<00:00,  2.59it/s]\n","                 all       692  3.06e+03    0.0408    0.0547   0.00863    0.0454\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","    90/299      3.3G      2.43       4.2     0.595      7.22        62        64: 100% 87/87 [01:40<00:00,  1.16s/it]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 22/22 [00:08<00:00,  2.58it/s]\n","                 all       692  3.06e+03    0.0352    0.0454   0.00604    0.0389\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","    91/299      3.3G      2.59      4.25     0.666      7.51        58        64: 100% 87/87 [01:41<00:00,  1.17s/it]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 22/22 [00:08<00:00,  2.60it/s]\n","                 all       692  3.06e+03    0.0329    0.0426   0.00515    0.0363\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","    92/299      3.3G      2.51      4.15     0.575      7.24        55        64: 100% 87/87 [01:41<00:00,  1.17s/it]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 22/22 [00:08<00:00,  2.58it/s]\n","                 all       692  3.06e+03    0.0399    0.0519   0.00755    0.0443\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","    93/299      3.3G      2.47      4.32     0.577      7.37        77        64: 100% 87/87 [01:42<00:00,  1.18s/it]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 22/22 [00:08<00:00,  2.62it/s]\n","                 all       692  3.06e+03    0.0415    0.0535   0.00758    0.0454\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","    94/299      3.3G      2.47      4.15     0.707      7.33        63        64: 100% 87/87 [01:40<00:00,  1.16s/it]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 22/22 [00:08<00:00,  2.61it/s]\n","                 all       692  3.06e+03    0.0398    0.0531   0.00659     0.044\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","    95/299      3.3G      2.38      4.21     0.602      7.19        68        64: 100% 87/87 [01:41<00:00,  1.17s/it]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 22/22 [00:08<00:00,  2.60it/s]\n","                 all       692  3.06e+03    0.0396     0.045   0.00718    0.0412\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","    96/299      3.3G      2.33      4.23     0.596      7.15        64        64: 100% 87/87 [01:41<00:00,  1.17s/it]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 22/22 [00:08<00:00,  2.61it/s]\n","                 all       692  3.06e+03    0.0422    0.0523   0.00702    0.0445\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","    97/299      3.3G      2.36      4.13     0.586      7.08        59        64: 100% 87/87 [01:41<00:00,  1.16s/it]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 22/22 [00:08<00:00,  2.57it/s]\n","                 all       692  3.06e+03    0.0426    0.0578   0.00791    0.0477\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","    98/299      3.3G      2.48      4.35     0.581      7.41        68        64: 100% 87/87 [01:42<00:00,  1.18s/it]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 22/22 [00:08<00:00,  2.58it/s]\n","                 all       692  3.06e+03    0.0328    0.0442   0.00551    0.0367\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","    99/299      3.3G      2.49      4.15     0.589      7.23        68        64: 100% 87/87 [01:41<00:00,  1.17s/it]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 22/22 [00:08<00:00,  2.59it/s]\n","                 all       692  3.06e+03    0.0373    0.0461   0.00661    0.0403\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","   100/299      3.3G      2.46      4.13      1.43      8.03        73        64: 100% 87/87 [01:42<00:00,  1.18s/it]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 22/22 [00:08<00:00,  2.59it/s]\n","                 all       692  3.06e+03    0.0411    0.0481     0.007    0.0429\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","   101/299      3.3G      2.34       4.2     0.581      7.11        73        64: 100% 87/87 [01:42<00:00,  1.18s/it]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 22/22 [00:08<00:00,  2.57it/s]\n","                 all       692  3.06e+03    0.0386    0.0493   0.00728    0.0422\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","   102/299      3.3G      2.41      4.18     0.563      7.15        62        64: 100% 87/87 [01:42<00:00,  1.18s/it]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 22/22 [00:08<00:00,  2.56it/s]\n","                 all       692  3.06e+03    0.0403    0.0519   0.00668    0.0438\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","   103/299      3.3G      2.47      4.22     0.569      7.25        53        64: 100% 87/87 [01:41<00:00,  1.17s/it]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 22/22 [00:08<00:00,  2.62it/s]\n","                 all       692  3.06e+03    0.0419    0.0506   0.00702    0.0447\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","   104/299      3.3G      2.31      4.16     0.575      7.05        60        64: 100% 87/87 [01:41<00:00,  1.17s/it]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 22/22 [00:08<00:00,  2.60it/s]\n","                 all       692  3.06e+03    0.0458    0.0562    0.0079    0.0492\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","   105/299      3.3G      2.22       4.1     0.529      6.85        27        64: 100% 87/87 [01:43<00:00,  1.19s/it]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 22/22 [00:08<00:00,  2.59it/s]\n","                 all       692  3.06e+03    0.0464    0.0537   0.00761    0.0482\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","   106/299      3.3G      2.35      4.13     0.563      7.04        45        64: 100% 87/87 [01:42<00:00,  1.18s/it]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 22/22 [00:08<00:00,  2.61it/s]\n","                 all       692  3.06e+03    0.0411    0.0509   0.00604    0.0443\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","   107/299      3.3G      2.33      4.17     0.538      7.04        63        64: 100% 87/87 [01:41<00:00,  1.17s/it]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 22/22 [00:08<00:00,  2.59it/s]\n","                 all       692  3.06e+03    0.0443    0.0535   0.00789    0.0476\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","   108/299      3.3G      2.47      4.11     0.717       7.3        62        64: 100% 87/87 [01:41<00:00,  1.16s/it]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 22/22 [00:08<00:00,  2.56it/s]\n","                 all       692  3.06e+03      0.04    0.0523   0.00718     0.044\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","   109/299      3.3G      2.39      4.18     0.886      7.46        64        64: 100% 87/87 [01:40<00:00,  1.15s/it]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 22/22 [00:08<00:00,  2.62it/s]\n","                 all       692  3.06e+03      0.04    0.0489   0.00663    0.0431\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","   110/299      3.3G      2.45      4.08     0.561       7.1        79        64: 100% 87/87 [01:41<00:00,  1.17s/it]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 22/22 [00:08<00:00,  2.60it/s]\n","                 all       692  3.06e+03    0.0382    0.0498   0.00716     0.042\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","   111/299      3.3G      2.43      4.18      0.52      7.12        59        64: 100% 87/87 [01:43<00:00,  1.19s/it]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 22/22 [00:09<00:00,  2.41it/s]\n","                 all       692  3.06e+03    0.0394    0.0507   0.00836    0.0434\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","   112/299      3.3G      2.34      4.23     0.497      7.06        82        64: 100% 87/87 [01:43<00:00,  1.19s/it]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 22/22 [00:08<00:00,  2.57it/s]\n","                 all       692  3.06e+03    0.0412    0.0542   0.00753    0.0457\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","   113/299      3.3G       2.3      4.04     0.491      6.83        67        64: 100% 87/87 [01:44<00:00,  1.20s/it]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 22/22 [00:08<00:00,  2.55it/s]\n","                 all       692  3.06e+03    0.0453    0.0556   0.00825    0.0484\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","   114/299      3.3G      2.32      4.09     0.591         7        69        64: 100% 87/87 [01:44<00:00,  1.20s/it]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 22/22 [00:08<00:00,  2.56it/s]\n","                 all       692  3.06e+03    0.0415    0.0507   0.00838    0.0446\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","   115/299      3.3G      2.34      4.19     0.528      7.06        69        64: 100% 87/87 [01:44<00:00,  1.21s/it]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 22/22 [00:08<00:00,  2.55it/s]\n","                 all       692  3.06e+03    0.0395    0.0538   0.00797    0.0441\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","   116/299      3.3G      2.32      4.02     0.513      6.85        71        64: 100% 87/87 [01:44<00:00,  1.20s/it]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 22/22 [00:08<00:00,  2.51it/s]\n","                 all       692  3.06e+03    0.0368    0.0461   0.00636    0.0398\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","   117/299      3.3G      2.48      4.19     0.704      7.37        57        64: 100% 87/87 [01:44<00:00,  1.20s/it]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 22/22 [00:08<00:00,  2.52it/s]\n","                 all       692  3.06e+03    0.0389    0.0493   0.00697    0.0422\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","   118/299      3.3G      2.49      4.17     0.499      7.16        60        64: 100% 87/87 [01:45<00:00,  1.21s/it]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 22/22 [00:08<00:00,  2.52it/s]\n","                 all       692  3.06e+03    0.0405    0.0512   0.00636    0.0442\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","   119/299      3.3G      2.36      4.09     0.498      6.94        54        64: 100% 87/87 [01:45<00:00,  1.21s/it]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 22/22 [00:08<00:00,  2.51it/s]\n","                 all       692  3.06e+03    0.0408     0.049   0.00743    0.0435\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","   120/299      3.3G      2.23      4.08     0.506      6.82        51        64: 100% 87/87 [01:43<00:00,  1.19s/it]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 22/22 [00:08<00:00,  2.55it/s]\n","                 all       692  3.06e+03    0.0394     0.048   0.00652    0.0418\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","   121/299      3.3G      2.35      4.05     0.463      6.87        75        64: 100% 87/87 [01:44<00:00,  1.20s/it]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 22/22 [00:08<00:00,  2.52it/s]\n","                 all       692  3.06e+03    0.0405    0.0485   0.00715    0.0431\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","   122/299      3.3G      2.23      4.16     0.496      6.88        70        64: 100% 87/87 [01:47<00:00,  1.23s/it]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 22/22 [00:08<00:00,  2.51it/s]\n","                 all       692  3.06e+03    0.0429    0.0559   0.00877    0.0477\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","   123/299      3.3G      2.46      4.11     0.508      7.08        61        64: 100% 87/87 [01:44<00:00,  1.20s/it]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 22/22 [00:08<00:00,  2.57it/s]\n","                 all       692  3.06e+03    0.0421    0.0527   0.00671    0.0452\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","   124/299      3.3G      2.29      4.08      0.49      6.85        52        64: 100% 87/87 [01:43<00:00,  1.19s/it]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 22/22 [00:08<00:00,  2.52it/s]\n","                 all       692  3.06e+03     0.044     0.055   0.00786    0.0479\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","   125/299      3.3G      2.24         4     0.435      6.68        63        64: 100% 87/87 [01:42<00:00,  1.18s/it]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 22/22 [00:08<00:00,  2.50it/s]\n","                 all       692  3.06e+03    0.0437     0.054   0.00884    0.0472\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","   126/299      3.3G      2.34      4.06     0.439      6.84        47        64: 100% 87/87 [01:44<00:00,  1.20s/it]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 22/22 [00:08<00:00,  2.58it/s]\n","                 all       692  3.06e+03    0.0417    0.0497    0.0076    0.0445\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","   127/299      3.3G      2.37      4.13     0.438      6.93        66        64: 100% 87/87 [01:41<00:00,  1.17s/it]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 22/22 [00:08<00:00,  2.59it/s]\n","                 all       692  3.06e+03    0.0434    0.0521   0.00769    0.0458\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","   128/299      3.3G      2.31      4.05     0.479      6.84        74        64: 100% 87/87 [01:43<00:00,  1.20s/it]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 22/22 [00:08<00:00,  2.54it/s]\n","                 all       692  3.06e+03     0.046    0.0532   0.00802     0.048\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","   129/299      3.3G      2.39         4     0.458      6.85        51        64: 100% 87/87 [01:43<00:00,  1.19s/it]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 22/22 [00:08<00:00,  2.59it/s]\n","                 all       692  3.06e+03    0.0433    0.0525   0.00825    0.0461\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","   130/299      3.3G      2.37      4.08     0.468      6.92        63        64: 100% 87/87 [01:43<00:00,  1.18s/it]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 22/22 [00:08<00:00,  2.56it/s]\n","                 all       692  3.06e+03     0.045     0.056   0.00865    0.0488\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","   131/299      3.3G      2.22      4.02     0.459      6.69        47        64: 100% 87/87 [01:44<00:00,  1.20s/it]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 22/22 [00:08<00:00,  2.50it/s]\n","                 all       692  3.06e+03    0.0395    0.0496   0.00702    0.0429\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","   132/299      3.3G      2.43      3.97     0.459      6.85        52        64: 100% 87/87 [01:43<00:00,  1.19s/it]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 22/22 [00:08<00:00,  2.57it/s]\n","                 all       692  3.06e+03    0.0433     0.055   0.00887     0.047\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","   133/299      3.3G      2.27      3.99     0.471      6.73        77        64: 100% 87/87 [01:44<00:00,  1.20s/it]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 22/22 [00:08<00:00,  2.54it/s]\n","                 all       692  3.06e+03    0.0402    0.0522   0.00711     0.044\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","   134/299      3.3G      2.28      4.04     0.864      7.18        61        64: 100% 87/87 [01:44<00:00,  1.21s/it]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 22/22 [00:08<00:00,  2.56it/s]\n","                 all       692  3.06e+03    0.0364    0.0479   0.00661    0.0404\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","   135/299      3.3G      2.37         4     0.456      6.83        69        64: 100% 87/87 [01:43<00:00,  1.19s/it]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 22/22 [00:08<00:00,  2.58it/s]\n","                 all       692  3.06e+03     0.044     0.054   0.00856    0.0471\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","   136/299      3.3G      2.18      4.05     0.449      6.68        71        64: 100% 87/87 [01:43<00:00,  1.20s/it]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 22/22 [00:08<00:00,  2.55it/s]\n","                 all       692  3.06e+03    0.0418    0.0583   0.00834    0.0471\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","   137/299      3.3G       2.1       3.9     0.464      6.47        58        64: 100% 87/87 [01:42<00:00,  1.18s/it]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 22/22 [00:08<00:00,  2.59it/s]\n","                 all       692  3.06e+03    0.0406    0.0537   0.00751    0.0447\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","   138/299      3.3G      2.39      4.07     0.402      6.86        58        64: 100% 87/87 [01:42<00:00,  1.18s/it]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 22/22 [00:08<00:00,  2.59it/s]\n","                 all       692  3.06e+03    0.0403    0.0539   0.00869     0.045\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","   139/299      3.3G      2.25         4     0.463      6.71        67        64: 100% 87/87 [01:44<00:00,  1.20s/it]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 22/22 [00:08<00:00,  2.48it/s]\n","                 all       692  3.06e+03    0.0419      0.05    0.0093    0.0446\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","   140/299      3.3G      2.28      4.04     0.427      6.75        66        64: 100% 87/87 [01:42<00:00,  1.18s/it]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 22/22 [00:08<00:00,  2.54it/s]\n","                 all       692  3.06e+03    0.0415    0.0526   0.00759    0.0452\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","   141/299      3.3G      2.32      4.07     0.444      6.84        65        64: 100% 87/87 [01:42<00:00,  1.18s/it]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 22/22 [00:08<00:00,  2.54it/s]\n","                 all       692  3.06e+03    0.0409    0.0513    0.0075    0.0447\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","   142/299      3.3G      2.39      3.98     0.502      6.88        59        64: 100% 87/87 [01:44<00:00,  1.20s/it]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 22/22 [00:08<00:00,  2.55it/s]\n","                 all       692  3.06e+03    0.0454    0.0559   0.00833     0.049\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","   143/299      3.3G       2.3      3.92     0.466      6.69        64        64: 100% 87/87 [01:45<00:00,  1.21s/it]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 22/22 [00:08<00:00,  2.55it/s]\n","                 all       692  3.06e+03    0.0448    0.0539   0.00904    0.0481\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","   144/299      3.3G      2.34      4.03     0.445      6.81        57        64: 100% 87/87 [01:43<00:00,  1.19s/it]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 22/22 [00:08<00:00,  2.52it/s]\n","                 all       692  3.06e+03    0.0441    0.0515   0.00723    0.0466\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","   145/299      3.3G      2.44      3.99     0.567      6.99        79        64: 100% 87/87 [01:44<00:00,  1.20s/it]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 22/22 [00:08<00:00,  2.53it/s]\n","                 all       692  3.06e+03    0.0387    0.0491   0.00677    0.0422\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","   146/299      3.3G       2.4      4.02     0.405      6.82        70        64: 100% 87/87 [01:44<00:00,  1.20s/it]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 22/22 [00:08<00:00,  2.56it/s]\n","                 all       692  3.06e+03    0.0413    0.0518   0.00734    0.0448\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","   147/299      3.3G      2.29      4.01     0.428      6.73        81        64: 100% 87/87 [01:43<00:00,  1.19s/it]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 22/22 [00:08<00:00,  2.56it/s]\n","                 all       692  3.06e+03    0.0422    0.0505   0.00749     0.045\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","   148/299      3.3G      2.45      3.99     0.406      6.85        77        64: 100% 87/87 [01:44<00:00,  1.20s/it]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 22/22 [00:08<00:00,  2.53it/s]\n","                 all       692  3.06e+03    0.0417    0.0533   0.00761    0.0455\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","   149/299      3.3G      2.32      3.88     0.397       6.6        85        64: 100% 87/87 [01:44<00:00,  1.20s/it]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 22/22 [00:08<00:00,  2.51it/s]\n","                 all       692  3.06e+03    0.0434    0.0517   0.00741    0.0465\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","   150/299      3.3G      2.28      3.97     0.417      6.66        41        64: 100% 87/87 [01:45<00:00,  1.22s/it]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 22/22 [00:08<00:00,  2.53it/s]\n","                 all       692  3.06e+03    0.0376    0.0477   0.00727    0.0411\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","   151/299      3.3G      2.17      4.03     0.434      6.63        59        64: 100% 87/87 [01:45<00:00,  1.21s/it]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 22/22 [00:08<00:00,  2.52it/s]\n","                 all       692  3.06e+03    0.0382    0.0486   0.00782    0.0418\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","   152/299      3.3G      2.22      3.88     0.392      6.49        67        64: 100% 87/87 [01:45<00:00,  1.21s/it]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 22/22 [00:08<00:00,  2.51it/s]\n","                 all       692  3.06e+03    0.0433    0.0528    0.0086    0.0466\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","   153/299      3.3G      2.19      3.94      0.41      6.54        60        64: 100% 87/87 [01:45<00:00,  1.21s/it]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 22/22 [00:08<00:00,  2.53it/s]\n","                 all       692  3.06e+03    0.0375    0.0492   0.00662    0.0416\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","   154/299      3.3G      2.45      3.91     0.395      6.76        46        64: 100% 87/87 [01:43<00:00,  1.19s/it]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 22/22 [00:08<00:00,  2.57it/s]\n","                 all       692  3.06e+03    0.0375    0.0491   0.00816    0.0416\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","   155/299      3.3G      2.29       3.9     0.386      6.58        65        64: 100% 87/87 [01:44<00:00,  1.20s/it]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 22/22 [00:08<00:00,  2.56it/s]\n","                 all       692  3.06e+03    0.0402    0.0504   0.00873     0.044\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","   156/299      3.3G       2.1      3.91     0.381       6.4        45        64: 100% 87/87 [01:44<00:00,  1.20s/it]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 22/22 [00:08<00:00,  2.52it/s]\n","                 all       692  3.06e+03    0.0385    0.0474   0.00651    0.0415\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","   157/299      3.3G      2.09       3.8     0.372      6.27       120        64:   9% 8/87 [00:10<01:17,  1.03it/s]"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"CWWxUVoe9YqR"},"source":["## Training yolo branch only by freezing the midas layers on 128x128 resolution"]},{"cell_type":"code","metadata":{"id":"ZzrbaR8PVgo6","colab":{"base_uri":"https://localhost:8080/"},"outputId":"751d70a0-8a1b-40b8-9ccd-4288cc6a2331"},"source":["## Ignore the model summary in the below output - as it is summary on dummy input (3, 416,416) and before freezing the midas layers. But you can observe img_size attribute though as 128.\n","# Training yolo branch only by freezing the midas layers on 128x128 resolution\n","!python train.py --data data/customdata/custom.data --batch 16  --cache --cfg cfg/yolov3-custom.cfg --epochs 300 --weights 'weights/best.pt'  --img-size=128 --midasnet_freeze='True'"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Namespace(accumulate=4, adam=False, batch_size=16, bucket='', cache_images=True, cfg='cfg/yolov3-custom.cfg', data='data/customdata/custom.data', device='', epochs=300, evolve=False, img_size=[128], init_train='False', midas_weights='', midasnet_freeze='True', multi_scale=False, name='', nosave=False, notest=False, rect=False, resume=False, single_cls=False, weights='weights/best.pt', yolo_weights='')\n","Using CUDA device0 _CudaDeviceProperties(name='Tesla P100-PCIE-16GB', total_memory=16280MB)\n","\n","2020-11-14 10:39:45.785315: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n","Run 'tensorboard --logdir=runs' to view tensorboard at http://localhost:6006/\n","cfg - cfg/yolov3-custom.cfg\n","data - data/customdata/custom.data\n","epochs - 300\n","batch_size - 16\n","accumulate - 4\n","yolo weights - \n","midas weights - \n","imgsz_min- 128, imgsz_max- 128, imgsz_test- 128\n","opt.rect - False\n","train_path - data/customdata/train.txt\n","test_path - data/customdata/test.txt\n","init_train - False\n","weights - weights/best.pt\n","midasnet_freeze - True\n","Using cache found in /root/.cache/torch/hub/facebookresearch_WSL-Images_master\n","Caching labels (2623 found, 114 missing, 30 empty, 0 duplicate, for 2767 images): 100% 2767/2767 [00:03<00:00, 795.78it/s]\n","Caching images (0.1GB): 100% 2767/2767 [01:30<00:00, 30.51it/s]\n","Caching labels (657 found, 27 missing, 8 empty, 0 duplicate, for 692 images): 100% 692/692 [00:01<00:00, 632.46it/s]\n","Caching images (0.0GB): 100% 692/692 [00:23<00:00, 29.03it/s]\n","Freezing the midasnet\n","YMP Model Summary\n","----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","            Conv2d-1         [-1, 64, 208, 208]           9,408\n","       BatchNorm2d-2         [-1, 64, 208, 208]             128\n","              ReLU-3         [-1, 64, 208, 208]               0\n","         MaxPool2d-4         [-1, 64, 104, 104]               0\n","            Conv2d-5        [-1, 256, 104, 104]          16,384\n","       BatchNorm2d-6        [-1, 256, 104, 104]             512\n","              ReLU-7        [-1, 256, 104, 104]               0\n","            Conv2d-8        [-1, 256, 104, 104]          18,432\n","       BatchNorm2d-9        [-1, 256, 104, 104]             512\n","             ReLU-10        [-1, 256, 104, 104]               0\n","           Conv2d-11        [-1, 256, 104, 104]          65,536\n","      BatchNorm2d-12        [-1, 256, 104, 104]             512\n","           Conv2d-13        [-1, 256, 104, 104]          16,384\n","      BatchNorm2d-14        [-1, 256, 104, 104]             512\n","             ReLU-15        [-1, 256, 104, 104]               0\n","       Bottleneck-16        [-1, 256, 104, 104]               0\n","           Conv2d-17        [-1, 256, 104, 104]          65,536\n","      BatchNorm2d-18        [-1, 256, 104, 104]             512\n","             ReLU-19        [-1, 256, 104, 104]               0\n","           Conv2d-20        [-1, 256, 104, 104]          18,432\n","      BatchNorm2d-21        [-1, 256, 104, 104]             512\n","             ReLU-22        [-1, 256, 104, 104]               0\n","           Conv2d-23        [-1, 256, 104, 104]          65,536\n","      BatchNorm2d-24        [-1, 256, 104, 104]             512\n","             ReLU-25        [-1, 256, 104, 104]               0\n","       Bottleneck-26        [-1, 256, 104, 104]               0\n","           Conv2d-27        [-1, 256, 104, 104]          65,536\n","      BatchNorm2d-28        [-1, 256, 104, 104]             512\n","             ReLU-29        [-1, 256, 104, 104]               0\n","           Conv2d-30        [-1, 256, 104, 104]          18,432\n","      BatchNorm2d-31        [-1, 256, 104, 104]             512\n","             ReLU-32        [-1, 256, 104, 104]               0\n","           Conv2d-33        [-1, 256, 104, 104]          65,536\n","      BatchNorm2d-34        [-1, 256, 104, 104]             512\n","             ReLU-35        [-1, 256, 104, 104]               0\n","       Bottleneck-36        [-1, 256, 104, 104]               0\n","           Conv2d-37        [-1, 512, 104, 104]         131,072\n","      BatchNorm2d-38        [-1, 512, 104, 104]           1,024\n","             ReLU-39        [-1, 512, 104, 104]               0\n","           Conv2d-40          [-1, 512, 52, 52]          73,728\n","      BatchNorm2d-41          [-1, 512, 52, 52]           1,024\n","             ReLU-42          [-1, 512, 52, 52]               0\n","           Conv2d-43          [-1, 512, 52, 52]         262,144\n","      BatchNorm2d-44          [-1, 512, 52, 52]           1,024\n","           Conv2d-45          [-1, 512, 52, 52]         131,072\n","      BatchNorm2d-46          [-1, 512, 52, 52]           1,024\n","             ReLU-47          [-1, 512, 52, 52]               0\n","       Bottleneck-48          [-1, 512, 52, 52]               0\n","           Conv2d-49          [-1, 512, 52, 52]         262,144\n","      BatchNorm2d-50          [-1, 512, 52, 52]           1,024\n","             ReLU-51          [-1, 512, 52, 52]               0\n","           Conv2d-52          [-1, 512, 52, 52]          73,728\n","      BatchNorm2d-53          [-1, 512, 52, 52]           1,024\n","             ReLU-54          [-1, 512, 52, 52]               0\n","           Conv2d-55          [-1, 512, 52, 52]         262,144\n","      BatchNorm2d-56          [-1, 512, 52, 52]           1,024\n","             ReLU-57          [-1, 512, 52, 52]               0\n","       Bottleneck-58          [-1, 512, 52, 52]               0\n","           Conv2d-59          [-1, 512, 52, 52]         262,144\n","      BatchNorm2d-60          [-1, 512, 52, 52]           1,024\n","             ReLU-61          [-1, 512, 52, 52]               0\n","           Conv2d-62          [-1, 512, 52, 52]          73,728\n","      BatchNorm2d-63          [-1, 512, 52, 52]           1,024\n","             ReLU-64          [-1, 512, 52, 52]               0\n","           Conv2d-65          [-1, 512, 52, 52]         262,144\n","      BatchNorm2d-66          [-1, 512, 52, 52]           1,024\n","             ReLU-67          [-1, 512, 52, 52]               0\n","       Bottleneck-68          [-1, 512, 52, 52]               0\n","           Conv2d-69          [-1, 512, 52, 52]         262,144\n","      BatchNorm2d-70          [-1, 512, 52, 52]           1,024\n","             ReLU-71          [-1, 512, 52, 52]               0\n","           Conv2d-72          [-1, 512, 52, 52]          73,728\n","      BatchNorm2d-73          [-1, 512, 52, 52]           1,024\n","             ReLU-74          [-1, 512, 52, 52]               0\n","           Conv2d-75          [-1, 512, 52, 52]         262,144\n","      BatchNorm2d-76          [-1, 512, 52, 52]           1,024\n","             ReLU-77          [-1, 512, 52, 52]               0\n","       Bottleneck-78          [-1, 512, 52, 52]               0\n","           Conv2d-79         [-1, 1024, 52, 52]         524,288\n","      BatchNorm2d-80         [-1, 1024, 52, 52]           2,048\n","             ReLU-81         [-1, 1024, 52, 52]               0\n","           Conv2d-82         [-1, 1024, 26, 26]         294,912\n","      BatchNorm2d-83         [-1, 1024, 26, 26]           2,048\n","             ReLU-84         [-1, 1024, 26, 26]               0\n","           Conv2d-85         [-1, 1024, 26, 26]       1,048,576\n","      BatchNorm2d-86         [-1, 1024, 26, 26]           2,048\n","           Conv2d-87         [-1, 1024, 26, 26]         524,288\n","      BatchNorm2d-88         [-1, 1024, 26, 26]           2,048\n","             ReLU-89         [-1, 1024, 26, 26]               0\n","       Bottleneck-90         [-1, 1024, 26, 26]               0\n","           Conv2d-91         [-1, 1024, 26, 26]       1,048,576\n","      BatchNorm2d-92         [-1, 1024, 26, 26]           2,048\n","             ReLU-93         [-1, 1024, 26, 26]               0\n","           Conv2d-94         [-1, 1024, 26, 26]         294,912\n","      BatchNorm2d-95         [-1, 1024, 26, 26]           2,048\n","             ReLU-96         [-1, 1024, 26, 26]               0\n","           Conv2d-97         [-1, 1024, 26, 26]       1,048,576\n","      BatchNorm2d-98         [-1, 1024, 26, 26]           2,048\n","             ReLU-99         [-1, 1024, 26, 26]               0\n","      Bottleneck-100         [-1, 1024, 26, 26]               0\n","          Conv2d-101         [-1, 1024, 26, 26]       1,048,576\n","     BatchNorm2d-102         [-1, 1024, 26, 26]           2,048\n","            ReLU-103         [-1, 1024, 26, 26]               0\n","          Conv2d-104         [-1, 1024, 26, 26]         294,912\n","     BatchNorm2d-105         [-1, 1024, 26, 26]           2,048\n","            ReLU-106         [-1, 1024, 26, 26]               0\n","          Conv2d-107         [-1, 1024, 26, 26]       1,048,576\n","     BatchNorm2d-108         [-1, 1024, 26, 26]           2,048\n","            ReLU-109         [-1, 1024, 26, 26]               0\n","      Bottleneck-110         [-1, 1024, 26, 26]               0\n","          Conv2d-111         [-1, 1024, 26, 26]       1,048,576\n","     BatchNorm2d-112         [-1, 1024, 26, 26]           2,048\n","            ReLU-113         [-1, 1024, 26, 26]               0\n","          Conv2d-114         [-1, 1024, 26, 26]         294,912\n","     BatchNorm2d-115         [-1, 1024, 26, 26]           2,048\n","            ReLU-116         [-1, 1024, 26, 26]               0\n","          Conv2d-117         [-1, 1024, 26, 26]       1,048,576\n","     BatchNorm2d-118         [-1, 1024, 26, 26]           2,048\n","            ReLU-119         [-1, 1024, 26, 26]               0\n","      Bottleneck-120         [-1, 1024, 26, 26]               0\n","          Conv2d-121         [-1, 1024, 26, 26]       1,048,576\n","     BatchNorm2d-122         [-1, 1024, 26, 26]           2,048\n","            ReLU-123         [-1, 1024, 26, 26]               0\n","          Conv2d-124         [-1, 1024, 26, 26]         294,912\n","     BatchNorm2d-125         [-1, 1024, 26, 26]           2,048\n","            ReLU-126         [-1, 1024, 26, 26]               0\n","          Conv2d-127         [-1, 1024, 26, 26]       1,048,576\n","     BatchNorm2d-128         [-1, 1024, 26, 26]           2,048\n","            ReLU-129         [-1, 1024, 26, 26]               0\n","      Bottleneck-130         [-1, 1024, 26, 26]               0\n","          Conv2d-131         [-1, 1024, 26, 26]       1,048,576\n","     BatchNorm2d-132         [-1, 1024, 26, 26]           2,048\n","            ReLU-133         [-1, 1024, 26, 26]               0\n","          Conv2d-134         [-1, 1024, 26, 26]         294,912\n","     BatchNorm2d-135         [-1, 1024, 26, 26]           2,048\n","            ReLU-136         [-1, 1024, 26, 26]               0\n","          Conv2d-137         [-1, 1024, 26, 26]       1,048,576\n","     BatchNorm2d-138         [-1, 1024, 26, 26]           2,048\n","            ReLU-139         [-1, 1024, 26, 26]               0\n","      Bottleneck-140         [-1, 1024, 26, 26]               0\n","          Conv2d-141         [-1, 1024, 26, 26]       1,048,576\n","     BatchNorm2d-142         [-1, 1024, 26, 26]           2,048\n","            ReLU-143         [-1, 1024, 26, 26]               0\n","          Conv2d-144         [-1, 1024, 26, 26]         294,912\n","     BatchNorm2d-145         [-1, 1024, 26, 26]           2,048\n","            ReLU-146         [-1, 1024, 26, 26]               0\n","          Conv2d-147         [-1, 1024, 26, 26]       1,048,576\n","     BatchNorm2d-148         [-1, 1024, 26, 26]           2,048\n","            ReLU-149         [-1, 1024, 26, 26]               0\n","      Bottleneck-150         [-1, 1024, 26, 26]               0\n","          Conv2d-151         [-1, 1024, 26, 26]       1,048,576\n","     BatchNorm2d-152         [-1, 1024, 26, 26]           2,048\n","            ReLU-153         [-1, 1024, 26, 26]               0\n","          Conv2d-154         [-1, 1024, 26, 26]         294,912\n","     BatchNorm2d-155         [-1, 1024, 26, 26]           2,048\n","            ReLU-156         [-1, 1024, 26, 26]               0\n","          Conv2d-157         [-1, 1024, 26, 26]       1,048,576\n","     BatchNorm2d-158         [-1, 1024, 26, 26]           2,048\n","            ReLU-159         [-1, 1024, 26, 26]               0\n","      Bottleneck-160         [-1, 1024, 26, 26]               0\n","          Conv2d-161         [-1, 1024, 26, 26]       1,048,576\n","     BatchNorm2d-162         [-1, 1024, 26, 26]           2,048\n","            ReLU-163         [-1, 1024, 26, 26]               0\n","          Conv2d-164         [-1, 1024, 26, 26]         294,912\n","     BatchNorm2d-165         [-1, 1024, 26, 26]           2,048\n","            ReLU-166         [-1, 1024, 26, 26]               0\n","          Conv2d-167         [-1, 1024, 26, 26]       1,048,576\n","     BatchNorm2d-168         [-1, 1024, 26, 26]           2,048\n","            ReLU-169         [-1, 1024, 26, 26]               0\n","      Bottleneck-170         [-1, 1024, 26, 26]               0\n","          Conv2d-171         [-1, 1024, 26, 26]       1,048,576\n","     BatchNorm2d-172         [-1, 1024, 26, 26]           2,048\n","            ReLU-173         [-1, 1024, 26, 26]               0\n","          Conv2d-174         [-1, 1024, 26, 26]         294,912\n","     BatchNorm2d-175         [-1, 1024, 26, 26]           2,048\n","            ReLU-176         [-1, 1024, 26, 26]               0\n","          Conv2d-177         [-1, 1024, 26, 26]       1,048,576\n","     BatchNorm2d-178         [-1, 1024, 26, 26]           2,048\n","            ReLU-179         [-1, 1024, 26, 26]               0\n","      Bottleneck-180         [-1, 1024, 26, 26]               0\n","          Conv2d-181         [-1, 1024, 26, 26]       1,048,576\n","     BatchNorm2d-182         [-1, 1024, 26, 26]           2,048\n","            ReLU-183         [-1, 1024, 26, 26]               0\n","          Conv2d-184         [-1, 1024, 26, 26]         294,912\n","     BatchNorm2d-185         [-1, 1024, 26, 26]           2,048\n","            ReLU-186         [-1, 1024, 26, 26]               0\n","          Conv2d-187         [-1, 1024, 26, 26]       1,048,576\n","     BatchNorm2d-188         [-1, 1024, 26, 26]           2,048\n","            ReLU-189         [-1, 1024, 26, 26]               0\n","      Bottleneck-190         [-1, 1024, 26, 26]               0\n","          Conv2d-191         [-1, 1024, 26, 26]       1,048,576\n","     BatchNorm2d-192         [-1, 1024, 26, 26]           2,048\n","            ReLU-193         [-1, 1024, 26, 26]               0\n","          Conv2d-194         [-1, 1024, 26, 26]         294,912\n","     BatchNorm2d-195         [-1, 1024, 26, 26]           2,048\n","            ReLU-196         [-1, 1024, 26, 26]               0\n","          Conv2d-197         [-1, 1024, 26, 26]       1,048,576\n","     BatchNorm2d-198         [-1, 1024, 26, 26]           2,048\n","            ReLU-199         [-1, 1024, 26, 26]               0\n","      Bottleneck-200         [-1, 1024, 26, 26]               0\n","          Conv2d-201         [-1, 1024, 26, 26]       1,048,576\n","     BatchNorm2d-202         [-1, 1024, 26, 26]           2,048\n","            ReLU-203         [-1, 1024, 26, 26]               0\n","          Conv2d-204         [-1, 1024, 26, 26]         294,912\n","     BatchNorm2d-205         [-1, 1024, 26, 26]           2,048\n","            ReLU-206         [-1, 1024, 26, 26]               0\n","          Conv2d-207         [-1, 1024, 26, 26]       1,048,576\n","     BatchNorm2d-208         [-1, 1024, 26, 26]           2,048\n","            ReLU-209         [-1, 1024, 26, 26]               0\n","      Bottleneck-210         [-1, 1024, 26, 26]               0\n","          Conv2d-211         [-1, 1024, 26, 26]       1,048,576\n","     BatchNorm2d-212         [-1, 1024, 26, 26]           2,048\n","            ReLU-213         [-1, 1024, 26, 26]               0\n","          Conv2d-214         [-1, 1024, 26, 26]         294,912\n","     BatchNorm2d-215         [-1, 1024, 26, 26]           2,048\n","            ReLU-216         [-1, 1024, 26, 26]               0\n","          Conv2d-217         [-1, 1024, 26, 26]       1,048,576\n","     BatchNorm2d-218         [-1, 1024, 26, 26]           2,048\n","            ReLU-219         [-1, 1024, 26, 26]               0\n","      Bottleneck-220         [-1, 1024, 26, 26]               0\n","          Conv2d-221         [-1, 1024, 26, 26]       1,048,576\n","     BatchNorm2d-222         [-1, 1024, 26, 26]           2,048\n","            ReLU-223         [-1, 1024, 26, 26]               0\n","          Conv2d-224         [-1, 1024, 26, 26]         294,912\n","     BatchNorm2d-225         [-1, 1024, 26, 26]           2,048\n","            ReLU-226         [-1, 1024, 26, 26]               0\n","          Conv2d-227         [-1, 1024, 26, 26]       1,048,576\n","     BatchNorm2d-228         [-1, 1024, 26, 26]           2,048\n","            ReLU-229         [-1, 1024, 26, 26]               0\n","      Bottleneck-230         [-1, 1024, 26, 26]               0\n","          Conv2d-231         [-1, 1024, 26, 26]       1,048,576\n","     BatchNorm2d-232         [-1, 1024, 26, 26]           2,048\n","            ReLU-233         [-1, 1024, 26, 26]               0\n","          Conv2d-234         [-1, 1024, 26, 26]         294,912\n","     BatchNorm2d-235         [-1, 1024, 26, 26]           2,048\n","            ReLU-236         [-1, 1024, 26, 26]               0\n","          Conv2d-237         [-1, 1024, 26, 26]       1,048,576\n","     BatchNorm2d-238         [-1, 1024, 26, 26]           2,048\n","            ReLU-239         [-1, 1024, 26, 26]               0\n","      Bottleneck-240         [-1, 1024, 26, 26]               0\n","          Conv2d-241         [-1, 1024, 26, 26]       1,048,576\n","     BatchNorm2d-242         [-1, 1024, 26, 26]           2,048\n","            ReLU-243         [-1, 1024, 26, 26]               0\n","          Conv2d-244         [-1, 1024, 26, 26]         294,912\n","     BatchNorm2d-245         [-1, 1024, 26, 26]           2,048\n","            ReLU-246         [-1, 1024, 26, 26]               0\n","          Conv2d-247         [-1, 1024, 26, 26]       1,048,576\n","     BatchNorm2d-248         [-1, 1024, 26, 26]           2,048\n","            ReLU-249         [-1, 1024, 26, 26]               0\n","      Bottleneck-250         [-1, 1024, 26, 26]               0\n","          Conv2d-251         [-1, 1024, 26, 26]       1,048,576\n","     BatchNorm2d-252         [-1, 1024, 26, 26]           2,048\n","            ReLU-253         [-1, 1024, 26, 26]               0\n","          Conv2d-254         [-1, 1024, 26, 26]         294,912\n","     BatchNorm2d-255         [-1, 1024, 26, 26]           2,048\n","            ReLU-256         [-1, 1024, 26, 26]               0\n","          Conv2d-257         [-1, 1024, 26, 26]       1,048,576\n","     BatchNorm2d-258         [-1, 1024, 26, 26]           2,048\n","            ReLU-259         [-1, 1024, 26, 26]               0\n","      Bottleneck-260         [-1, 1024, 26, 26]               0\n","          Conv2d-261         [-1, 1024, 26, 26]       1,048,576\n","     BatchNorm2d-262         [-1, 1024, 26, 26]           2,048\n","            ReLU-263         [-1, 1024, 26, 26]               0\n","          Conv2d-264         [-1, 1024, 26, 26]         294,912\n","     BatchNorm2d-265         [-1, 1024, 26, 26]           2,048\n","            ReLU-266         [-1, 1024, 26, 26]               0\n","          Conv2d-267         [-1, 1024, 26, 26]       1,048,576\n","     BatchNorm2d-268         [-1, 1024, 26, 26]           2,048\n","            ReLU-269         [-1, 1024, 26, 26]               0\n","      Bottleneck-270         [-1, 1024, 26, 26]               0\n","          Conv2d-271         [-1, 1024, 26, 26]       1,048,576\n","     BatchNorm2d-272         [-1, 1024, 26, 26]           2,048\n","            ReLU-273         [-1, 1024, 26, 26]               0\n","          Conv2d-274         [-1, 1024, 26, 26]         294,912\n","     BatchNorm2d-275         [-1, 1024, 26, 26]           2,048\n","            ReLU-276         [-1, 1024, 26, 26]               0\n","          Conv2d-277         [-1, 1024, 26, 26]       1,048,576\n","     BatchNorm2d-278         [-1, 1024, 26, 26]           2,048\n","            ReLU-279         [-1, 1024, 26, 26]               0\n","      Bottleneck-280         [-1, 1024, 26, 26]               0\n","          Conv2d-281         [-1, 1024, 26, 26]       1,048,576\n","     BatchNorm2d-282         [-1, 1024, 26, 26]           2,048\n","            ReLU-283         [-1, 1024, 26, 26]               0\n","          Conv2d-284         [-1, 1024, 26, 26]         294,912\n","     BatchNorm2d-285         [-1, 1024, 26, 26]           2,048\n","            ReLU-286         [-1, 1024, 26, 26]               0\n","          Conv2d-287         [-1, 1024, 26, 26]       1,048,576\n","     BatchNorm2d-288         [-1, 1024, 26, 26]           2,048\n","            ReLU-289         [-1, 1024, 26, 26]               0\n","      Bottleneck-290         [-1, 1024, 26, 26]               0\n","          Conv2d-291         [-1, 1024, 26, 26]       1,048,576\n","     BatchNorm2d-292         [-1, 1024, 26, 26]           2,048\n","            ReLU-293         [-1, 1024, 26, 26]               0\n","          Conv2d-294         [-1, 1024, 26, 26]         294,912\n","     BatchNorm2d-295         [-1, 1024, 26, 26]           2,048\n","            ReLU-296         [-1, 1024, 26, 26]               0\n","          Conv2d-297         [-1, 1024, 26, 26]       1,048,576\n","     BatchNorm2d-298         [-1, 1024, 26, 26]           2,048\n","            ReLU-299         [-1, 1024, 26, 26]               0\n","      Bottleneck-300         [-1, 1024, 26, 26]               0\n","          Conv2d-301         [-1, 1024, 26, 26]       1,048,576\n","     BatchNorm2d-302         [-1, 1024, 26, 26]           2,048\n","            ReLU-303         [-1, 1024, 26, 26]               0\n","          Conv2d-304         [-1, 1024, 26, 26]         294,912\n","     BatchNorm2d-305         [-1, 1024, 26, 26]           2,048\n","            ReLU-306         [-1, 1024, 26, 26]               0\n","          Conv2d-307         [-1, 1024, 26, 26]       1,048,576\n","     BatchNorm2d-308         [-1, 1024, 26, 26]           2,048\n","            ReLU-309         [-1, 1024, 26, 26]               0\n","      Bottleneck-310         [-1, 1024, 26, 26]               0\n","          Conv2d-311         [-1, 2048, 26, 26]       2,097,152\n","     BatchNorm2d-312         [-1, 2048, 26, 26]           4,096\n","            ReLU-313         [-1, 2048, 26, 26]               0\n","          Conv2d-314         [-1, 2048, 13, 13]       1,179,648\n","     BatchNorm2d-315         [-1, 2048, 13, 13]           4,096\n","            ReLU-316         [-1, 2048, 13, 13]               0\n","          Conv2d-317         [-1, 2048, 13, 13]       4,194,304\n","     BatchNorm2d-318         [-1, 2048, 13, 13]           4,096\n","          Conv2d-319         [-1, 2048, 13, 13]       2,097,152\n","     BatchNorm2d-320         [-1, 2048, 13, 13]           4,096\n","            ReLU-321         [-1, 2048, 13, 13]               0\n","      Bottleneck-322         [-1, 2048, 13, 13]               0\n","          Conv2d-323         [-1, 2048, 13, 13]       4,194,304\n","     BatchNorm2d-324         [-1, 2048, 13, 13]           4,096\n","            ReLU-325         [-1, 2048, 13, 13]               0\n","          Conv2d-326         [-1, 2048, 13, 13]       1,179,648\n","     BatchNorm2d-327         [-1, 2048, 13, 13]           4,096\n","            ReLU-328         [-1, 2048, 13, 13]               0\n","          Conv2d-329         [-1, 2048, 13, 13]       4,194,304\n","     BatchNorm2d-330         [-1, 2048, 13, 13]           4,096\n","            ReLU-331         [-1, 2048, 13, 13]               0\n","      Bottleneck-332         [-1, 2048, 13, 13]               0\n","          Conv2d-333         [-1, 2048, 13, 13]       4,194,304\n","     BatchNorm2d-334         [-1, 2048, 13, 13]           4,096\n","            ReLU-335         [-1, 2048, 13, 13]               0\n","          Conv2d-336         [-1, 2048, 13, 13]       1,179,648\n","     BatchNorm2d-337         [-1, 2048, 13, 13]           4,096\n","            ReLU-338         [-1, 2048, 13, 13]               0\n","          Conv2d-339         [-1, 2048, 13, 13]       4,194,304\n","     BatchNorm2d-340         [-1, 2048, 13, 13]           4,096\n","            ReLU-341         [-1, 2048, 13, 13]               0\n","      Bottleneck-342         [-1, 2048, 13, 13]               0\n","          Conv2d-343        [-1, 256, 104, 104]         589,824\n","          Conv2d-344          [-1, 256, 52, 52]       1,179,648\n","          Conv2d-345          [-1, 256, 26, 26]       2,359,296\n","          Conv2d-346          [-1, 256, 13, 13]       4,718,592\n","            ReLU-347          [-1, 256, 13, 13]               0\n","          Conv2d-348          [-1, 256, 13, 13]         590,080\n","            ReLU-349          [-1, 256, 13, 13]               0\n","          Conv2d-350          [-1, 256, 13, 13]         590,080\n","ResidualConvUnit-351          [-1, 256, 13, 13]               0\n","FeatureFusionBlock-352          [-1, 256, 26, 26]               0\n","            ReLU-353          [-1, 256, 26, 26]               0\n","          Conv2d-354          [-1, 256, 26, 26]         590,080\n","            ReLU-355          [-1, 256, 26, 26]               0\n","          Conv2d-356          [-1, 256, 26, 26]         590,080\n","ResidualConvUnit-357          [-1, 256, 26, 26]               0\n","            ReLU-358          [-1, 256, 26, 26]               0\n","          Conv2d-359          [-1, 256, 26, 26]         590,080\n","            ReLU-360          [-1, 256, 26, 26]               0\n","          Conv2d-361          [-1, 256, 26, 26]         590,080\n","ResidualConvUnit-362          [-1, 256, 26, 26]               0\n","FeatureFusionBlock-363          [-1, 256, 52, 52]               0\n","            ReLU-364          [-1, 256, 52, 52]               0\n","          Conv2d-365          [-1, 256, 52, 52]         590,080\n","            ReLU-366          [-1, 256, 52, 52]               0\n","          Conv2d-367          [-1, 256, 52, 52]         590,080\n","ResidualConvUnit-368          [-1, 256, 52, 52]               0\n","            ReLU-369          [-1, 256, 52, 52]               0\n","          Conv2d-370          [-1, 256, 52, 52]         590,080\n","            ReLU-371          [-1, 256, 52, 52]               0\n","          Conv2d-372          [-1, 256, 52, 52]         590,080\n","ResidualConvUnit-373          [-1, 256, 52, 52]               0\n","FeatureFusionBlock-374        [-1, 256, 104, 104]               0\n","            ReLU-375        [-1, 256, 104, 104]               0\n","          Conv2d-376        [-1, 256, 104, 104]         590,080\n","            ReLU-377        [-1, 256, 104, 104]               0\n","          Conv2d-378        [-1, 256, 104, 104]         590,080\n","ResidualConvUnit-379        [-1, 256, 104, 104]               0\n","            ReLU-380        [-1, 256, 104, 104]               0\n","          Conv2d-381        [-1, 256, 104, 104]         590,080\n","            ReLU-382        [-1, 256, 104, 104]               0\n","          Conv2d-383        [-1, 256, 104, 104]         590,080\n","ResidualConvUnit-384        [-1, 256, 104, 104]               0\n","FeatureFusionBlock-385        [-1, 256, 208, 208]               0\n","          Conv2d-386        [-1, 128, 208, 208]         295,040\n","     Interpolate-387        [-1, 128, 416, 416]               0\n","          Conv2d-388         [-1, 32, 416, 416]          36,896\n","            ReLU-389         [-1, 32, 416, 416]               0\n","          Conv2d-390          [-1, 1, 416, 416]              33\n","            ReLU-391          [-1, 1, 416, 416]               0\n","          Conv2d-392        [-1, 256, 208, 208]           6,912\n","     BatchNorm2d-393        [-1, 256, 208, 208]             512\n","            ReLU-394        [-1, 256, 208, 208]               0\n","          Conv2d-395        [-1, 256, 104, 104]         589,824\n","     BatchNorm2d-396        [-1, 256, 104, 104]             512\n","            ReLU-397        [-1, 256, 104, 104]               0\n","          Conv2d-398          [-1, 256, 52, 52]         589,824\n","     BatchNorm2d-399          [-1, 256, 52, 52]             512\n","            ReLU-400          [-1, 256, 52, 52]               0\n","          Conv2d-401          [-1, 512, 26, 26]       1,179,648\n","     BatchNorm2d-402          [-1, 512, 26, 26]           1,024\n","            ReLU-403          [-1, 512, 26, 26]               0\n","          Conv2d-404         [-1, 1024, 13, 13]       4,718,592\n","     BatchNorm2d-405         [-1, 1024, 13, 13]           2,048\n","            ReLU-406         [-1, 1024, 13, 13]               0\n","          Conv2d-407         [-1, 1024, 13, 13]       2,097,152\n","     BatchNorm2d-408         [-1, 1024, 13, 13]           2,048\n","            ReLU-409         [-1, 1024, 13, 13]               0\n","          Conv2d-410           [-1, 27, 13, 13]          27,675\n","       YOLOLayer-411         [-1, 3, 13, 13, 9]               0\n","     Interpolate-412         [-1, 1024, 26, 26]               0\n","          Conv2d-413          [-1, 256, 26, 26]         262,144\n","     BatchNorm2d-414          [-1, 256, 26, 26]             512\n","            ReLU-415          [-1, 256, 26, 26]               0\n","          Conv2d-416          [-1, 512, 26, 26]         524,288\n","     BatchNorm2d-417          [-1, 512, 26, 26]           1,024\n","            ReLU-418          [-1, 512, 26, 26]               0\n","          Conv2d-419          [-1, 256, 26, 26]         196,608\n","     BatchNorm2d-420          [-1, 256, 26, 26]             512\n","            ReLU-421          [-1, 256, 26, 26]               0\n","          Conv2d-422          [-1, 512, 26, 26]       1,179,648\n","     BatchNorm2d-423          [-1, 512, 26, 26]           1,024\n","            ReLU-424          [-1, 512, 26, 26]               0\n","          Conv2d-425          [-1, 256, 26, 26]         131,072\n","     BatchNorm2d-426          [-1, 256, 26, 26]             512\n","            ReLU-427          [-1, 256, 26, 26]               0\n","          Conv2d-428          [-1, 512, 26, 26]       1,179,648\n","     BatchNorm2d-429          [-1, 512, 26, 26]           1,024\n","            ReLU-430          [-1, 512, 26, 26]               0\n","          Conv2d-431          [-1, 256, 26, 26]         131,072\n","     BatchNorm2d-432          [-1, 256, 26, 26]             512\n","            ReLU-433          [-1, 256, 26, 26]               0\n","          Conv2d-434          [-1, 512, 26, 26]       1,179,648\n","     BatchNorm2d-435          [-1, 512, 26, 26]           1,024\n","            ReLU-436          [-1, 512, 26, 26]               0\n","          Conv2d-437           [-1, 27, 26, 26]          13,851\n","       YOLOLayer-438         [-1, 3, 26, 26, 9]               0\n","          Conv2d-439          [-1, 256, 52, 52]         131,072\n","     BatchNorm2d-440          [-1, 256, 52, 52]             512\n","            ReLU-441          [-1, 256, 52, 52]               0\n","     Interpolate-442          [-1, 512, 52, 52]               0\n","          Conv2d-443          [-1, 128, 52, 52]          65,536\n","     BatchNorm2d-444          [-1, 128, 52, 52]             256\n","            ReLU-445          [-1, 128, 52, 52]               0\n","          Conv2d-446          [-1, 128, 52, 52]          49,152\n","     BatchNorm2d-447          [-1, 128, 52, 52]             256\n","            ReLU-448          [-1, 128, 52, 52]               0\n","          Conv2d-449          [-1, 256, 52, 52]         294,912\n","     BatchNorm2d-450          [-1, 256, 52, 52]             512\n","            ReLU-451          [-1, 256, 52, 52]               0\n","          Conv2d-452          [-1, 128, 52, 52]          32,768\n","     BatchNorm2d-453          [-1, 128, 52, 52]             256\n","            ReLU-454          [-1, 128, 52, 52]               0\n","          Conv2d-455          [-1, 256, 52, 52]         294,912\n","     BatchNorm2d-456          [-1, 256, 52, 52]             512\n","            ReLU-457          [-1, 256, 52, 52]               0\n","          Conv2d-458          [-1, 128, 52, 52]          32,768\n","     BatchNorm2d-459          [-1, 128, 52, 52]             256\n","            ReLU-460          [-1, 128, 52, 52]               0\n","          Conv2d-461          [-1, 256, 52, 52]         294,912\n","     BatchNorm2d-462          [-1, 256, 52, 52]             512\n","            ReLU-463          [-1, 256, 52, 52]               0\n","          Conv2d-464           [-1, 27, 52, 52]           6,939\n","       YOLOLayer-465         [-1, 3, 52, 52, 9]               0\n","================================================================\n","Total params: 119,409,234\n","Trainable params: 15,226,449\n","Non-trainable params: 104,182,785\n","----------------------------------------------------------------\n","Input size (MB): 1.98\n","Forward/backward pass size (MB): 3890.44\n","Params size (MB): 455.51\n","Estimated Total Size (MB): 4347.93\n","----------------------------------------------------------------\n","Image sizes 128 - 128 train, 128 test\n","Using 4 dataloader workers\n","Starting training for 300 epochs...\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","  0% 0/173 [00:00<?, ?it/s]/usr/local/lib/python3.6/dist-packages/torch/cuda/memory.py:346: FutureWarning: torch.cuda.memory_cached has been renamed to torch.cuda.memory_reserved\n","  FutureWarning)\n","    86/299     1.72G      5.73      4.32      5.69      15.7        68       128: 100% 173/173 [01:50<00:00,  1.56it/s]\n","               Class    Images   Targets         P         R   mAP@0.5        F1:   0% 0/44 [00:00<?, ?it/s]/content/drive/My Drive/computer_vision/capstone_project/yolo_v3/utils/utils.py:544: UserWarning: This overload of nonzero is deprecated:\n","\tnonzero()\n","Consider using one of the following signatures instead:\n","\tnonzero(*, bool as_tuple) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:882.)\n","  i, j = (x[:, 5:] > conf_thres).nonzero().t()\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 44/44 [00:12<00:00,  3.51it/s]\n","                 all       692  3.06e+03    0.0774     0.165    0.0386     0.103\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","  0% 0/173 [00:00<?, ?it/s]/usr/local/lib/python3.6/dist-packages/torch/cuda/memory.py:346: FutureWarning: torch.cuda.memory_cached has been renamed to torch.cuda.memory_reserved\n","  FutureWarning)\n","    87/299     1.72G      5.61         4      2.87      12.5        89       128: 100% 173/173 [01:51<00:00,  1.55it/s]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 44/44 [00:11<00:00,  3.88it/s]\n","                 all       692  3.06e+03    0.0857     0.179    0.0491     0.113\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","    88/299     1.73G      5.52      3.95      1.86      11.3        79       128: 100% 173/173 [01:52<00:00,  1.54it/s]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 44/44 [00:11<00:00,  3.93it/s]\n","                 all       692  3.06e+03    0.0938     0.182    0.0485     0.121\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","    89/299     1.73G      5.46      3.86      1.44      10.8        76       128: 100% 173/173 [01:50<00:00,  1.57it/s]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 44/44 [00:11<00:00,  3.93it/s]\n","                 all       692  3.06e+03    0.0962     0.197     0.054     0.126\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","    90/299     1.73G      5.36      3.91      1.44      10.7        76       128: 100% 173/173 [01:52<00:00,  1.54it/s]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 44/44 [00:11<00:00,  3.91it/s]\n","                 all       692  3.06e+03    0.0963      0.19    0.0539     0.125\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","    91/299     1.73G      5.32      3.91      1.36      10.6        96       128: 100% 173/173 [01:51<00:00,  1.56it/s]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 44/44 [00:11<00:00,  3.92it/s]\n","                 all       692  3.06e+03     0.102     0.197    0.0544     0.132\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","    92/299     1.73G      5.39      3.85      1.55      10.8        98       128: 100% 173/173 [01:51<00:00,  1.55it/s]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 44/44 [00:11<00:00,  3.84it/s]\n","                 all       692  3.06e+03     0.104     0.199    0.0566     0.134\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","    93/299     1.73G       5.3      3.84      1.21      10.3        71       128: 100% 173/173 [01:53<00:00,  1.52it/s]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 44/44 [00:11<00:00,  3.92it/s]\n","                 all       692  3.06e+03     0.105     0.201    0.0538     0.134\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","    94/299     1.73G      5.25      3.79      1.26      10.3        92       128: 100% 173/173 [01:51<00:00,  1.55it/s]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 44/44 [00:11<00:00,  3.92it/s]\n","                 all       692  3.06e+03     0.111     0.206    0.0661     0.141\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","    95/299     1.73G      5.23      3.74      1.21      10.2        93       128: 100% 173/173 [01:53<00:00,  1.52it/s]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 44/44 [00:11<00:00,  3.89it/s]\n","                 all       692  3.06e+03     0.114     0.217    0.0644     0.147\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","    96/299     1.73G       5.1      3.74      1.22      10.1       112       128: 100% 173/173 [01:52<00:00,  1.53it/s]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 44/44 [00:11<00:00,  3.91it/s]\n","                 all       692  3.06e+03     0.109     0.215    0.0575     0.143\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","    97/299     1.73G       5.3      3.79      1.14      10.2        95       128: 100% 173/173 [01:54<00:00,  1.51it/s]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 44/44 [00:11<00:00,  3.86it/s]\n","                 all       692  3.06e+03      0.11      0.22     0.066     0.144\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","    98/299     1.73G      5.13      3.68      1.14      9.95        94       128: 100% 173/173 [01:54<00:00,  1.52it/s]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 44/44 [00:11<00:00,  3.95it/s]\n","                 all       692  3.06e+03     0.116     0.219    0.0609     0.149\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","    99/299     1.73G      5.02      3.66      1.05      9.73       107       128: 100% 173/173 [01:53<00:00,  1.53it/s]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 44/44 [00:11<00:00,  3.91it/s]\n","                 all       692  3.06e+03     0.113     0.215    0.0568     0.145\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","   100/299     1.73G      5.19       3.6      1.13      9.92        70       128: 100% 173/173 [01:52<00:00,  1.54it/s]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 44/44 [00:11<00:00,  3.93it/s]\n","                 all       692  3.06e+03     0.119     0.221    0.0714     0.153\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","   101/299     1.73G      5.11      3.68      1.05      9.85        53       128: 100% 173/173 [01:53<00:00,  1.53it/s]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 44/44 [00:11<00:00,  3.96it/s]\n","                 all       692  3.06e+03     0.116     0.216    0.0645     0.149\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","   102/299     1.73G      5.03      3.61      1.02      9.66        72       128: 100% 173/173 [01:53<00:00,  1.53it/s]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 44/44 [00:11<00:00,  3.91it/s]\n","                 all       692  3.06e+03     0.117     0.222     0.063     0.151\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","   103/299     1.73G      5.01      3.65       1.1      9.76        86       128: 100% 173/173 [01:52<00:00,  1.54it/s]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 44/44 [00:11<00:00,  3.93it/s]\n","                 all       692  3.06e+03     0.117     0.216    0.0689     0.151\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","   104/299     1.73G      5.08      3.62      1.03      9.72       101       128: 100% 173/173 [01:52<00:00,  1.54it/s]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 44/44 [00:11<00:00,  3.96it/s]\n","                 all       692  3.06e+03     0.116      0.22    0.0663     0.149\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","   105/299     1.73G      5.11      3.62      1.01      9.74        57       128: 100% 173/173 [01:52<00:00,  1.54it/s]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 44/44 [00:11<00:00,  3.93it/s]\n","                 all       692  3.06e+03      0.12      0.23    0.0748     0.156\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","   106/299     1.73G      5.16      3.56      1.03      9.74        80       128: 100% 173/173 [01:51<00:00,  1.55it/s]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 44/44 [00:11<00:00,  3.95it/s]\n","                 all       692  3.06e+03     0.117     0.223    0.0618     0.152\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","   107/299     1.73G      5.05      3.47      1.06      9.59        74       128: 100% 173/173 [01:51<00:00,  1.56it/s]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 44/44 [00:11<00:00,  3.97it/s]\n","                 all       692  3.06e+03     0.115     0.221    0.0661     0.149\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","   108/299     1.73G      5.07      3.52      1.05      9.64        83       128: 100% 173/173 [01:49<00:00,  1.57it/s]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 44/44 [00:11<00:00,  3.98it/s]\n","                 all       692  3.06e+03     0.114     0.223    0.0699     0.149\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","   109/299     1.73G      4.91      3.51       0.9      9.32        87       128: 100% 173/173 [01:50<00:00,  1.57it/s]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 44/44 [00:11<00:00,  4.00it/s]\n","                 all       692  3.06e+03      0.12     0.228    0.0704     0.155\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","   110/299     1.73G      5.06      3.46      1.09      9.61        86       128: 100% 173/173 [01:50<00:00,  1.57it/s]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 44/44 [00:10<00:00,  4.01it/s]\n","                 all       692  3.06e+03     0.119     0.219    0.0684     0.152\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","   111/299     1.73G      4.89       3.5     0.935      9.32        90       128: 100% 173/173 [01:49<00:00,  1.58it/s]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 44/44 [00:11<00:00,  3.89it/s]\n","                 all       692  3.06e+03     0.117     0.226    0.0745     0.152\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","   112/299     1.73G      5.13      3.49      1.12      9.73        86       128: 100% 173/173 [01:57<00:00,  1.47it/s]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 44/44 [00:11<00:00,  3.90it/s]\n","                 all       692  3.06e+03     0.117     0.225    0.0665     0.152\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","   113/299     1.73G      5.09      3.45      0.97      9.51        84       128: 100% 173/173 [01:53<00:00,  1.53it/s]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 44/44 [00:11<00:00,  3.87it/s]\n","                 all       692  3.06e+03     0.121     0.225     0.068     0.156\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","   114/299     1.73G       5.1      3.44      0.88      9.42       101       128: 100% 173/173 [01:53<00:00,  1.53it/s]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 44/44 [00:11<00:00,  3.94it/s]\n","                 all       692  3.06e+03     0.119     0.226    0.0697     0.155\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","   115/299     1.73G      4.93      3.41     0.831      9.18        92       128: 100% 173/173 [01:54<00:00,  1.51it/s]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 44/44 [00:11<00:00,  3.90it/s]\n","                 all       692  3.06e+03     0.125     0.221     0.073     0.158\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","   116/299     1.73G      5.08      3.45     0.852      9.38        94       128: 100% 173/173 [01:54<00:00,  1.51it/s]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 44/44 [00:11<00:00,  3.92it/s]\n","                 all       692  3.06e+03     0.124     0.227    0.0725     0.158\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","   117/299     1.73G       5.2      3.41     0.899      9.51        97       128: 100% 173/173 [01:53<00:00,  1.52it/s]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 44/44 [00:11<00:00,  3.91it/s]\n","                 all       692  3.06e+03     0.117     0.221    0.0655     0.152\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","   118/299     1.73G      5.23      3.27     0.797       9.3        93       128:  14% 24/173 [00:19<01:07,  2.20it/s]"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"ozBMGxbm9cL6"},"source":["## Training yolo branch only by freezing the midas layers on 256x256 resolution"]},{"cell_type":"code","metadata":{"id":"g0-hri_yl_EU","colab":{"base_uri":"https://localhost:8080/"},"outputId":"90f1204a-22a2-42ce-9dc8-3a1fcb3460e3"},"source":["## Correct the model summary in the below output to print on given resolution and after freezing the midas layers. This is perfect model summary\n","# Training yolo branch only by freezing the midas layers on 256x256 resolution\n","!python train.py --data data/customdata/custom.data --batch 8  --cache --cfg cfg/yolov3-custom.cfg --epochs 300 --weights 'weights/best.pt'  --img-size=256 --midasnet_freeze='True'"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Namespace(accumulate=4, adam=False, batch_size=8, bucket='', cache_images=True, cfg='cfg/yolov3-custom.cfg', data='data/customdata/custom.data', device='', epochs=300, evolve=False, img_size=[256], init_train='False', midas_weights='', midasnet_freeze='True', multi_scale=False, name='', nosave=False, notest=False, rect=False, resume=False, single_cls=False, weights='weights/best.pt', yolo_weights='')\n","Using CUDA device0 _CudaDeviceProperties(name='Tesla P100-PCIE-16GB', total_memory=16280MB)\n","\n","2020-11-14 11:53:04.210579: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n","Run 'tensorboard --logdir=runs' to view tensorboard at http://localhost:6006/\n","cfg - cfg/yolov3-custom.cfg\n","data - data/customdata/custom.data\n","epochs - 300\n","batch_size - 8\n","accumulate - 4\n","yolo weights - \n","midas weights - \n","imgsz_min- 256, imgsz_max- 256, imgsz_test- 256\n","opt.rect - False\n","train_path - data/customdata/train.txt\n","test_path - data/customdata/test.txt\n","init_train - False\n","weights - weights/best.pt\n","midasnet_freeze - True\n","Using cache found in /root/.cache/torch/hub/facebookresearch_WSL-Images_master\n","Caching labels (2623 found, 114 missing, 30 empty, 0 duplicate, for 2767 images): 100% 2767/2767 [00:03<00:00, 767.14it/s]\n","Caching images (0.4GB): 100% 2767/2767 [01:32<00:00, 29.94it/s]\n","Caching labels (657 found, 27 missing, 8 empty, 0 duplicate, for 692 images): 100% 692/692 [00:00<00:00, 767.09it/s]\n","Caching images (0.1GB): 100% 692/692 [00:24<00:00, 28.05it/s]\n","Freezing the midasnet\n","YMP Model Summary\n","----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","            Conv2d-1         [-1, 64, 128, 128]           9,408\n","       BatchNorm2d-2         [-1, 64, 128, 128]             128\n","              ReLU-3         [-1, 64, 128, 128]               0\n","         MaxPool2d-4           [-1, 64, 64, 64]               0\n","            Conv2d-5          [-1, 256, 64, 64]          16,384\n","       BatchNorm2d-6          [-1, 256, 64, 64]             512\n","              ReLU-7          [-1, 256, 64, 64]               0\n","            Conv2d-8          [-1, 256, 64, 64]          18,432\n","       BatchNorm2d-9          [-1, 256, 64, 64]             512\n","             ReLU-10          [-1, 256, 64, 64]               0\n","           Conv2d-11          [-1, 256, 64, 64]          65,536\n","      BatchNorm2d-12          [-1, 256, 64, 64]             512\n","           Conv2d-13          [-1, 256, 64, 64]          16,384\n","      BatchNorm2d-14          [-1, 256, 64, 64]             512\n","             ReLU-15          [-1, 256, 64, 64]               0\n","       Bottleneck-16          [-1, 256, 64, 64]               0\n","           Conv2d-17          [-1, 256, 64, 64]          65,536\n","      BatchNorm2d-18          [-1, 256, 64, 64]             512\n","             ReLU-19          [-1, 256, 64, 64]               0\n","           Conv2d-20          [-1, 256, 64, 64]          18,432\n","      BatchNorm2d-21          [-1, 256, 64, 64]             512\n","             ReLU-22          [-1, 256, 64, 64]               0\n","           Conv2d-23          [-1, 256, 64, 64]          65,536\n","      BatchNorm2d-24          [-1, 256, 64, 64]             512\n","             ReLU-25          [-1, 256, 64, 64]               0\n","       Bottleneck-26          [-1, 256, 64, 64]               0\n","           Conv2d-27          [-1, 256, 64, 64]          65,536\n","      BatchNorm2d-28          [-1, 256, 64, 64]             512\n","             ReLU-29          [-1, 256, 64, 64]               0\n","           Conv2d-30          [-1, 256, 64, 64]          18,432\n","      BatchNorm2d-31          [-1, 256, 64, 64]             512\n","             ReLU-32          [-1, 256, 64, 64]               0\n","           Conv2d-33          [-1, 256, 64, 64]          65,536\n","      BatchNorm2d-34          [-1, 256, 64, 64]             512\n","             ReLU-35          [-1, 256, 64, 64]               0\n","       Bottleneck-36          [-1, 256, 64, 64]               0\n","           Conv2d-37          [-1, 512, 64, 64]         131,072\n","      BatchNorm2d-38          [-1, 512, 64, 64]           1,024\n","             ReLU-39          [-1, 512, 64, 64]               0\n","           Conv2d-40          [-1, 512, 32, 32]          73,728\n","      BatchNorm2d-41          [-1, 512, 32, 32]           1,024\n","             ReLU-42          [-1, 512, 32, 32]               0\n","           Conv2d-43          [-1, 512, 32, 32]         262,144\n","      BatchNorm2d-44          [-1, 512, 32, 32]           1,024\n","           Conv2d-45          [-1, 512, 32, 32]         131,072\n","      BatchNorm2d-46          [-1, 512, 32, 32]           1,024\n","             ReLU-47          [-1, 512, 32, 32]               0\n","       Bottleneck-48          [-1, 512, 32, 32]               0\n","           Conv2d-49          [-1, 512, 32, 32]         262,144\n","      BatchNorm2d-50          [-1, 512, 32, 32]           1,024\n","             ReLU-51          [-1, 512, 32, 32]               0\n","           Conv2d-52          [-1, 512, 32, 32]          73,728\n","      BatchNorm2d-53          [-1, 512, 32, 32]           1,024\n","             ReLU-54          [-1, 512, 32, 32]               0\n","           Conv2d-55          [-1, 512, 32, 32]         262,144\n","      BatchNorm2d-56          [-1, 512, 32, 32]           1,024\n","             ReLU-57          [-1, 512, 32, 32]               0\n","       Bottleneck-58          [-1, 512, 32, 32]               0\n","           Conv2d-59          [-1, 512, 32, 32]         262,144\n","      BatchNorm2d-60          [-1, 512, 32, 32]           1,024\n","             ReLU-61          [-1, 512, 32, 32]               0\n","           Conv2d-62          [-1, 512, 32, 32]          73,728\n","      BatchNorm2d-63          [-1, 512, 32, 32]           1,024\n","             ReLU-64          [-1, 512, 32, 32]               0\n","           Conv2d-65          [-1, 512, 32, 32]         262,144\n","      BatchNorm2d-66          [-1, 512, 32, 32]           1,024\n","             ReLU-67          [-1, 512, 32, 32]               0\n","       Bottleneck-68          [-1, 512, 32, 32]               0\n","           Conv2d-69          [-1, 512, 32, 32]         262,144\n","      BatchNorm2d-70          [-1, 512, 32, 32]           1,024\n","             ReLU-71          [-1, 512, 32, 32]               0\n","           Conv2d-72          [-1, 512, 32, 32]          73,728\n","      BatchNorm2d-73          [-1, 512, 32, 32]           1,024\n","             ReLU-74          [-1, 512, 32, 32]               0\n","           Conv2d-75          [-1, 512, 32, 32]         262,144\n","      BatchNorm2d-76          [-1, 512, 32, 32]           1,024\n","             ReLU-77          [-1, 512, 32, 32]               0\n","       Bottleneck-78          [-1, 512, 32, 32]               0\n","           Conv2d-79         [-1, 1024, 32, 32]         524,288\n","      BatchNorm2d-80         [-1, 1024, 32, 32]           2,048\n","             ReLU-81         [-1, 1024, 32, 32]               0\n","           Conv2d-82         [-1, 1024, 16, 16]         294,912\n","      BatchNorm2d-83         [-1, 1024, 16, 16]           2,048\n","             ReLU-84         [-1, 1024, 16, 16]               0\n","           Conv2d-85         [-1, 1024, 16, 16]       1,048,576\n","      BatchNorm2d-86         [-1, 1024, 16, 16]           2,048\n","           Conv2d-87         [-1, 1024, 16, 16]         524,288\n","      BatchNorm2d-88         [-1, 1024, 16, 16]           2,048\n","             ReLU-89         [-1, 1024, 16, 16]               0\n","       Bottleneck-90         [-1, 1024, 16, 16]               0\n","           Conv2d-91         [-1, 1024, 16, 16]       1,048,576\n","      BatchNorm2d-92         [-1, 1024, 16, 16]           2,048\n","             ReLU-93         [-1, 1024, 16, 16]               0\n","           Conv2d-94         [-1, 1024, 16, 16]         294,912\n","      BatchNorm2d-95         [-1, 1024, 16, 16]           2,048\n","             ReLU-96         [-1, 1024, 16, 16]               0\n","           Conv2d-97         [-1, 1024, 16, 16]       1,048,576\n","      BatchNorm2d-98         [-1, 1024, 16, 16]           2,048\n","             ReLU-99         [-1, 1024, 16, 16]               0\n","      Bottleneck-100         [-1, 1024, 16, 16]               0\n","          Conv2d-101         [-1, 1024, 16, 16]       1,048,576\n","     BatchNorm2d-102         [-1, 1024, 16, 16]           2,048\n","            ReLU-103         [-1, 1024, 16, 16]               0\n","          Conv2d-104         [-1, 1024, 16, 16]         294,912\n","     BatchNorm2d-105         [-1, 1024, 16, 16]           2,048\n","            ReLU-106         [-1, 1024, 16, 16]               0\n","          Conv2d-107         [-1, 1024, 16, 16]       1,048,576\n","     BatchNorm2d-108         [-1, 1024, 16, 16]           2,048\n","            ReLU-109         [-1, 1024, 16, 16]               0\n","      Bottleneck-110         [-1, 1024, 16, 16]               0\n","          Conv2d-111         [-1, 1024, 16, 16]       1,048,576\n","     BatchNorm2d-112         [-1, 1024, 16, 16]           2,048\n","            ReLU-113         [-1, 1024, 16, 16]               0\n","          Conv2d-114         [-1, 1024, 16, 16]         294,912\n","     BatchNorm2d-115         [-1, 1024, 16, 16]           2,048\n","            ReLU-116         [-1, 1024, 16, 16]               0\n","          Conv2d-117         [-1, 1024, 16, 16]       1,048,576\n","     BatchNorm2d-118         [-1, 1024, 16, 16]           2,048\n","            ReLU-119         [-1, 1024, 16, 16]               0\n","      Bottleneck-120         [-1, 1024, 16, 16]               0\n","          Conv2d-121         [-1, 1024, 16, 16]       1,048,576\n","     BatchNorm2d-122         [-1, 1024, 16, 16]           2,048\n","            ReLU-123         [-1, 1024, 16, 16]               0\n","          Conv2d-124         [-1, 1024, 16, 16]         294,912\n","     BatchNorm2d-125         [-1, 1024, 16, 16]           2,048\n","            ReLU-126         [-1, 1024, 16, 16]               0\n","          Conv2d-127         [-1, 1024, 16, 16]       1,048,576\n","     BatchNorm2d-128         [-1, 1024, 16, 16]           2,048\n","            ReLU-129         [-1, 1024, 16, 16]               0\n","      Bottleneck-130         [-1, 1024, 16, 16]               0\n","          Conv2d-131         [-1, 1024, 16, 16]       1,048,576\n","     BatchNorm2d-132         [-1, 1024, 16, 16]           2,048\n","            ReLU-133         [-1, 1024, 16, 16]               0\n","          Conv2d-134         [-1, 1024, 16, 16]         294,912\n","     BatchNorm2d-135         [-1, 1024, 16, 16]           2,048\n","            ReLU-136         [-1, 1024, 16, 16]               0\n","          Conv2d-137         [-1, 1024, 16, 16]       1,048,576\n","     BatchNorm2d-138         [-1, 1024, 16, 16]           2,048\n","            ReLU-139         [-1, 1024, 16, 16]               0\n","      Bottleneck-140         [-1, 1024, 16, 16]               0\n","          Conv2d-141         [-1, 1024, 16, 16]       1,048,576\n","     BatchNorm2d-142         [-1, 1024, 16, 16]           2,048\n","            ReLU-143         [-1, 1024, 16, 16]               0\n","          Conv2d-144         [-1, 1024, 16, 16]         294,912\n","     BatchNorm2d-145         [-1, 1024, 16, 16]           2,048\n","            ReLU-146         [-1, 1024, 16, 16]               0\n","          Conv2d-147         [-1, 1024, 16, 16]       1,048,576\n","     BatchNorm2d-148         [-1, 1024, 16, 16]           2,048\n","            ReLU-149         [-1, 1024, 16, 16]               0\n","      Bottleneck-150         [-1, 1024, 16, 16]               0\n","          Conv2d-151         [-1, 1024, 16, 16]       1,048,576\n","     BatchNorm2d-152         [-1, 1024, 16, 16]           2,048\n","            ReLU-153         [-1, 1024, 16, 16]               0\n","          Conv2d-154         [-1, 1024, 16, 16]         294,912\n","     BatchNorm2d-155         [-1, 1024, 16, 16]           2,048\n","            ReLU-156         [-1, 1024, 16, 16]               0\n","          Conv2d-157         [-1, 1024, 16, 16]       1,048,576\n","     BatchNorm2d-158         [-1, 1024, 16, 16]           2,048\n","            ReLU-159         [-1, 1024, 16, 16]               0\n","      Bottleneck-160         [-1, 1024, 16, 16]               0\n","          Conv2d-161         [-1, 1024, 16, 16]       1,048,576\n","     BatchNorm2d-162         [-1, 1024, 16, 16]           2,048\n","            ReLU-163         [-1, 1024, 16, 16]               0\n","          Conv2d-164         [-1, 1024, 16, 16]         294,912\n","     BatchNorm2d-165         [-1, 1024, 16, 16]           2,048\n","            ReLU-166         [-1, 1024, 16, 16]               0\n","          Conv2d-167         [-1, 1024, 16, 16]       1,048,576\n","     BatchNorm2d-168         [-1, 1024, 16, 16]           2,048\n","            ReLU-169         [-1, 1024, 16, 16]               0\n","      Bottleneck-170         [-1, 1024, 16, 16]               0\n","          Conv2d-171         [-1, 1024, 16, 16]       1,048,576\n","     BatchNorm2d-172         [-1, 1024, 16, 16]           2,048\n","            ReLU-173         [-1, 1024, 16, 16]               0\n","          Conv2d-174         [-1, 1024, 16, 16]         294,912\n","     BatchNorm2d-175         [-1, 1024, 16, 16]           2,048\n","            ReLU-176         [-1, 1024, 16, 16]               0\n","          Conv2d-177         [-1, 1024, 16, 16]       1,048,576\n","     BatchNorm2d-178         [-1, 1024, 16, 16]           2,048\n","            ReLU-179         [-1, 1024, 16, 16]               0\n","      Bottleneck-180         [-1, 1024, 16, 16]               0\n","          Conv2d-181         [-1, 1024, 16, 16]       1,048,576\n","     BatchNorm2d-182         [-1, 1024, 16, 16]           2,048\n","            ReLU-183         [-1, 1024, 16, 16]               0\n","          Conv2d-184         [-1, 1024, 16, 16]         294,912\n","     BatchNorm2d-185         [-1, 1024, 16, 16]           2,048\n","            ReLU-186         [-1, 1024, 16, 16]               0\n","          Conv2d-187         [-1, 1024, 16, 16]       1,048,576\n","     BatchNorm2d-188         [-1, 1024, 16, 16]           2,048\n","            ReLU-189         [-1, 1024, 16, 16]               0\n","      Bottleneck-190         [-1, 1024, 16, 16]               0\n","          Conv2d-191         [-1, 1024, 16, 16]       1,048,576\n","     BatchNorm2d-192         [-1, 1024, 16, 16]           2,048\n","            ReLU-193         [-1, 1024, 16, 16]               0\n","          Conv2d-194         [-1, 1024, 16, 16]         294,912\n","     BatchNorm2d-195         [-1, 1024, 16, 16]           2,048\n","            ReLU-196         [-1, 1024, 16, 16]               0\n","          Conv2d-197         [-1, 1024, 16, 16]       1,048,576\n","     BatchNorm2d-198         [-1, 1024, 16, 16]           2,048\n","            ReLU-199         [-1, 1024, 16, 16]               0\n","      Bottleneck-200         [-1, 1024, 16, 16]               0\n","          Conv2d-201         [-1, 1024, 16, 16]       1,048,576\n","     BatchNorm2d-202         [-1, 1024, 16, 16]           2,048\n","            ReLU-203         [-1, 1024, 16, 16]               0\n","          Conv2d-204         [-1, 1024, 16, 16]         294,912\n","     BatchNorm2d-205         [-1, 1024, 16, 16]           2,048\n","            ReLU-206         [-1, 1024, 16, 16]               0\n","          Conv2d-207         [-1, 1024, 16, 16]       1,048,576\n","     BatchNorm2d-208         [-1, 1024, 16, 16]           2,048\n","            ReLU-209         [-1, 1024, 16, 16]               0\n","      Bottleneck-210         [-1, 1024, 16, 16]               0\n","          Conv2d-211         [-1, 1024, 16, 16]       1,048,576\n","     BatchNorm2d-212         [-1, 1024, 16, 16]           2,048\n","            ReLU-213         [-1, 1024, 16, 16]               0\n","          Conv2d-214         [-1, 1024, 16, 16]         294,912\n","     BatchNorm2d-215         [-1, 1024, 16, 16]           2,048\n","            ReLU-216         [-1, 1024, 16, 16]               0\n","          Conv2d-217         [-1, 1024, 16, 16]       1,048,576\n","     BatchNorm2d-218         [-1, 1024, 16, 16]           2,048\n","            ReLU-219         [-1, 1024, 16, 16]               0\n","      Bottleneck-220         [-1, 1024, 16, 16]               0\n","          Conv2d-221         [-1, 1024, 16, 16]       1,048,576\n","     BatchNorm2d-222         [-1, 1024, 16, 16]           2,048\n","            ReLU-223         [-1, 1024, 16, 16]               0\n","          Conv2d-224         [-1, 1024, 16, 16]         294,912\n","     BatchNorm2d-225         [-1, 1024, 16, 16]           2,048\n","            ReLU-226         [-1, 1024, 16, 16]               0\n","          Conv2d-227         [-1, 1024, 16, 16]       1,048,576\n","     BatchNorm2d-228         [-1, 1024, 16, 16]           2,048\n","            ReLU-229         [-1, 1024, 16, 16]               0\n","      Bottleneck-230         [-1, 1024, 16, 16]               0\n","          Conv2d-231         [-1, 1024, 16, 16]       1,048,576\n","     BatchNorm2d-232         [-1, 1024, 16, 16]           2,048\n","            ReLU-233         [-1, 1024, 16, 16]               0\n","          Conv2d-234         [-1, 1024, 16, 16]         294,912\n","     BatchNorm2d-235         [-1, 1024, 16, 16]           2,048\n","            ReLU-236         [-1, 1024, 16, 16]               0\n","          Conv2d-237         [-1, 1024, 16, 16]       1,048,576\n","     BatchNorm2d-238         [-1, 1024, 16, 16]           2,048\n","            ReLU-239         [-1, 1024, 16, 16]               0\n","      Bottleneck-240         [-1, 1024, 16, 16]               0\n","          Conv2d-241         [-1, 1024, 16, 16]       1,048,576\n","     BatchNorm2d-242         [-1, 1024, 16, 16]           2,048\n","            ReLU-243         [-1, 1024, 16, 16]               0\n","          Conv2d-244         [-1, 1024, 16, 16]         294,912\n","     BatchNorm2d-245         [-1, 1024, 16, 16]           2,048\n","            ReLU-246         [-1, 1024, 16, 16]               0\n","          Conv2d-247         [-1, 1024, 16, 16]       1,048,576\n","     BatchNorm2d-248         [-1, 1024, 16, 16]           2,048\n","            ReLU-249         [-1, 1024, 16, 16]               0\n","      Bottleneck-250         [-1, 1024, 16, 16]               0\n","          Conv2d-251         [-1, 1024, 16, 16]       1,048,576\n","     BatchNorm2d-252         [-1, 1024, 16, 16]           2,048\n","            ReLU-253         [-1, 1024, 16, 16]               0\n","          Conv2d-254         [-1, 1024, 16, 16]         294,912\n","     BatchNorm2d-255         [-1, 1024, 16, 16]           2,048\n","            ReLU-256         [-1, 1024, 16, 16]               0\n","          Conv2d-257         [-1, 1024, 16, 16]       1,048,576\n","     BatchNorm2d-258         [-1, 1024, 16, 16]           2,048\n","            ReLU-259         [-1, 1024, 16, 16]               0\n","      Bottleneck-260         [-1, 1024, 16, 16]               0\n","          Conv2d-261         [-1, 1024, 16, 16]       1,048,576\n","     BatchNorm2d-262         [-1, 1024, 16, 16]           2,048\n","            ReLU-263         [-1, 1024, 16, 16]               0\n","          Conv2d-264         [-1, 1024, 16, 16]         294,912\n","     BatchNorm2d-265         [-1, 1024, 16, 16]           2,048\n","            ReLU-266         [-1, 1024, 16, 16]               0\n","          Conv2d-267         [-1, 1024, 16, 16]       1,048,576\n","     BatchNorm2d-268         [-1, 1024, 16, 16]           2,048\n","            ReLU-269         [-1, 1024, 16, 16]               0\n","      Bottleneck-270         [-1, 1024, 16, 16]               0\n","          Conv2d-271         [-1, 1024, 16, 16]       1,048,576\n","     BatchNorm2d-272         [-1, 1024, 16, 16]           2,048\n","            ReLU-273         [-1, 1024, 16, 16]               0\n","          Conv2d-274         [-1, 1024, 16, 16]         294,912\n","     BatchNorm2d-275         [-1, 1024, 16, 16]           2,048\n","            ReLU-276         [-1, 1024, 16, 16]               0\n","          Conv2d-277         [-1, 1024, 16, 16]       1,048,576\n","     BatchNorm2d-278         [-1, 1024, 16, 16]           2,048\n","            ReLU-279         [-1, 1024, 16, 16]               0\n","      Bottleneck-280         [-1, 1024, 16, 16]               0\n","          Conv2d-281         [-1, 1024, 16, 16]       1,048,576\n","     BatchNorm2d-282         [-1, 1024, 16, 16]           2,048\n","            ReLU-283         [-1, 1024, 16, 16]               0\n","          Conv2d-284         [-1, 1024, 16, 16]         294,912\n","     BatchNorm2d-285         [-1, 1024, 16, 16]           2,048\n","            ReLU-286         [-1, 1024, 16, 16]               0\n","          Conv2d-287         [-1, 1024, 16, 16]       1,048,576\n","     BatchNorm2d-288         [-1, 1024, 16, 16]           2,048\n","            ReLU-289         [-1, 1024, 16, 16]               0\n","      Bottleneck-290         [-1, 1024, 16, 16]               0\n","          Conv2d-291         [-1, 1024, 16, 16]       1,048,576\n","     BatchNorm2d-292         [-1, 1024, 16, 16]           2,048\n","            ReLU-293         [-1, 1024, 16, 16]               0\n","          Conv2d-294         [-1, 1024, 16, 16]         294,912\n","     BatchNorm2d-295         [-1, 1024, 16, 16]           2,048\n","            ReLU-296         [-1, 1024, 16, 16]               0\n","          Conv2d-297         [-1, 1024, 16, 16]       1,048,576\n","     BatchNorm2d-298         [-1, 1024, 16, 16]           2,048\n","            ReLU-299         [-1, 1024, 16, 16]               0\n","      Bottleneck-300         [-1, 1024, 16, 16]               0\n","          Conv2d-301         [-1, 1024, 16, 16]       1,048,576\n","     BatchNorm2d-302         [-1, 1024, 16, 16]           2,048\n","            ReLU-303         [-1, 1024, 16, 16]               0\n","          Conv2d-304         [-1, 1024, 16, 16]         294,912\n","     BatchNorm2d-305         [-1, 1024, 16, 16]           2,048\n","            ReLU-306         [-1, 1024, 16, 16]               0\n","          Conv2d-307         [-1, 1024, 16, 16]       1,048,576\n","     BatchNorm2d-308         [-1, 1024, 16, 16]           2,048\n","            ReLU-309         [-1, 1024, 16, 16]               0\n","      Bottleneck-310         [-1, 1024, 16, 16]               0\n","          Conv2d-311         [-1, 2048, 16, 16]       2,097,152\n","     BatchNorm2d-312         [-1, 2048, 16, 16]           4,096\n","            ReLU-313         [-1, 2048, 16, 16]               0\n","          Conv2d-314           [-1, 2048, 8, 8]       1,179,648\n","     BatchNorm2d-315           [-1, 2048, 8, 8]           4,096\n","            ReLU-316           [-1, 2048, 8, 8]               0\n","          Conv2d-317           [-1, 2048, 8, 8]       4,194,304\n","     BatchNorm2d-318           [-1, 2048, 8, 8]           4,096\n","          Conv2d-319           [-1, 2048, 8, 8]       2,097,152\n","     BatchNorm2d-320           [-1, 2048, 8, 8]           4,096\n","            ReLU-321           [-1, 2048, 8, 8]               0\n","      Bottleneck-322           [-1, 2048, 8, 8]               0\n","          Conv2d-323           [-1, 2048, 8, 8]       4,194,304\n","     BatchNorm2d-324           [-1, 2048, 8, 8]           4,096\n","            ReLU-325           [-1, 2048, 8, 8]               0\n","          Conv2d-326           [-1, 2048, 8, 8]       1,179,648\n","     BatchNorm2d-327           [-1, 2048, 8, 8]           4,096\n","            ReLU-328           [-1, 2048, 8, 8]               0\n","          Conv2d-329           [-1, 2048, 8, 8]       4,194,304\n","     BatchNorm2d-330           [-1, 2048, 8, 8]           4,096\n","            ReLU-331           [-1, 2048, 8, 8]               0\n","      Bottleneck-332           [-1, 2048, 8, 8]               0\n","          Conv2d-333           [-1, 2048, 8, 8]       4,194,304\n","     BatchNorm2d-334           [-1, 2048, 8, 8]           4,096\n","            ReLU-335           [-1, 2048, 8, 8]               0\n","          Conv2d-336           [-1, 2048, 8, 8]       1,179,648\n","     BatchNorm2d-337           [-1, 2048, 8, 8]           4,096\n","            ReLU-338           [-1, 2048, 8, 8]               0\n","          Conv2d-339           [-1, 2048, 8, 8]       4,194,304\n","     BatchNorm2d-340           [-1, 2048, 8, 8]           4,096\n","            ReLU-341           [-1, 2048, 8, 8]               0\n","      Bottleneck-342           [-1, 2048, 8, 8]               0\n","          Conv2d-343          [-1, 256, 64, 64]         589,824\n","          Conv2d-344          [-1, 256, 32, 32]       1,179,648\n","          Conv2d-345          [-1, 256, 16, 16]       2,359,296\n","          Conv2d-346            [-1, 256, 8, 8]       4,718,592\n","            ReLU-347            [-1, 256, 8, 8]               0\n","          Conv2d-348            [-1, 256, 8, 8]         590,080\n","            ReLU-349            [-1, 256, 8, 8]               0\n","          Conv2d-350            [-1, 256, 8, 8]         590,080\n","ResidualConvUnit-351            [-1, 256, 8, 8]               0\n","FeatureFusionBlock-352          [-1, 256, 16, 16]               0\n","            ReLU-353          [-1, 256, 16, 16]               0\n","          Conv2d-354          [-1, 256, 16, 16]         590,080\n","            ReLU-355          [-1, 256, 16, 16]               0\n","          Conv2d-356          [-1, 256, 16, 16]         590,080\n","ResidualConvUnit-357          [-1, 256, 16, 16]               0\n","            ReLU-358          [-1, 256, 16, 16]               0\n","          Conv2d-359          [-1, 256, 16, 16]         590,080\n","            ReLU-360          [-1, 256, 16, 16]               0\n","          Conv2d-361          [-1, 256, 16, 16]         590,080\n","ResidualConvUnit-362          [-1, 256, 16, 16]               0\n","FeatureFusionBlock-363          [-1, 256, 32, 32]               0\n","            ReLU-364          [-1, 256, 32, 32]               0\n","          Conv2d-365          [-1, 256, 32, 32]         590,080\n","            ReLU-366          [-1, 256, 32, 32]               0\n","          Conv2d-367          [-1, 256, 32, 32]         590,080\n","ResidualConvUnit-368          [-1, 256, 32, 32]               0\n","            ReLU-369          [-1, 256, 32, 32]               0\n","          Conv2d-370          [-1, 256, 32, 32]         590,080\n","            ReLU-371          [-1, 256, 32, 32]               0\n","          Conv2d-372          [-1, 256, 32, 32]         590,080\n","ResidualConvUnit-373          [-1, 256, 32, 32]               0\n","FeatureFusionBlock-374          [-1, 256, 64, 64]               0\n","            ReLU-375          [-1, 256, 64, 64]               0\n","          Conv2d-376          [-1, 256, 64, 64]         590,080\n","            ReLU-377          [-1, 256, 64, 64]               0\n","          Conv2d-378          [-1, 256, 64, 64]         590,080\n","ResidualConvUnit-379          [-1, 256, 64, 64]               0\n","            ReLU-380          [-1, 256, 64, 64]               0\n","          Conv2d-381          [-1, 256, 64, 64]         590,080\n","            ReLU-382          [-1, 256, 64, 64]               0\n","          Conv2d-383          [-1, 256, 64, 64]         590,080\n","ResidualConvUnit-384          [-1, 256, 64, 64]               0\n","FeatureFusionBlock-385        [-1, 256, 128, 128]               0\n","          Conv2d-386        [-1, 128, 128, 128]         295,040\n","     Interpolate-387        [-1, 128, 256, 256]               0\n","          Conv2d-388         [-1, 32, 256, 256]          36,896\n","            ReLU-389         [-1, 32, 256, 256]               0\n","          Conv2d-390          [-1, 1, 256, 256]              33\n","            ReLU-391          [-1, 1, 256, 256]               0\n","          Conv2d-392        [-1, 256, 128, 128]           6,912\n","     BatchNorm2d-393        [-1, 256, 128, 128]             512\n","            ReLU-394        [-1, 256, 128, 128]               0\n","          Conv2d-395          [-1, 256, 64, 64]         589,824\n","     BatchNorm2d-396          [-1, 256, 64, 64]             512\n","            ReLU-397          [-1, 256, 64, 64]               0\n","          Conv2d-398          [-1, 256, 32, 32]         589,824\n","     BatchNorm2d-399          [-1, 256, 32, 32]             512\n","            ReLU-400          [-1, 256, 32, 32]               0\n","          Conv2d-401          [-1, 512, 16, 16]       1,179,648\n","     BatchNorm2d-402          [-1, 512, 16, 16]           1,024\n","            ReLU-403          [-1, 512, 16, 16]               0\n","          Conv2d-404           [-1, 1024, 8, 8]       4,718,592\n","     BatchNorm2d-405           [-1, 1024, 8, 8]           2,048\n","            ReLU-406           [-1, 1024, 8, 8]               0\n","          Conv2d-407           [-1, 1024, 8, 8]       2,097,152\n","     BatchNorm2d-408           [-1, 1024, 8, 8]           2,048\n","            ReLU-409           [-1, 1024, 8, 8]               0\n","          Conv2d-410             [-1, 27, 8, 8]          27,675\n","       YOLOLayer-411           [-1, 3, 8, 8, 9]               0\n","     Interpolate-412         [-1, 1024, 16, 16]               0\n","          Conv2d-413          [-1, 256, 16, 16]         262,144\n","     BatchNorm2d-414          [-1, 256, 16, 16]             512\n","            ReLU-415          [-1, 256, 16, 16]               0\n","          Conv2d-416          [-1, 512, 16, 16]         524,288\n","     BatchNorm2d-417          [-1, 512, 16, 16]           1,024\n","            ReLU-418          [-1, 512, 16, 16]               0\n","          Conv2d-419          [-1, 256, 16, 16]         196,608\n","     BatchNorm2d-420          [-1, 256, 16, 16]             512\n","            ReLU-421          [-1, 256, 16, 16]               0\n","          Conv2d-422          [-1, 512, 16, 16]       1,179,648\n","     BatchNorm2d-423          [-1, 512, 16, 16]           1,024\n","            ReLU-424          [-1, 512, 16, 16]               0\n","          Conv2d-425          [-1, 256, 16, 16]         131,072\n","     BatchNorm2d-426          [-1, 256, 16, 16]             512\n","            ReLU-427          [-1, 256, 16, 16]               0\n","          Conv2d-428          [-1, 512, 16, 16]       1,179,648\n","     BatchNorm2d-429          [-1, 512, 16, 16]           1,024\n","            ReLU-430          [-1, 512, 16, 16]               0\n","          Conv2d-431          [-1, 256, 16, 16]         131,072\n","     BatchNorm2d-432          [-1, 256, 16, 16]             512\n","            ReLU-433          [-1, 256, 16, 16]               0\n","          Conv2d-434          [-1, 512, 16, 16]       1,179,648\n","     BatchNorm2d-435          [-1, 512, 16, 16]           1,024\n","            ReLU-436          [-1, 512, 16, 16]               0\n","          Conv2d-437           [-1, 27, 16, 16]          13,851\n","       YOLOLayer-438         [-1, 3, 16, 16, 9]               0\n","          Conv2d-439          [-1, 256, 32, 32]         131,072\n","     BatchNorm2d-440          [-1, 256, 32, 32]             512\n","            ReLU-441          [-1, 256, 32, 32]               0\n","     Interpolate-442          [-1, 512, 32, 32]               0\n","          Conv2d-443          [-1, 128, 32, 32]          65,536\n","     BatchNorm2d-444          [-1, 128, 32, 32]             256\n","            ReLU-445          [-1, 128, 32, 32]               0\n","          Conv2d-446          [-1, 128, 32, 32]          49,152\n","     BatchNorm2d-447          [-1, 128, 32, 32]             256\n","            ReLU-448          [-1, 128, 32, 32]               0\n","          Conv2d-449          [-1, 256, 32, 32]         294,912\n","     BatchNorm2d-450          [-1, 256, 32, 32]             512\n","            ReLU-451          [-1, 256, 32, 32]               0\n","          Conv2d-452          [-1, 128, 32, 32]          32,768\n","     BatchNorm2d-453          [-1, 128, 32, 32]             256\n","            ReLU-454          [-1, 128, 32, 32]               0\n","          Conv2d-455          [-1, 256, 32, 32]         294,912\n","     BatchNorm2d-456          [-1, 256, 32, 32]             512\n","            ReLU-457          [-1, 256, 32, 32]               0\n","          Conv2d-458          [-1, 128, 32, 32]          32,768\n","     BatchNorm2d-459          [-1, 128, 32, 32]             256\n","            ReLU-460          [-1, 128, 32, 32]               0\n","          Conv2d-461          [-1, 256, 32, 32]         294,912\n","     BatchNorm2d-462          [-1, 256, 32, 32]             512\n","            ReLU-463          [-1, 256, 32, 32]               0\n","          Conv2d-464           [-1, 27, 32, 32]           6,939\n","       YOLOLayer-465         [-1, 3, 32, 32, 9]               0\n","================================================================\n","Total params: 119,409,234\n","Trainable params: 15,226,449\n","Non-trainable params: 104,182,785\n","----------------------------------------------------------------\n","Input size (MB): 0.75\n","Forward/backward pass size (MB): 1473.30\n","Params size (MB): 455.51\n","Estimated Total Size (MB): 1929.56\n","----------------------------------------------------------------\n","Image sizes 256 - 256 train, 256 test\n","Using 4 dataloader workers\n","Starting training for 300 epochs...\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","  0% 0/346 [00:00<?, ?it/s]/usr/local/lib/python3.6/dist-packages/torch/cuda/memory.py:346: FutureWarning: torch.cuda.memory_cached has been renamed to torch.cuda.memory_reserved\n","  FutureWarning)\n","   106/299     2.09G      5.74      2.17      1.27      9.18        27       256: 100% 346/346 [02:14<00:00,  2.57it/s]\n","               Class    Images   Targets         P         R   mAP@0.5        F1:   0% 0/87 [00:00<?, ?it/s]/content/drive/My Drive/computer_vision/capstone_project/yolo_v3/utils/utils.py:544: UserWarning: This overload of nonzero is deprecated:\n","\tnonzero()\n","Consider using one of the following signatures instead:\n","\tnonzero(*, bool as_tuple) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:882.)\n","  i, j = (x[:, 5:] > conf_thres).nonzero().t()\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 87/87 [00:23<00:00,  3.71it/s]\n","                 all       692  3.06e+03     0.206     0.433     0.166     0.277\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","  0% 0/346 [00:00<?, ?it/s]/usr/local/lib/python3.6/dist-packages/torch/cuda/memory.py:346: FutureWarning: torch.cuda.memory_cached has been renamed to torch.cuda.memory_reserved\n","  FutureWarning)\n","   107/299     2.09G      5.52      2.18      1.16      8.85        58       256: 100% 346/346 [02:17<00:00,  2.52it/s]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 87/87 [00:21<00:00,  4.03it/s]\n","                 all       692  3.06e+03     0.217     0.433     0.192     0.287\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","   108/299     2.09G      5.32      2.26      1.09      8.67        38       256: 100% 346/346 [02:16<00:00,  2.53it/s]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 87/87 [00:21<00:00,  4.04it/s]\n","                 all       692  3.06e+03     0.212     0.453       0.2     0.287\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","   109/299     2.09G       5.3      2.26     0.995      8.55        73       256: 100% 346/346 [02:16<00:00,  2.54it/s]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 87/87 [00:21<00:00,  4.06it/s]\n","                 all       692  3.06e+03     0.197     0.463     0.205     0.275\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","   110/299     2.09G      5.23      2.24      1.05      8.51        37       256: 100% 346/346 [02:15<00:00,  2.56it/s]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 87/87 [00:21<00:00,  4.07it/s]\n","                 all       692  3.06e+03     0.207     0.463     0.197     0.285\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","   111/299     2.09G      5.24       2.2         1      8.44        45       256: 100% 346/346 [02:14<00:00,  2.56it/s]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 87/87 [00:21<00:00,  4.06it/s]\n","                 all       692  3.06e+03      0.21     0.457     0.228     0.287\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","   112/299     2.09G      5.21       2.2     0.981      8.39        25       256: 100% 346/346 [02:13<00:00,  2.58it/s]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 87/87 [00:21<00:00,  4.05it/s]\n","                 all       692  3.06e+03     0.212     0.462     0.222      0.29\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","   113/299     2.09G      5.18      2.22     0.963      8.36        29       256: 100% 346/346 [02:14<00:00,  2.56it/s]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 87/87 [00:21<00:00,  4.04it/s]\n","                 all       692  3.06e+03      0.21     0.453     0.204     0.286\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","   114/299     2.09G      5.17      2.14     0.953      8.26        39       256: 100% 346/346 [02:15<00:00,  2.55it/s]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 87/87 [00:21<00:00,  4.05it/s]\n","                 all       692  3.06e+03     0.209     0.462     0.213     0.287\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","   115/299     2.09G      5.15      2.19      0.94      8.28        77       256: 100% 346/346 [02:16<00:00,  2.54it/s]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 87/87 [00:21<00:00,  4.04it/s]\n","                 all       692  3.06e+03     0.209     0.471     0.216     0.289\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","   116/299     2.09G      5.12      2.14     0.894      8.15        66       256: 100% 346/346 [02:14<00:00,  2.57it/s]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 87/87 [00:21<00:00,  4.06it/s]\n","                 all       692  3.06e+03     0.206      0.46     0.216     0.284\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","   117/299     2.09G      5.15      2.11     0.928      8.19        61       256: 100% 346/346 [02:15<00:00,  2.55it/s]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 87/87 [00:21<00:00,  4.06it/s]\n","                 all       692  3.06e+03     0.212     0.478     0.229     0.294\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","   118/299     2.09G      5.12      2.11     0.909      8.14        35       256: 100% 346/346 [02:15<00:00,  2.55it/s]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 87/87 [00:21<00:00,  4.05it/s]\n","                 all       692  3.06e+03     0.211     0.469     0.212      0.29\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","   119/299     2.09G       5.1       2.1     0.924      8.13        24       256: 100% 346/346 [02:16<00:00,  2.54it/s]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 87/87 [00:21<00:00,  4.04it/s]\n","                 all       692  3.06e+03     0.211     0.456       0.2     0.288\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","   120/299     2.09G      5.09       2.1     0.873      8.06        43       256: 100% 346/346 [02:15<00:00,  2.55it/s]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 87/87 [00:21<00:00,  4.04it/s]\n","                 all       692  3.06e+03     0.214     0.471     0.223     0.294\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","   121/299     2.09G      5.08      2.08     0.847      8.01        50       256: 100% 346/346 [02:15<00:00,  2.55it/s]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 87/87 [00:21<00:00,  4.06it/s]\n","                 all       692  3.06e+03     0.216     0.477     0.216     0.297\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","   122/299     2.09G      5.06      2.05     0.855      7.96        46       256: 100% 346/346 [02:14<00:00,  2.57it/s]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 87/87 [00:21<00:00,  4.03it/s]\n","                 all       692  3.06e+03     0.213     0.475     0.233     0.293\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","   123/299     2.09G      5.03      2.08     0.865      7.97        32       256: 100% 346/346 [02:15<00:00,  2.55it/s]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 87/87 [00:21<00:00,  4.06it/s]\n","                 all       692  3.06e+03     0.202      0.46     0.201      0.28\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","   124/299     2.09G      5.07      2.05     0.834      7.95        52       256: 100% 346/346 [02:15<00:00,  2.56it/s]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 87/87 [00:21<00:00,  4.02it/s]\n","                 all       692  3.06e+03     0.205     0.467     0.205     0.285\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","   125/299     2.09G      5.02      2.06      0.81      7.89        49       256: 100% 346/346 [02:14<00:00,  2.57it/s]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 87/87 [00:21<00:00,  4.06it/s]\n","                 all       692  3.06e+03     0.214     0.472     0.213     0.295\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","   126/299     2.09G      5.03      2.07     0.775      7.88        31       256: 100% 346/346 [02:14<00:00,  2.58it/s]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 87/87 [00:21<00:00,  4.05it/s]\n","                 all       692  3.06e+03     0.214     0.466     0.208     0.292\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","   127/299     2.09G      5.02      2.03      0.78      7.82        21       256: 100% 346/346 [02:14<00:00,  2.57it/s]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 87/87 [00:21<00:00,  4.08it/s]\n","                 all       692  3.06e+03     0.201     0.472     0.217     0.282\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","   128/299     2.09G      5.03      2.02     0.786      7.84        57       256: 100% 346/346 [02:12<00:00,  2.60it/s]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 87/87 [00:21<00:00,  4.08it/s]\n","                 all       692  3.06e+03     0.205     0.481      0.23     0.287\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","   129/299     2.09G      5.02      2.04     0.758      7.82        26       256: 100% 346/346 [02:14<00:00,  2.57it/s]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 87/87 [00:21<00:00,  4.07it/s]\n","                 all       692  3.06e+03     0.211     0.472     0.213     0.291\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","   130/299     2.09G      5.01      1.98     0.726      7.71        44       256: 100% 346/346 [02:13<00:00,  2.59it/s]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 87/87 [00:21<00:00,  4.06it/s]\n","                 all       692  3.06e+03     0.216     0.476     0.227     0.297\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","   131/299     2.09G         5      2.05     0.716      7.77        46       256: 100% 346/346 [02:15<00:00,  2.56it/s]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 87/87 [00:21<00:00,  4.06it/s]\n","                 all       692  3.06e+03     0.212     0.486     0.222     0.295\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","   132/299     2.09G      4.99         2     0.753      7.74        41       256: 100% 346/346 [02:16<00:00,  2.54it/s]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 87/87 [00:21<00:00,  4.07it/s]\n","                 all       692  3.06e+03     0.213     0.482     0.207     0.295\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","   133/299     2.09G      4.95         2     0.731      7.69        30       256: 100% 346/346 [02:14<00:00,  2.58it/s]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 87/87 [00:21<00:00,  4.07it/s]\n","                 all       692  3.06e+03     0.212     0.478     0.217     0.293\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","   134/299     2.09G      4.98      2.02     0.751      7.75        40       256: 100% 346/346 [02:16<00:00,  2.53it/s]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 87/87 [00:21<00:00,  4.06it/s]\n","                 all       692  3.06e+03     0.207     0.484     0.225      0.29\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","   135/299     2.09G      4.97      1.98     0.702      7.65        39       256: 100% 346/346 [02:17<00:00,  2.52it/s]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 87/87 [00:21<00:00,  4.06it/s]\n","                 all       692  3.06e+03     0.214     0.466     0.219     0.292\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","   136/299     2.09G      4.96      2.02     0.684      7.66        54       256: 100% 346/346 [02:15<00:00,  2.56it/s]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 87/87 [00:21<00:00,  4.06it/s]\n","                 all       692  3.06e+03     0.212     0.476     0.227     0.293\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","   137/299     2.09G      4.96      1.94     0.713       7.6        32       256: 100% 346/346 [02:13<00:00,  2.60it/s]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 87/87 [00:21<00:00,  4.10it/s]\n","                 all       692  3.06e+03     0.216     0.465     0.213     0.295\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","   138/299     2.09G      4.94      1.99     0.701      7.64        64       256: 100% 346/346 [02:11<00:00,  2.64it/s]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 87/87 [00:21<00:00,  4.14it/s]\n","                 all       692  3.06e+03     0.217     0.463     0.231     0.296\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","   139/299     2.09G      4.93      1.98     0.696      7.61        53       256: 100% 346/346 [02:12<00:00,  2.62it/s]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 87/87 [00:21<00:00,  4.14it/s]\n","                 all       692  3.06e+03     0.212      0.48      0.24     0.294\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","   140/299     2.09G      4.94      1.98      0.67      7.58        69       256: 100% 346/346 [02:13<00:00,  2.60it/s]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 87/87 [00:21<00:00,  4.13it/s]\n","                 all       692  3.06e+03     0.215     0.471     0.232     0.295\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","   141/299     2.09G      4.93      1.94     0.676      7.55        26       256: 100% 346/346 [02:14<00:00,  2.58it/s]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 87/87 [00:21<00:00,  4.11it/s]\n","                 all       692  3.06e+03     0.213     0.474     0.234     0.293\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","   142/299     2.09G      4.91      1.95     0.679      7.54        37       256: 100% 346/346 [02:15<00:00,  2.56it/s]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 87/87 [00:21<00:00,  4.12it/s]\n","                 all       692  3.06e+03     0.219     0.476     0.233       0.3\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","   143/299     2.09G      4.92      1.95     0.668      7.54        32       256: 100% 346/346 [02:20<00:00,  2.46it/s]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 87/87 [00:21<00:00,  4.06it/s]\n","                 all       692  3.06e+03     0.213     0.469      0.23     0.293\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","   144/299     2.09G      4.93      1.93     0.645      7.51        44       256: 100% 346/346 [02:18<00:00,  2.49it/s]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 87/87 [00:21<00:00,  4.05it/s]\n","                 all       692  3.06e+03     0.211     0.481     0.237     0.293\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","   145/299     2.09G      4.91      1.91     0.645      7.47        43       256: 100% 346/346 [02:20<00:00,  2.46it/s]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 87/87 [00:21<00:00,  4.04it/s]\n","                 all       692  3.06e+03     0.216     0.474     0.233     0.296\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","   146/299     2.09G      4.89      1.91     0.624      7.43        35       256: 100% 346/346 [02:20<00:00,  2.46it/s]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 87/87 [00:21<00:00,  4.04it/s]\n","                 all       692  3.06e+03     0.211     0.469     0.226     0.291\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","   147/299     2.09G      4.86      1.91      0.61      7.38        35       256: 100% 346/346 [02:19<00:00,  2.48it/s]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 87/87 [00:21<00:00,  4.06it/s]\n","                 all       692  3.06e+03     0.211     0.476     0.233     0.292\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","   148/299     2.09G      4.87      1.93     0.599       7.4        41       256: 100% 346/346 [02:19<00:00,  2.48it/s]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 87/87 [00:21<00:00,  4.07it/s]\n","                 all       692  3.06e+03     0.207     0.475     0.241     0.288\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","   149/299     2.09G      4.85       1.9       0.6      7.35        57       256: 100% 346/346 [02:16<00:00,  2.53it/s]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 87/87 [00:21<00:00,  4.03it/s]\n","                 all       692  3.06e+03     0.212     0.469     0.233     0.292\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","   150/299     2.09G      4.87       1.9     0.601      7.37        40       256: 100% 346/346 [02:18<00:00,  2.50it/s]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 87/87 [00:21<00:00,  4.07it/s]\n","                 all       692  3.06e+03     0.208     0.477     0.223     0.289\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","   151/299     2.09G      4.88      1.88     0.613      7.37        43       256: 100% 346/346 [02:16<00:00,  2.54it/s]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 87/87 [00:21<00:00,  4.10it/s]\n","                 all       692  3.06e+03     0.209     0.469     0.231     0.289\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","   152/299     2.09G      4.86      1.91     0.607      7.37        32       256: 100% 346/346 [02:17<00:00,  2.52it/s]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 87/87 [00:21<00:00,  4.08it/s]\n","                 all       692  3.06e+03     0.207     0.477     0.231     0.289\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","   153/299     2.09G      4.88      1.89     0.576      7.35        24       256: 100% 346/346 [02:17<00:00,  2.52it/s]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 87/87 [00:21<00:00,  4.07it/s]\n","                 all       692  3.06e+03     0.219     0.478     0.244       0.3\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","   154/299     2.09G      4.84      1.89     0.596      7.33        47       256: 100% 346/346 [02:19<00:00,  2.49it/s]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 87/87 [00:21<00:00,  4.06it/s]\n","                 all       692  3.06e+03     0.214     0.479     0.233     0.296\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","   155/299     2.09G      4.85      1.85     0.606       7.3        60       256: 100% 346/346 [02:17<00:00,  2.52it/s]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 87/87 [00:21<00:00,  4.03it/s]\n","                 all       692  3.06e+03     0.215     0.469     0.234     0.295\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","   156/299     2.09G      4.83      1.88     0.551      7.26        73       256: 100% 346/346 [02:19<00:00,  2.49it/s]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 87/87 [00:21<00:00,  4.06it/s]\n","                 all       692  3.06e+03     0.212     0.469     0.228     0.292\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","   157/299     2.09G      4.84       1.9     0.572      7.31        31       256: 100% 346/346 [02:19<00:00,  2.48it/s]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 87/87 [00:21<00:00,  4.08it/s]\n","                 all       692  3.06e+03     0.213     0.474     0.232     0.294\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","   158/299     2.09G      4.83      1.86     0.573      7.26        34       256: 100% 346/346 [02:19<00:00,  2.48it/s]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 87/87 [00:21<00:00,  4.01it/s]\n","                 all       692  3.06e+03     0.217     0.474     0.241     0.297\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","   159/299     2.09G      4.82      1.87     0.526      7.22        50       256: 100% 346/346 [02:19<00:00,  2.47it/s]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 87/87 [00:21<00:00,  4.07it/s]\n","                 all       692  3.06e+03     0.217     0.466     0.234     0.296\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","   160/299     2.09G      4.84      1.85     0.557      7.24        50       256: 100% 346/346 [02:17<00:00,  2.51it/s]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 87/87 [00:21<00:00,  4.07it/s]\n","                 all       692  3.06e+03     0.211     0.476     0.232     0.293\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","   161/299     2.09G       4.8      1.87     0.548      7.21        48       256: 100% 346/346 [02:20<00:00,  2.46it/s]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 87/87 [00:21<00:00,  4.00it/s]\n","                 all       692  3.06e+03     0.217     0.475     0.243     0.297\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","   162/299     2.09G      4.79      1.84     0.572      7.21        73       256: 100% 346/346 [02:18<00:00,  2.49it/s]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 87/87 [00:21<00:00,  4.05it/s]\n","                 all       692  3.06e+03     0.215     0.481     0.238     0.297\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","   163/299     2.09G      4.81       1.8     0.525      7.14        33       256: 100% 346/346 [02:18<00:00,  2.50it/s]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 87/87 [00:21<00:00,  4.07it/s]\n","                 all       692  3.06e+03     0.215     0.474     0.238     0.295\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","   164/299     2.09G       4.8      1.84     0.555       7.2        40       256: 100% 346/346 [02:18<00:00,  2.50it/s]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 87/87 [00:21<00:00,  4.06it/s]\n","                 all       692  3.06e+03     0.211     0.472     0.231     0.292\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","   165/299     2.09G       4.8      1.87     0.539       7.2        36       256:   9% 32/346 [00:14<01:45,  2.96it/s]"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"JMcbOq6O9gmv"},"source":["## Training yolo branch only by freezing the midas layers on 448x448 resolution"]},{"cell_type":"code","metadata":{"id":"CEQNL_9sLack","colab":{"base_uri":"https://localhost:8080/"},"outputId":"687ceafa-9d9b-4e2f-924a-ae6446527597"},"source":["!python train.py --data data/customdata/custom.data --batch 8  --cache --cfg cfg/yolov3-custom.cfg --epochs 300 --weights 'weights/best.pt'  --img-size=448 --midasnet_freeze='True'"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Namespace(accumulate=4, adam=False, batch_size=8, bucket='', cache_images=True, cfg='cfg/yolov3-custom.cfg', data='data/customdata/custom.data', device='', epochs=300, evolve=False, img_size=[448], init_train='False', midas_weights='', midasnet_freeze='True', multi_scale=False, name='', nosave=False, notest=False, rect=False, resume=False, single_cls=False, weights='weights/best.pt', yolo_weights='')\n","Using CUDA device0 _CudaDeviceProperties(name='Tesla P100-PCIE-16GB', total_memory=16280MB)\n","\n","2020-11-14 14:35:15.043896: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n","Run 'tensorboard --logdir=runs' to view tensorboard at http://localhost:6006/\n","cfg - cfg/yolov3-custom.cfg\n","data - data/customdata/custom.data\n","epochs - 300\n","batch_size - 8\n","accumulate - 4\n","yolo weights - \n","midas weights - \n","imgsz_min- 448, imgsz_max- 448, imgsz_test- 448\n","opt.rect - False\n","train_path - data/customdata/train.txt\n","test_path - data/customdata/test.txt\n","init_train - False\n","weights - weights/best.pt\n","midasnet_freeze - True\n","Using cache found in /root/.cache/torch/hub/facebookresearch_WSL-Images_master\n","Caching labels (2623 found, 114 missing, 30 empty, 0 duplicate, for 2767 images): 100% 2767/2767 [00:03<00:00, 775.37it/s]\n","Caching images (1.2GB): 100% 2767/2767 [01:39<00:00, 27.90it/s]\n","Caching labels (657 found, 27 missing, 8 empty, 0 duplicate, for 692 images): 100% 692/692 [00:00<00:00, 771.62it/s]\n","Caching images (0.2GB): 100% 692/692 [00:26<00:00, 26.25it/s]\n","Freezing the midasnet\n","YMP Model Summary\n","----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","            Conv2d-1         [-1, 64, 224, 224]           9,408\n","       BatchNorm2d-2         [-1, 64, 224, 224]             128\n","              ReLU-3         [-1, 64, 224, 224]               0\n","         MaxPool2d-4         [-1, 64, 112, 112]               0\n","            Conv2d-5        [-1, 256, 112, 112]          16,384\n","       BatchNorm2d-6        [-1, 256, 112, 112]             512\n","              ReLU-7        [-1, 256, 112, 112]               0\n","            Conv2d-8        [-1, 256, 112, 112]          18,432\n","       BatchNorm2d-9        [-1, 256, 112, 112]             512\n","             ReLU-10        [-1, 256, 112, 112]               0\n","           Conv2d-11        [-1, 256, 112, 112]          65,536\n","      BatchNorm2d-12        [-1, 256, 112, 112]             512\n","           Conv2d-13        [-1, 256, 112, 112]          16,384\n","      BatchNorm2d-14        [-1, 256, 112, 112]             512\n","             ReLU-15        [-1, 256, 112, 112]               0\n","       Bottleneck-16        [-1, 256, 112, 112]               0\n","           Conv2d-17        [-1, 256, 112, 112]          65,536\n","      BatchNorm2d-18        [-1, 256, 112, 112]             512\n","             ReLU-19        [-1, 256, 112, 112]               0\n","           Conv2d-20        [-1, 256, 112, 112]          18,432\n","      BatchNorm2d-21        [-1, 256, 112, 112]             512\n","             ReLU-22        [-1, 256, 112, 112]               0\n","           Conv2d-23        [-1, 256, 112, 112]          65,536\n","      BatchNorm2d-24        [-1, 256, 112, 112]             512\n","             ReLU-25        [-1, 256, 112, 112]               0\n","       Bottleneck-26        [-1, 256, 112, 112]               0\n","           Conv2d-27        [-1, 256, 112, 112]          65,536\n","      BatchNorm2d-28        [-1, 256, 112, 112]             512\n","             ReLU-29        [-1, 256, 112, 112]               0\n","           Conv2d-30        [-1, 256, 112, 112]          18,432\n","      BatchNorm2d-31        [-1, 256, 112, 112]             512\n","             ReLU-32        [-1, 256, 112, 112]               0\n","           Conv2d-33        [-1, 256, 112, 112]          65,536\n","      BatchNorm2d-34        [-1, 256, 112, 112]             512\n","             ReLU-35        [-1, 256, 112, 112]               0\n","       Bottleneck-36        [-1, 256, 112, 112]               0\n","           Conv2d-37        [-1, 512, 112, 112]         131,072\n","      BatchNorm2d-38        [-1, 512, 112, 112]           1,024\n","             ReLU-39        [-1, 512, 112, 112]               0\n","           Conv2d-40          [-1, 512, 56, 56]          73,728\n","      BatchNorm2d-41          [-1, 512, 56, 56]           1,024\n","             ReLU-42          [-1, 512, 56, 56]               0\n","           Conv2d-43          [-1, 512, 56, 56]         262,144\n","      BatchNorm2d-44          [-1, 512, 56, 56]           1,024\n","           Conv2d-45          [-1, 512, 56, 56]         131,072\n","      BatchNorm2d-46          [-1, 512, 56, 56]           1,024\n","             ReLU-47          [-1, 512, 56, 56]               0\n","       Bottleneck-48          [-1, 512, 56, 56]               0\n","           Conv2d-49          [-1, 512, 56, 56]         262,144\n","      BatchNorm2d-50          [-1, 512, 56, 56]           1,024\n","             ReLU-51          [-1, 512, 56, 56]               0\n","           Conv2d-52          [-1, 512, 56, 56]          73,728\n","      BatchNorm2d-53          [-1, 512, 56, 56]           1,024\n","             ReLU-54          [-1, 512, 56, 56]               0\n","           Conv2d-55          [-1, 512, 56, 56]         262,144\n","      BatchNorm2d-56          [-1, 512, 56, 56]           1,024\n","             ReLU-57          [-1, 512, 56, 56]               0\n","       Bottleneck-58          [-1, 512, 56, 56]               0\n","           Conv2d-59          [-1, 512, 56, 56]         262,144\n","      BatchNorm2d-60          [-1, 512, 56, 56]           1,024\n","             ReLU-61          [-1, 512, 56, 56]               0\n","           Conv2d-62          [-1, 512, 56, 56]          73,728\n","      BatchNorm2d-63          [-1, 512, 56, 56]           1,024\n","             ReLU-64          [-1, 512, 56, 56]               0\n","           Conv2d-65          [-1, 512, 56, 56]         262,144\n","      BatchNorm2d-66          [-1, 512, 56, 56]           1,024\n","             ReLU-67          [-1, 512, 56, 56]               0\n","       Bottleneck-68          [-1, 512, 56, 56]               0\n","           Conv2d-69          [-1, 512, 56, 56]         262,144\n","      BatchNorm2d-70          [-1, 512, 56, 56]           1,024\n","             ReLU-71          [-1, 512, 56, 56]               0\n","           Conv2d-72          [-1, 512, 56, 56]          73,728\n","      BatchNorm2d-73          [-1, 512, 56, 56]           1,024\n","             ReLU-74          [-1, 512, 56, 56]               0\n","           Conv2d-75          [-1, 512, 56, 56]         262,144\n","      BatchNorm2d-76          [-1, 512, 56, 56]           1,024\n","             ReLU-77          [-1, 512, 56, 56]               0\n","       Bottleneck-78          [-1, 512, 56, 56]               0\n","           Conv2d-79         [-1, 1024, 56, 56]         524,288\n","      BatchNorm2d-80         [-1, 1024, 56, 56]           2,048\n","             ReLU-81         [-1, 1024, 56, 56]               0\n","           Conv2d-82         [-1, 1024, 28, 28]         294,912\n","      BatchNorm2d-83         [-1, 1024, 28, 28]           2,048\n","             ReLU-84         [-1, 1024, 28, 28]               0\n","           Conv2d-85         [-1, 1024, 28, 28]       1,048,576\n","      BatchNorm2d-86         [-1, 1024, 28, 28]           2,048\n","           Conv2d-87         [-1, 1024, 28, 28]         524,288\n","      BatchNorm2d-88         [-1, 1024, 28, 28]           2,048\n","             ReLU-89         [-1, 1024, 28, 28]               0\n","       Bottleneck-90         [-1, 1024, 28, 28]               0\n","           Conv2d-91         [-1, 1024, 28, 28]       1,048,576\n","      BatchNorm2d-92         [-1, 1024, 28, 28]           2,048\n","             ReLU-93         [-1, 1024, 28, 28]               0\n","           Conv2d-94         [-1, 1024, 28, 28]         294,912\n","      BatchNorm2d-95         [-1, 1024, 28, 28]           2,048\n","             ReLU-96         [-1, 1024, 28, 28]               0\n","           Conv2d-97         [-1, 1024, 28, 28]       1,048,576\n","      BatchNorm2d-98         [-1, 1024, 28, 28]           2,048\n","             ReLU-99         [-1, 1024, 28, 28]               0\n","      Bottleneck-100         [-1, 1024, 28, 28]               0\n","          Conv2d-101         [-1, 1024, 28, 28]       1,048,576\n","     BatchNorm2d-102         [-1, 1024, 28, 28]           2,048\n","            ReLU-103         [-1, 1024, 28, 28]               0\n","          Conv2d-104         [-1, 1024, 28, 28]         294,912\n","     BatchNorm2d-105         [-1, 1024, 28, 28]           2,048\n","            ReLU-106         [-1, 1024, 28, 28]               0\n","          Conv2d-107         [-1, 1024, 28, 28]       1,048,576\n","     BatchNorm2d-108         [-1, 1024, 28, 28]           2,048\n","            ReLU-109         [-1, 1024, 28, 28]               0\n","      Bottleneck-110         [-1, 1024, 28, 28]               0\n","          Conv2d-111         [-1, 1024, 28, 28]       1,048,576\n","     BatchNorm2d-112         [-1, 1024, 28, 28]           2,048\n","            ReLU-113         [-1, 1024, 28, 28]               0\n","          Conv2d-114         [-1, 1024, 28, 28]         294,912\n","     BatchNorm2d-115         [-1, 1024, 28, 28]           2,048\n","            ReLU-116         [-1, 1024, 28, 28]               0\n","          Conv2d-117         [-1, 1024, 28, 28]       1,048,576\n","     BatchNorm2d-118         [-1, 1024, 28, 28]           2,048\n","            ReLU-119         [-1, 1024, 28, 28]               0\n","      Bottleneck-120         [-1, 1024, 28, 28]               0\n","          Conv2d-121         [-1, 1024, 28, 28]       1,048,576\n","     BatchNorm2d-122         [-1, 1024, 28, 28]           2,048\n","            ReLU-123         [-1, 1024, 28, 28]               0\n","          Conv2d-124         [-1, 1024, 28, 28]         294,912\n","     BatchNorm2d-125         [-1, 1024, 28, 28]           2,048\n","            ReLU-126         [-1, 1024, 28, 28]               0\n","          Conv2d-127         [-1, 1024, 28, 28]       1,048,576\n","     BatchNorm2d-128         [-1, 1024, 28, 28]           2,048\n","            ReLU-129         [-1, 1024, 28, 28]               0\n","      Bottleneck-130         [-1, 1024, 28, 28]               0\n","          Conv2d-131         [-1, 1024, 28, 28]       1,048,576\n","     BatchNorm2d-132         [-1, 1024, 28, 28]           2,048\n","            ReLU-133         [-1, 1024, 28, 28]               0\n","          Conv2d-134         [-1, 1024, 28, 28]         294,912\n","     BatchNorm2d-135         [-1, 1024, 28, 28]           2,048\n","            ReLU-136         [-1, 1024, 28, 28]               0\n","          Conv2d-137         [-1, 1024, 28, 28]       1,048,576\n","     BatchNorm2d-138         [-1, 1024, 28, 28]           2,048\n","            ReLU-139         [-1, 1024, 28, 28]               0\n","      Bottleneck-140         [-1, 1024, 28, 28]               0\n","          Conv2d-141         [-1, 1024, 28, 28]       1,048,576\n","     BatchNorm2d-142         [-1, 1024, 28, 28]           2,048\n","            ReLU-143         [-1, 1024, 28, 28]               0\n","          Conv2d-144         [-1, 1024, 28, 28]         294,912\n","     BatchNorm2d-145         [-1, 1024, 28, 28]           2,048\n","            ReLU-146         [-1, 1024, 28, 28]               0\n","          Conv2d-147         [-1, 1024, 28, 28]       1,048,576\n","     BatchNorm2d-148         [-1, 1024, 28, 28]           2,048\n","            ReLU-149         [-1, 1024, 28, 28]               0\n","      Bottleneck-150         [-1, 1024, 28, 28]               0\n","          Conv2d-151         [-1, 1024, 28, 28]       1,048,576\n","     BatchNorm2d-152         [-1, 1024, 28, 28]           2,048\n","            ReLU-153         [-1, 1024, 28, 28]               0\n","          Conv2d-154         [-1, 1024, 28, 28]         294,912\n","     BatchNorm2d-155         [-1, 1024, 28, 28]           2,048\n","            ReLU-156         [-1, 1024, 28, 28]               0\n","          Conv2d-157         [-1, 1024, 28, 28]       1,048,576\n","     BatchNorm2d-158         [-1, 1024, 28, 28]           2,048\n","            ReLU-159         [-1, 1024, 28, 28]               0\n","      Bottleneck-160         [-1, 1024, 28, 28]               0\n","          Conv2d-161         [-1, 1024, 28, 28]       1,048,576\n","     BatchNorm2d-162         [-1, 1024, 28, 28]           2,048\n","            ReLU-163         [-1, 1024, 28, 28]               0\n","          Conv2d-164         [-1, 1024, 28, 28]         294,912\n","     BatchNorm2d-165         [-1, 1024, 28, 28]           2,048\n","            ReLU-166         [-1, 1024, 28, 28]               0\n","          Conv2d-167         [-1, 1024, 28, 28]       1,048,576\n","     BatchNorm2d-168         [-1, 1024, 28, 28]           2,048\n","            ReLU-169         [-1, 1024, 28, 28]               0\n","      Bottleneck-170         [-1, 1024, 28, 28]               0\n","          Conv2d-171         [-1, 1024, 28, 28]       1,048,576\n","     BatchNorm2d-172         [-1, 1024, 28, 28]           2,048\n","            ReLU-173         [-1, 1024, 28, 28]               0\n","          Conv2d-174         [-1, 1024, 28, 28]         294,912\n","     BatchNorm2d-175         [-1, 1024, 28, 28]           2,048\n","            ReLU-176         [-1, 1024, 28, 28]               0\n","          Conv2d-177         [-1, 1024, 28, 28]       1,048,576\n","     BatchNorm2d-178         [-1, 1024, 28, 28]           2,048\n","            ReLU-179         [-1, 1024, 28, 28]               0\n","      Bottleneck-180         [-1, 1024, 28, 28]               0\n","          Conv2d-181         [-1, 1024, 28, 28]       1,048,576\n","     BatchNorm2d-182         [-1, 1024, 28, 28]           2,048\n","            ReLU-183         [-1, 1024, 28, 28]               0\n","          Conv2d-184         [-1, 1024, 28, 28]         294,912\n","     BatchNorm2d-185         [-1, 1024, 28, 28]           2,048\n","            ReLU-186         [-1, 1024, 28, 28]               0\n","          Conv2d-187         [-1, 1024, 28, 28]       1,048,576\n","     BatchNorm2d-188         [-1, 1024, 28, 28]           2,048\n","            ReLU-189         [-1, 1024, 28, 28]               0\n","      Bottleneck-190         [-1, 1024, 28, 28]               0\n","          Conv2d-191         [-1, 1024, 28, 28]       1,048,576\n","     BatchNorm2d-192         [-1, 1024, 28, 28]           2,048\n","            ReLU-193         [-1, 1024, 28, 28]               0\n","          Conv2d-194         [-1, 1024, 28, 28]         294,912\n","     BatchNorm2d-195         [-1, 1024, 28, 28]           2,048\n","            ReLU-196         [-1, 1024, 28, 28]               0\n","          Conv2d-197         [-1, 1024, 28, 28]       1,048,576\n","     BatchNorm2d-198         [-1, 1024, 28, 28]           2,048\n","            ReLU-199         [-1, 1024, 28, 28]               0\n","      Bottleneck-200         [-1, 1024, 28, 28]               0\n","          Conv2d-201         [-1, 1024, 28, 28]       1,048,576\n","     BatchNorm2d-202         [-1, 1024, 28, 28]           2,048\n","            ReLU-203         [-1, 1024, 28, 28]               0\n","          Conv2d-204         [-1, 1024, 28, 28]         294,912\n","     BatchNorm2d-205         [-1, 1024, 28, 28]           2,048\n","            ReLU-206         [-1, 1024, 28, 28]               0\n","          Conv2d-207         [-1, 1024, 28, 28]       1,048,576\n","     BatchNorm2d-208         [-1, 1024, 28, 28]           2,048\n","            ReLU-209         [-1, 1024, 28, 28]               0\n","      Bottleneck-210         [-1, 1024, 28, 28]               0\n","          Conv2d-211         [-1, 1024, 28, 28]       1,048,576\n","     BatchNorm2d-212         [-1, 1024, 28, 28]           2,048\n","            ReLU-213         [-1, 1024, 28, 28]               0\n","          Conv2d-214         [-1, 1024, 28, 28]         294,912\n","     BatchNorm2d-215         [-1, 1024, 28, 28]           2,048\n","            ReLU-216         [-1, 1024, 28, 28]               0\n","          Conv2d-217         [-1, 1024, 28, 28]       1,048,576\n","     BatchNorm2d-218         [-1, 1024, 28, 28]           2,048\n","            ReLU-219         [-1, 1024, 28, 28]               0\n","      Bottleneck-220         [-1, 1024, 28, 28]               0\n","          Conv2d-221         [-1, 1024, 28, 28]       1,048,576\n","     BatchNorm2d-222         [-1, 1024, 28, 28]           2,048\n","            ReLU-223         [-1, 1024, 28, 28]               0\n","          Conv2d-224         [-1, 1024, 28, 28]         294,912\n","     BatchNorm2d-225         [-1, 1024, 28, 28]           2,048\n","            ReLU-226         [-1, 1024, 28, 28]               0\n","          Conv2d-227         [-1, 1024, 28, 28]       1,048,576\n","     BatchNorm2d-228         [-1, 1024, 28, 28]           2,048\n","            ReLU-229         [-1, 1024, 28, 28]               0\n","      Bottleneck-230         [-1, 1024, 28, 28]               0\n","          Conv2d-231         [-1, 1024, 28, 28]       1,048,576\n","     BatchNorm2d-232         [-1, 1024, 28, 28]           2,048\n","            ReLU-233         [-1, 1024, 28, 28]               0\n","          Conv2d-234         [-1, 1024, 28, 28]         294,912\n","     BatchNorm2d-235         [-1, 1024, 28, 28]           2,048\n","            ReLU-236         [-1, 1024, 28, 28]               0\n","          Conv2d-237         [-1, 1024, 28, 28]       1,048,576\n","     BatchNorm2d-238         [-1, 1024, 28, 28]           2,048\n","            ReLU-239         [-1, 1024, 28, 28]               0\n","      Bottleneck-240         [-1, 1024, 28, 28]               0\n","          Conv2d-241         [-1, 1024, 28, 28]       1,048,576\n","     BatchNorm2d-242         [-1, 1024, 28, 28]           2,048\n","            ReLU-243         [-1, 1024, 28, 28]               0\n","          Conv2d-244         [-1, 1024, 28, 28]         294,912\n","     BatchNorm2d-245         [-1, 1024, 28, 28]           2,048\n","            ReLU-246         [-1, 1024, 28, 28]               0\n","          Conv2d-247         [-1, 1024, 28, 28]       1,048,576\n","     BatchNorm2d-248         [-1, 1024, 28, 28]           2,048\n","            ReLU-249         [-1, 1024, 28, 28]               0\n","      Bottleneck-250         [-1, 1024, 28, 28]               0\n","          Conv2d-251         [-1, 1024, 28, 28]       1,048,576\n","     BatchNorm2d-252         [-1, 1024, 28, 28]           2,048\n","            ReLU-253         [-1, 1024, 28, 28]               0\n","          Conv2d-254         [-1, 1024, 28, 28]         294,912\n","     BatchNorm2d-255         [-1, 1024, 28, 28]           2,048\n","            ReLU-256         [-1, 1024, 28, 28]               0\n","          Conv2d-257         [-1, 1024, 28, 28]       1,048,576\n","     BatchNorm2d-258         [-1, 1024, 28, 28]           2,048\n","            ReLU-259         [-1, 1024, 28, 28]               0\n","      Bottleneck-260         [-1, 1024, 28, 28]               0\n","          Conv2d-261         [-1, 1024, 28, 28]       1,048,576\n","     BatchNorm2d-262         [-1, 1024, 28, 28]           2,048\n","            ReLU-263         [-1, 1024, 28, 28]               0\n","          Conv2d-264         [-1, 1024, 28, 28]         294,912\n","     BatchNorm2d-265         [-1, 1024, 28, 28]           2,048\n","            ReLU-266         [-1, 1024, 28, 28]               0\n","          Conv2d-267         [-1, 1024, 28, 28]       1,048,576\n","     BatchNorm2d-268         [-1, 1024, 28, 28]           2,048\n","            ReLU-269         [-1, 1024, 28, 28]               0\n","      Bottleneck-270         [-1, 1024, 28, 28]               0\n","          Conv2d-271         [-1, 1024, 28, 28]       1,048,576\n","     BatchNorm2d-272         [-1, 1024, 28, 28]           2,048\n","            ReLU-273         [-1, 1024, 28, 28]               0\n","          Conv2d-274         [-1, 1024, 28, 28]         294,912\n","     BatchNorm2d-275         [-1, 1024, 28, 28]           2,048\n","            ReLU-276         [-1, 1024, 28, 28]               0\n","          Conv2d-277         [-1, 1024, 28, 28]       1,048,576\n","     BatchNorm2d-278         [-1, 1024, 28, 28]           2,048\n","            ReLU-279         [-1, 1024, 28, 28]               0\n","      Bottleneck-280         [-1, 1024, 28, 28]               0\n","          Conv2d-281         [-1, 1024, 28, 28]       1,048,576\n","     BatchNorm2d-282         [-1, 1024, 28, 28]           2,048\n","            ReLU-283         [-1, 1024, 28, 28]               0\n","          Conv2d-284         [-1, 1024, 28, 28]         294,912\n","     BatchNorm2d-285         [-1, 1024, 28, 28]           2,048\n","            ReLU-286         [-1, 1024, 28, 28]               0\n","          Conv2d-287         [-1, 1024, 28, 28]       1,048,576\n","     BatchNorm2d-288         [-1, 1024, 28, 28]           2,048\n","            ReLU-289         [-1, 1024, 28, 28]               0\n","      Bottleneck-290         [-1, 1024, 28, 28]               0\n","          Conv2d-291         [-1, 1024, 28, 28]       1,048,576\n","     BatchNorm2d-292         [-1, 1024, 28, 28]           2,048\n","            ReLU-293         [-1, 1024, 28, 28]               0\n","          Conv2d-294         [-1, 1024, 28, 28]         294,912\n","     BatchNorm2d-295         [-1, 1024, 28, 28]           2,048\n","            ReLU-296         [-1, 1024, 28, 28]               0\n","          Conv2d-297         [-1, 1024, 28, 28]       1,048,576\n","     BatchNorm2d-298         [-1, 1024, 28, 28]           2,048\n","            ReLU-299         [-1, 1024, 28, 28]               0\n","      Bottleneck-300         [-1, 1024, 28, 28]               0\n","          Conv2d-301         [-1, 1024, 28, 28]       1,048,576\n","     BatchNorm2d-302         [-1, 1024, 28, 28]           2,048\n","            ReLU-303         [-1, 1024, 28, 28]               0\n","          Conv2d-304         [-1, 1024, 28, 28]         294,912\n","     BatchNorm2d-305         [-1, 1024, 28, 28]           2,048\n","            ReLU-306         [-1, 1024, 28, 28]               0\n","          Conv2d-307         [-1, 1024, 28, 28]       1,048,576\n","     BatchNorm2d-308         [-1, 1024, 28, 28]           2,048\n","            ReLU-309         [-1, 1024, 28, 28]               0\n","      Bottleneck-310         [-1, 1024, 28, 28]               0\n","          Conv2d-311         [-1, 2048, 28, 28]       2,097,152\n","     BatchNorm2d-312         [-1, 2048, 28, 28]           4,096\n","            ReLU-313         [-1, 2048, 28, 28]               0\n","          Conv2d-314         [-1, 2048, 14, 14]       1,179,648\n","     BatchNorm2d-315         [-1, 2048, 14, 14]           4,096\n","            ReLU-316         [-1, 2048, 14, 14]               0\n","          Conv2d-317         [-1, 2048, 14, 14]       4,194,304\n","     BatchNorm2d-318         [-1, 2048, 14, 14]           4,096\n","          Conv2d-319         [-1, 2048, 14, 14]       2,097,152\n","     BatchNorm2d-320         [-1, 2048, 14, 14]           4,096\n","            ReLU-321         [-1, 2048, 14, 14]               0\n","      Bottleneck-322         [-1, 2048, 14, 14]               0\n","          Conv2d-323         [-1, 2048, 14, 14]       4,194,304\n","     BatchNorm2d-324         [-1, 2048, 14, 14]           4,096\n","            ReLU-325         [-1, 2048, 14, 14]               0\n","          Conv2d-326         [-1, 2048, 14, 14]       1,179,648\n","     BatchNorm2d-327         [-1, 2048, 14, 14]           4,096\n","            ReLU-328         [-1, 2048, 14, 14]               0\n","          Conv2d-329         [-1, 2048, 14, 14]       4,194,304\n","     BatchNorm2d-330         [-1, 2048, 14, 14]           4,096\n","            ReLU-331         [-1, 2048, 14, 14]               0\n","      Bottleneck-332         [-1, 2048, 14, 14]               0\n","          Conv2d-333         [-1, 2048, 14, 14]       4,194,304\n","     BatchNorm2d-334         [-1, 2048, 14, 14]           4,096\n","            ReLU-335         [-1, 2048, 14, 14]               0\n","          Conv2d-336         [-1, 2048, 14, 14]       1,179,648\n","     BatchNorm2d-337         [-1, 2048, 14, 14]           4,096\n","            ReLU-338         [-1, 2048, 14, 14]               0\n","          Conv2d-339         [-1, 2048, 14, 14]       4,194,304\n","     BatchNorm2d-340         [-1, 2048, 14, 14]           4,096\n","            ReLU-341         [-1, 2048, 14, 14]               0\n","      Bottleneck-342         [-1, 2048, 14, 14]               0\n","          Conv2d-343        [-1, 256, 112, 112]         589,824\n","          Conv2d-344          [-1, 256, 56, 56]       1,179,648\n","          Conv2d-345          [-1, 256, 28, 28]       2,359,296\n","          Conv2d-346          [-1, 256, 14, 14]       4,718,592\n","            ReLU-347          [-1, 256, 14, 14]               0\n","          Conv2d-348          [-1, 256, 14, 14]         590,080\n","            ReLU-349          [-1, 256, 14, 14]               0\n","          Conv2d-350          [-1, 256, 14, 14]         590,080\n","ResidualConvUnit-351          [-1, 256, 14, 14]               0\n","FeatureFusionBlock-352          [-1, 256, 28, 28]               0\n","            ReLU-353          [-1, 256, 28, 28]               0\n","          Conv2d-354          [-1, 256, 28, 28]         590,080\n","            ReLU-355          [-1, 256, 28, 28]               0\n","          Conv2d-356          [-1, 256, 28, 28]         590,080\n","ResidualConvUnit-357          [-1, 256, 28, 28]               0\n","            ReLU-358          [-1, 256, 28, 28]               0\n","          Conv2d-359          [-1, 256, 28, 28]         590,080\n","            ReLU-360          [-1, 256, 28, 28]               0\n","          Conv2d-361          [-1, 256, 28, 28]         590,080\n","ResidualConvUnit-362          [-1, 256, 28, 28]               0\n","FeatureFusionBlock-363          [-1, 256, 56, 56]               0\n","            ReLU-364          [-1, 256, 56, 56]               0\n","          Conv2d-365          [-1, 256, 56, 56]         590,080\n","            ReLU-366          [-1, 256, 56, 56]               0\n","          Conv2d-367          [-1, 256, 56, 56]         590,080\n","ResidualConvUnit-368          [-1, 256, 56, 56]               0\n","            ReLU-369          [-1, 256, 56, 56]               0\n","          Conv2d-370          [-1, 256, 56, 56]         590,080\n","            ReLU-371          [-1, 256, 56, 56]               0\n","          Conv2d-372          [-1, 256, 56, 56]         590,080\n","ResidualConvUnit-373          [-1, 256, 56, 56]               0\n","FeatureFusionBlock-374        [-1, 256, 112, 112]               0\n","            ReLU-375        [-1, 256, 112, 112]               0\n","          Conv2d-376        [-1, 256, 112, 112]         590,080\n","            ReLU-377        [-1, 256, 112, 112]               0\n","          Conv2d-378        [-1, 256, 112, 112]         590,080\n","ResidualConvUnit-379        [-1, 256, 112, 112]               0\n","            ReLU-380        [-1, 256, 112, 112]               0\n","          Conv2d-381        [-1, 256, 112, 112]         590,080\n","            ReLU-382        [-1, 256, 112, 112]               0\n","          Conv2d-383        [-1, 256, 112, 112]         590,080\n","ResidualConvUnit-384        [-1, 256, 112, 112]               0\n","FeatureFusionBlock-385        [-1, 256, 224, 224]               0\n","          Conv2d-386        [-1, 128, 224, 224]         295,040\n","     Interpolate-387        [-1, 128, 448, 448]               0\n","          Conv2d-388         [-1, 32, 448, 448]          36,896\n","            ReLU-389         [-1, 32, 448, 448]               0\n","          Conv2d-390          [-1, 1, 448, 448]              33\n","            ReLU-391          [-1, 1, 448, 448]               0\n","          Conv2d-392        [-1, 256, 224, 224]           6,912\n","     BatchNorm2d-393        [-1, 256, 224, 224]             512\n","            ReLU-394        [-1, 256, 224, 224]               0\n","          Conv2d-395        [-1, 256, 112, 112]         589,824\n","     BatchNorm2d-396        [-1, 256, 112, 112]             512\n","            ReLU-397        [-1, 256, 112, 112]               0\n","          Conv2d-398          [-1, 256, 56, 56]         589,824\n","     BatchNorm2d-399          [-1, 256, 56, 56]             512\n","            ReLU-400          [-1, 256, 56, 56]               0\n","          Conv2d-401          [-1, 512, 28, 28]       1,179,648\n","     BatchNorm2d-402          [-1, 512, 28, 28]           1,024\n","            ReLU-403          [-1, 512, 28, 28]               0\n","          Conv2d-404         [-1, 1024, 14, 14]       4,718,592\n","     BatchNorm2d-405         [-1, 1024, 14, 14]           2,048\n","            ReLU-406         [-1, 1024, 14, 14]               0\n","          Conv2d-407         [-1, 1024, 14, 14]       2,097,152\n","     BatchNorm2d-408         [-1, 1024, 14, 14]           2,048\n","            ReLU-409         [-1, 1024, 14, 14]               0\n","          Conv2d-410           [-1, 27, 14, 14]          27,675\n","       YOLOLayer-411         [-1, 3, 14, 14, 9]               0\n","     Interpolate-412         [-1, 1024, 28, 28]               0\n","          Conv2d-413          [-1, 256, 28, 28]         262,144\n","     BatchNorm2d-414          [-1, 256, 28, 28]             512\n","            ReLU-415          [-1, 256, 28, 28]               0\n","          Conv2d-416          [-1, 512, 28, 28]         524,288\n","     BatchNorm2d-417          [-1, 512, 28, 28]           1,024\n","            ReLU-418          [-1, 512, 28, 28]               0\n","          Conv2d-419          [-1, 256, 28, 28]         196,608\n","     BatchNorm2d-420          [-1, 256, 28, 28]             512\n","            ReLU-421          [-1, 256, 28, 28]               0\n","          Conv2d-422          [-1, 512, 28, 28]       1,179,648\n","     BatchNorm2d-423          [-1, 512, 28, 28]           1,024\n","            ReLU-424          [-1, 512, 28, 28]               0\n","          Conv2d-425          [-1, 256, 28, 28]         131,072\n","     BatchNorm2d-426          [-1, 256, 28, 28]             512\n","            ReLU-427          [-1, 256, 28, 28]               0\n","          Conv2d-428          [-1, 512, 28, 28]       1,179,648\n","     BatchNorm2d-429          [-1, 512, 28, 28]           1,024\n","            ReLU-430          [-1, 512, 28, 28]               0\n","          Conv2d-431          [-1, 256, 28, 28]         131,072\n","     BatchNorm2d-432          [-1, 256, 28, 28]             512\n","            ReLU-433          [-1, 256, 28, 28]               0\n","          Conv2d-434          [-1, 512, 28, 28]       1,179,648\n","     BatchNorm2d-435          [-1, 512, 28, 28]           1,024\n","            ReLU-436          [-1, 512, 28, 28]               0\n","          Conv2d-437           [-1, 27, 28, 28]          13,851\n","       YOLOLayer-438         [-1, 3, 28, 28, 9]               0\n","          Conv2d-439          [-1, 256, 56, 56]         131,072\n","     BatchNorm2d-440          [-1, 256, 56, 56]             512\n","            ReLU-441          [-1, 256, 56, 56]               0\n","     Interpolate-442          [-1, 512, 56, 56]               0\n","          Conv2d-443          [-1, 128, 56, 56]          65,536\n","     BatchNorm2d-444          [-1, 128, 56, 56]             256\n","            ReLU-445          [-1, 128, 56, 56]               0\n","          Conv2d-446          [-1, 128, 56, 56]          49,152\n","     BatchNorm2d-447          [-1, 128, 56, 56]             256\n","            ReLU-448          [-1, 128, 56, 56]               0\n","          Conv2d-449          [-1, 256, 56, 56]         294,912\n","     BatchNorm2d-450          [-1, 256, 56, 56]             512\n","            ReLU-451          [-1, 256, 56, 56]               0\n","          Conv2d-452          [-1, 128, 56, 56]          32,768\n","     BatchNorm2d-453          [-1, 128, 56, 56]             256\n","            ReLU-454          [-1, 128, 56, 56]               0\n","          Conv2d-455          [-1, 256, 56, 56]         294,912\n","     BatchNorm2d-456          [-1, 256, 56, 56]             512\n","            ReLU-457          [-1, 256, 56, 56]               0\n","          Conv2d-458          [-1, 128, 56, 56]          32,768\n","     BatchNorm2d-459          [-1, 128, 56, 56]             256\n","            ReLU-460          [-1, 128, 56, 56]               0\n","          Conv2d-461          [-1, 256, 56, 56]         294,912\n","     BatchNorm2d-462          [-1, 256, 56, 56]             512\n","            ReLU-463          [-1, 256, 56, 56]               0\n","          Conv2d-464           [-1, 27, 56, 56]           6,939\n","       YOLOLayer-465         [-1, 3, 56, 56, 9]               0\n","================================================================\n","Total params: 119,409,234\n","Trainable params: 15,226,449\n","Non-trainable params: 104,182,785\n","----------------------------------------------------------------\n","Input size (MB): 2.30\n","Forward/backward pass size (MB): 4511.99\n","Params size (MB): 455.51\n","Estimated Total Size (MB): 4969.80\n","----------------------------------------------------------------\n","Image sizes 448 - 448 train, 448 test\n","Using 4 dataloader workers\n","Starting training for 300 epochs...\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","  0% 0/346 [00:00<?, ?it/s]/usr/local/lib/python3.6/dist-packages/torch/cuda/memory.py:346: FutureWarning: torch.cuda.memory_cached has been renamed to torch.cuda.memory_reserved\n","  FutureWarning)\n","   154/299     4.17G       4.8      1.34     0.856      6.99        21       448: 100% 346/346 [03:42<00:00,  1.56it/s]\n","               Class    Images   Targets         P         R   mAP@0.5        F1:   0% 0/87 [00:00<?, ?it/s]/content/drive/My Drive/computer_vision/capstone_project/yolo_v3/utils/utils.py:544: UserWarning: This overload of nonzero is deprecated:\n","\tnonzero()\n","Consider using one of the following signatures instead:\n","\tnonzero(*, bool as_tuple) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:882.)\n","  i, j = (x[:, 5:] > conf_thres).nonzero().t()\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 87/87 [00:45<00:00,  1.93it/s]\n","                 all       692  3.06e+03      0.25     0.564       0.3     0.346\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","  0% 0/346 [00:00<?, ?it/s]/usr/local/lib/python3.6/dist-packages/torch/cuda/memory.py:346: FutureWarning: torch.cuda.memory_cached has been renamed to torch.cuda.memory_reserved\n","  FutureWarning)\n","   155/299     4.17G      4.71      1.28     0.762      6.75        44       448: 100% 346/346 [03:42<00:00,  1.55it/s]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 87/87 [00:43<00:00,  2.00it/s]\n","                 all       692  3.06e+03     0.256     0.585     0.349     0.355\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","   156/299     4.17G      4.69      1.28     0.785      6.76        53       448: 100% 346/346 [03:42<00:00,  1.55it/s]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 87/87 [00:43<00:00,  2.00it/s]\n","                 all       692  3.06e+03     0.246      0.58     0.337     0.346\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","   157/299     4.17G      4.68      1.26     0.734      6.67        36       448: 100% 346/346 [03:43<00:00,  1.55it/s]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 87/87 [00:43<00:00,  2.00it/s]\n","                 all       692  3.06e+03     0.266     0.577     0.357     0.363\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","   158/299     4.17G      4.67      1.26     0.681      6.61        30       448: 100% 346/346 [03:42<00:00,  1.55it/s]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 87/87 [00:43<00:00,  2.01it/s]\n","                 all       692  3.06e+03     0.249     0.585     0.323     0.349\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","   159/299     4.17G      4.62      1.26     0.699      6.58        49       448: 100% 346/346 [03:42<00:00,  1.56it/s]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 87/87 [00:43<00:00,  2.01it/s]\n","                 all       692  3.06e+03     0.259     0.565     0.335     0.354\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","   160/299     4.17G      4.61      1.25     0.677      6.53        68       448: 100% 346/346 [03:43<00:00,  1.55it/s]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 87/87 [00:43<00:00,  2.00it/s]\n","                 all       692  3.06e+03     0.251     0.585     0.352      0.35\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","   161/299     4.17G      4.61      1.23     0.665      6.51        72       448: 100% 346/346 [03:43<00:00,  1.55it/s]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 87/87 [00:43<00:00,  2.01it/s]\n","                 all       692  3.06e+03     0.257     0.597     0.348     0.359\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","   162/299     4.17G       4.6      1.25     0.615      6.47        30       448: 100% 346/346 [03:42<00:00,  1.55it/s]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 87/87 [00:43<00:00,  2.01it/s]\n","                 all       692  3.06e+03     0.247     0.583     0.327     0.347\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","   163/299     4.17G      4.57      1.24      0.61      6.42        26       448: 100% 346/346 [03:42<00:00,  1.55it/s]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 87/87 [00:43<00:00,  2.01it/s]\n","                 all       692  3.06e+03     0.249      0.58     0.314     0.348\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","   164/299     4.17G      4.57      1.23     0.609      6.41        34       448: 100% 346/346 [03:42<00:00,  1.55it/s]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 87/87 [00:43<00:00,  2.01it/s]\n","                 all       692  3.06e+03     0.247     0.584     0.346     0.347\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","   165/299     4.17G      4.57      1.23     0.615      6.41        45       448: 100% 346/346 [03:42<00:00,  1.56it/s]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 87/87 [00:43<00:00,  2.01it/s]\n","                 all       692  3.06e+03     0.254     0.583     0.338     0.353\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","   166/299     4.17G      4.53      1.22     0.587      6.34        30       448: 100% 346/346 [03:42<00:00,  1.55it/s]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 87/87 [00:43<00:00,  2.01it/s]\n","                 all       692  3.06e+03     0.247     0.588     0.348     0.348\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","   167/299     4.17G      4.53      1.23     0.605      6.37        63       448: 100% 346/346 [03:43<00:00,  1.55it/s]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 87/87 [00:43<00:00,  2.01it/s]\n","                 all       692  3.06e+03     0.243     0.589     0.351     0.344\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","   168/299     4.17G      4.53      1.18     0.607      6.32        49       448:  22% 77/346 [00:50<02:52,  1.56it/s]"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"ZrXqy-qQ9mVJ"},"source":["## Training yolo branch only by freezing the midas layers on 512x512 resolution"]},{"cell_type":"code","metadata":{"id":"MlSzxBEEa0JZ","colab":{"base_uri":"https://localhost:8080/"},"outputId":"4ff6bc3d-33eb-40b5-8f82-d1cf4b6afe57"},"source":["!python train.py --data data/customdata/custom.data --batch 8  --cache --cfg cfg/yolov3-custom.cfg --epochs 300 --weights 'weights/best.pt'  --img-size=512 --midasnet_freeze='True'"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Namespace(accumulate=4, adam=False, batch_size=8, bucket='', cache_images=True, cfg='cfg/yolov3-custom.cfg', data='data/customdata/custom.data', device='', epochs=300, evolve=False, img_size=[512], init_train='False', midas_weights='', midasnet_freeze='True', multi_scale=False, name='', nosave=False, notest=False, rect=False, resume=False, single_cls=False, weights='weights/best.pt', yolo_weights='')\n","Using CUDA device0 _CudaDeviceProperties(name='Tesla P100-PCIE-16GB', total_memory=16280MB)\n","\n","2020-11-14 15:42:10.266764: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n","Run 'tensorboard --logdir=runs' to view tensorboard at http://localhost:6006/\n","cfg - cfg/yolov3-custom.cfg\n","data - data/customdata/custom.data\n","epochs - 300\n","batch_size - 8\n","accumulate - 4\n","yolo weights - \n","midas weights - \n","imgsz_min- 512, imgsz_max- 512, imgsz_test- 512\n","opt.rect - False\n","train_path - data/customdata/train.txt\n","test_path - data/customdata/test.txt\n","init_train - False\n","weights - weights/best.pt\n","midasnet_freeze - True\n","Using cache found in /root/.cache/torch/hub/facebookresearch_WSL-Images_master\n","Caching labels (2623 found, 114 missing, 30 empty, 0 duplicate, for 2767 images): 100% 2767/2767 [00:04<00:00, 663.41it/s]\n","Caching images (1.5GB): 100% 2767/2767 [01:26<00:00, 32.05it/s]\n","Caching labels (657 found, 27 missing, 8 empty, 0 duplicate, for 692 images): 100% 692/692 [00:00<00:00, 817.02it/s]\n","Caching images (0.3GB): 100% 692/692 [00:22<00:00, 30.45it/s]\n","Freezing the midasnet\n","YMP Model Summary\n","----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","            Conv2d-1         [-1, 64, 256, 256]           9,408\n","       BatchNorm2d-2         [-1, 64, 256, 256]             128\n","              ReLU-3         [-1, 64, 256, 256]               0\n","         MaxPool2d-4         [-1, 64, 128, 128]               0\n","            Conv2d-5        [-1, 256, 128, 128]          16,384\n","       BatchNorm2d-6        [-1, 256, 128, 128]             512\n","              ReLU-7        [-1, 256, 128, 128]               0\n","            Conv2d-8        [-1, 256, 128, 128]          18,432\n","       BatchNorm2d-9        [-1, 256, 128, 128]             512\n","             ReLU-10        [-1, 256, 128, 128]               0\n","           Conv2d-11        [-1, 256, 128, 128]          65,536\n","      BatchNorm2d-12        [-1, 256, 128, 128]             512\n","           Conv2d-13        [-1, 256, 128, 128]          16,384\n","      BatchNorm2d-14        [-1, 256, 128, 128]             512\n","             ReLU-15        [-1, 256, 128, 128]               0\n","       Bottleneck-16        [-1, 256, 128, 128]               0\n","           Conv2d-17        [-1, 256, 128, 128]          65,536\n","      BatchNorm2d-18        [-1, 256, 128, 128]             512\n","             ReLU-19        [-1, 256, 128, 128]               0\n","           Conv2d-20        [-1, 256, 128, 128]          18,432\n","      BatchNorm2d-21        [-1, 256, 128, 128]             512\n","             ReLU-22        [-1, 256, 128, 128]               0\n","           Conv2d-23        [-1, 256, 128, 128]          65,536\n","      BatchNorm2d-24        [-1, 256, 128, 128]             512\n","             ReLU-25        [-1, 256, 128, 128]               0\n","       Bottleneck-26        [-1, 256, 128, 128]               0\n","           Conv2d-27        [-1, 256, 128, 128]          65,536\n","      BatchNorm2d-28        [-1, 256, 128, 128]             512\n","             ReLU-29        [-1, 256, 128, 128]               0\n","           Conv2d-30        [-1, 256, 128, 128]          18,432\n","      BatchNorm2d-31        [-1, 256, 128, 128]             512\n","             ReLU-32        [-1, 256, 128, 128]               0\n","           Conv2d-33        [-1, 256, 128, 128]          65,536\n","      BatchNorm2d-34        [-1, 256, 128, 128]             512\n","             ReLU-35        [-1, 256, 128, 128]               0\n","       Bottleneck-36        [-1, 256, 128, 128]               0\n","           Conv2d-37        [-1, 512, 128, 128]         131,072\n","      BatchNorm2d-38        [-1, 512, 128, 128]           1,024\n","             ReLU-39        [-1, 512, 128, 128]               0\n","           Conv2d-40          [-1, 512, 64, 64]          73,728\n","      BatchNorm2d-41          [-1, 512, 64, 64]           1,024\n","             ReLU-42          [-1, 512, 64, 64]               0\n","           Conv2d-43          [-1, 512, 64, 64]         262,144\n","      BatchNorm2d-44          [-1, 512, 64, 64]           1,024\n","           Conv2d-45          [-1, 512, 64, 64]         131,072\n","      BatchNorm2d-46          [-1, 512, 64, 64]           1,024\n","             ReLU-47          [-1, 512, 64, 64]               0\n","       Bottleneck-48          [-1, 512, 64, 64]               0\n","           Conv2d-49          [-1, 512, 64, 64]         262,144\n","      BatchNorm2d-50          [-1, 512, 64, 64]           1,024\n","             ReLU-51          [-1, 512, 64, 64]               0\n","           Conv2d-52          [-1, 512, 64, 64]          73,728\n","      BatchNorm2d-53          [-1, 512, 64, 64]           1,024\n","             ReLU-54          [-1, 512, 64, 64]               0\n","           Conv2d-55          [-1, 512, 64, 64]         262,144\n","      BatchNorm2d-56          [-1, 512, 64, 64]           1,024\n","             ReLU-57          [-1, 512, 64, 64]               0\n","       Bottleneck-58          [-1, 512, 64, 64]               0\n","           Conv2d-59          [-1, 512, 64, 64]         262,144\n","      BatchNorm2d-60          [-1, 512, 64, 64]           1,024\n","             ReLU-61          [-1, 512, 64, 64]               0\n","           Conv2d-62          [-1, 512, 64, 64]          73,728\n","      BatchNorm2d-63          [-1, 512, 64, 64]           1,024\n","             ReLU-64          [-1, 512, 64, 64]               0\n","           Conv2d-65          [-1, 512, 64, 64]         262,144\n","      BatchNorm2d-66          [-1, 512, 64, 64]           1,024\n","             ReLU-67          [-1, 512, 64, 64]               0\n","       Bottleneck-68          [-1, 512, 64, 64]               0\n","           Conv2d-69          [-1, 512, 64, 64]         262,144\n","      BatchNorm2d-70          [-1, 512, 64, 64]           1,024\n","             ReLU-71          [-1, 512, 64, 64]               0\n","           Conv2d-72          [-1, 512, 64, 64]          73,728\n","      BatchNorm2d-73          [-1, 512, 64, 64]           1,024\n","             ReLU-74          [-1, 512, 64, 64]               0\n","           Conv2d-75          [-1, 512, 64, 64]         262,144\n","      BatchNorm2d-76          [-1, 512, 64, 64]           1,024\n","             ReLU-77          [-1, 512, 64, 64]               0\n","       Bottleneck-78          [-1, 512, 64, 64]               0\n","           Conv2d-79         [-1, 1024, 64, 64]         524,288\n","      BatchNorm2d-80         [-1, 1024, 64, 64]           2,048\n","             ReLU-81         [-1, 1024, 64, 64]               0\n","           Conv2d-82         [-1, 1024, 32, 32]         294,912\n","      BatchNorm2d-83         [-1, 1024, 32, 32]           2,048\n","             ReLU-84         [-1, 1024, 32, 32]               0\n","           Conv2d-85         [-1, 1024, 32, 32]       1,048,576\n","      BatchNorm2d-86         [-1, 1024, 32, 32]           2,048\n","           Conv2d-87         [-1, 1024, 32, 32]         524,288\n","      BatchNorm2d-88         [-1, 1024, 32, 32]           2,048\n","             ReLU-89         [-1, 1024, 32, 32]               0\n","       Bottleneck-90         [-1, 1024, 32, 32]               0\n","           Conv2d-91         [-1, 1024, 32, 32]       1,048,576\n","      BatchNorm2d-92         [-1, 1024, 32, 32]           2,048\n","             ReLU-93         [-1, 1024, 32, 32]               0\n","           Conv2d-94         [-1, 1024, 32, 32]         294,912\n","      BatchNorm2d-95         [-1, 1024, 32, 32]           2,048\n","             ReLU-96         [-1, 1024, 32, 32]               0\n","           Conv2d-97         [-1, 1024, 32, 32]       1,048,576\n","      BatchNorm2d-98         [-1, 1024, 32, 32]           2,048\n","             ReLU-99         [-1, 1024, 32, 32]               0\n","      Bottleneck-100         [-1, 1024, 32, 32]               0\n","          Conv2d-101         [-1, 1024, 32, 32]       1,048,576\n","     BatchNorm2d-102         [-1, 1024, 32, 32]           2,048\n","            ReLU-103         [-1, 1024, 32, 32]               0\n","          Conv2d-104         [-1, 1024, 32, 32]         294,912\n","     BatchNorm2d-105         [-1, 1024, 32, 32]           2,048\n","            ReLU-106         [-1, 1024, 32, 32]               0\n","          Conv2d-107         [-1, 1024, 32, 32]       1,048,576\n","     BatchNorm2d-108         [-1, 1024, 32, 32]           2,048\n","            ReLU-109         [-1, 1024, 32, 32]               0\n","      Bottleneck-110         [-1, 1024, 32, 32]               0\n","          Conv2d-111         [-1, 1024, 32, 32]       1,048,576\n","     BatchNorm2d-112         [-1, 1024, 32, 32]           2,048\n","            ReLU-113         [-1, 1024, 32, 32]               0\n","          Conv2d-114         [-1, 1024, 32, 32]         294,912\n","     BatchNorm2d-115         [-1, 1024, 32, 32]           2,048\n","            ReLU-116         [-1, 1024, 32, 32]               0\n","          Conv2d-117         [-1, 1024, 32, 32]       1,048,576\n","     BatchNorm2d-118         [-1, 1024, 32, 32]           2,048\n","            ReLU-119         [-1, 1024, 32, 32]               0\n","      Bottleneck-120         [-1, 1024, 32, 32]               0\n","          Conv2d-121         [-1, 1024, 32, 32]       1,048,576\n","     BatchNorm2d-122         [-1, 1024, 32, 32]           2,048\n","            ReLU-123         [-1, 1024, 32, 32]               0\n","          Conv2d-124         [-1, 1024, 32, 32]         294,912\n","     BatchNorm2d-125         [-1, 1024, 32, 32]           2,048\n","            ReLU-126         [-1, 1024, 32, 32]               0\n","          Conv2d-127         [-1, 1024, 32, 32]       1,048,576\n","     BatchNorm2d-128         [-1, 1024, 32, 32]           2,048\n","            ReLU-129         [-1, 1024, 32, 32]               0\n","      Bottleneck-130         [-1, 1024, 32, 32]               0\n","          Conv2d-131         [-1, 1024, 32, 32]       1,048,576\n","     BatchNorm2d-132         [-1, 1024, 32, 32]           2,048\n","            ReLU-133         [-1, 1024, 32, 32]               0\n","          Conv2d-134         [-1, 1024, 32, 32]         294,912\n","     BatchNorm2d-135         [-1, 1024, 32, 32]           2,048\n","            ReLU-136         [-1, 1024, 32, 32]               0\n","          Conv2d-137         [-1, 1024, 32, 32]       1,048,576\n","     BatchNorm2d-138         [-1, 1024, 32, 32]           2,048\n","            ReLU-139         [-1, 1024, 32, 32]               0\n","      Bottleneck-140         [-1, 1024, 32, 32]               0\n","          Conv2d-141         [-1, 1024, 32, 32]       1,048,576\n","     BatchNorm2d-142         [-1, 1024, 32, 32]           2,048\n","            ReLU-143         [-1, 1024, 32, 32]               0\n","          Conv2d-144         [-1, 1024, 32, 32]         294,912\n","     BatchNorm2d-145         [-1, 1024, 32, 32]           2,048\n","            ReLU-146         [-1, 1024, 32, 32]               0\n","          Conv2d-147         [-1, 1024, 32, 32]       1,048,576\n","     BatchNorm2d-148         [-1, 1024, 32, 32]           2,048\n","            ReLU-149         [-1, 1024, 32, 32]               0\n","      Bottleneck-150         [-1, 1024, 32, 32]               0\n","          Conv2d-151         [-1, 1024, 32, 32]       1,048,576\n","     BatchNorm2d-152         [-1, 1024, 32, 32]           2,048\n","            ReLU-153         [-1, 1024, 32, 32]               0\n","          Conv2d-154         [-1, 1024, 32, 32]         294,912\n","     BatchNorm2d-155         [-1, 1024, 32, 32]           2,048\n","            ReLU-156         [-1, 1024, 32, 32]               0\n","          Conv2d-157         [-1, 1024, 32, 32]       1,048,576\n","     BatchNorm2d-158         [-1, 1024, 32, 32]           2,048\n","            ReLU-159         [-1, 1024, 32, 32]               0\n","      Bottleneck-160         [-1, 1024, 32, 32]               0\n","          Conv2d-161         [-1, 1024, 32, 32]       1,048,576\n","     BatchNorm2d-162         [-1, 1024, 32, 32]           2,048\n","            ReLU-163         [-1, 1024, 32, 32]               0\n","          Conv2d-164         [-1, 1024, 32, 32]         294,912\n","     BatchNorm2d-165         [-1, 1024, 32, 32]           2,048\n","            ReLU-166         [-1, 1024, 32, 32]               0\n","          Conv2d-167         [-1, 1024, 32, 32]       1,048,576\n","     BatchNorm2d-168         [-1, 1024, 32, 32]           2,048\n","            ReLU-169         [-1, 1024, 32, 32]               0\n","      Bottleneck-170         [-1, 1024, 32, 32]               0\n","          Conv2d-171         [-1, 1024, 32, 32]       1,048,576\n","     BatchNorm2d-172         [-1, 1024, 32, 32]           2,048\n","            ReLU-173         [-1, 1024, 32, 32]               0\n","          Conv2d-174         [-1, 1024, 32, 32]         294,912\n","     BatchNorm2d-175         [-1, 1024, 32, 32]           2,048\n","            ReLU-176         [-1, 1024, 32, 32]               0\n","          Conv2d-177         [-1, 1024, 32, 32]       1,048,576\n","     BatchNorm2d-178         [-1, 1024, 32, 32]           2,048\n","            ReLU-179         [-1, 1024, 32, 32]               0\n","      Bottleneck-180         [-1, 1024, 32, 32]               0\n","          Conv2d-181         [-1, 1024, 32, 32]       1,048,576\n","     BatchNorm2d-182         [-1, 1024, 32, 32]           2,048\n","            ReLU-183         [-1, 1024, 32, 32]               0\n","          Conv2d-184         [-1, 1024, 32, 32]         294,912\n","     BatchNorm2d-185         [-1, 1024, 32, 32]           2,048\n","            ReLU-186         [-1, 1024, 32, 32]               0\n","          Conv2d-187         [-1, 1024, 32, 32]       1,048,576\n","     BatchNorm2d-188         [-1, 1024, 32, 32]           2,048\n","            ReLU-189         [-1, 1024, 32, 32]               0\n","      Bottleneck-190         [-1, 1024, 32, 32]               0\n","          Conv2d-191         [-1, 1024, 32, 32]       1,048,576\n","     BatchNorm2d-192         [-1, 1024, 32, 32]           2,048\n","            ReLU-193         [-1, 1024, 32, 32]               0\n","          Conv2d-194         [-1, 1024, 32, 32]         294,912\n","     BatchNorm2d-195         [-1, 1024, 32, 32]           2,048\n","            ReLU-196         [-1, 1024, 32, 32]               0\n","          Conv2d-197         [-1, 1024, 32, 32]       1,048,576\n","     BatchNorm2d-198         [-1, 1024, 32, 32]           2,048\n","            ReLU-199         [-1, 1024, 32, 32]               0\n","      Bottleneck-200         [-1, 1024, 32, 32]               0\n","          Conv2d-201         [-1, 1024, 32, 32]       1,048,576\n","     BatchNorm2d-202         [-1, 1024, 32, 32]           2,048\n","            ReLU-203         [-1, 1024, 32, 32]               0\n","          Conv2d-204         [-1, 1024, 32, 32]         294,912\n","     BatchNorm2d-205         [-1, 1024, 32, 32]           2,048\n","            ReLU-206         [-1, 1024, 32, 32]               0\n","          Conv2d-207         [-1, 1024, 32, 32]       1,048,576\n","     BatchNorm2d-208         [-1, 1024, 32, 32]           2,048\n","            ReLU-209         [-1, 1024, 32, 32]               0\n","      Bottleneck-210         [-1, 1024, 32, 32]               0\n","          Conv2d-211         [-1, 1024, 32, 32]       1,048,576\n","     BatchNorm2d-212         [-1, 1024, 32, 32]           2,048\n","            ReLU-213         [-1, 1024, 32, 32]               0\n","          Conv2d-214         [-1, 1024, 32, 32]         294,912\n","     BatchNorm2d-215         [-1, 1024, 32, 32]           2,048\n","            ReLU-216         [-1, 1024, 32, 32]               0\n","          Conv2d-217         [-1, 1024, 32, 32]       1,048,576\n","     BatchNorm2d-218         [-1, 1024, 32, 32]           2,048\n","            ReLU-219         [-1, 1024, 32, 32]               0\n","      Bottleneck-220         [-1, 1024, 32, 32]               0\n","          Conv2d-221         [-1, 1024, 32, 32]       1,048,576\n","     BatchNorm2d-222         [-1, 1024, 32, 32]           2,048\n","            ReLU-223         [-1, 1024, 32, 32]               0\n","          Conv2d-224         [-1, 1024, 32, 32]         294,912\n","     BatchNorm2d-225         [-1, 1024, 32, 32]           2,048\n","            ReLU-226         [-1, 1024, 32, 32]               0\n","          Conv2d-227         [-1, 1024, 32, 32]       1,048,576\n","     BatchNorm2d-228         [-1, 1024, 32, 32]           2,048\n","            ReLU-229         [-1, 1024, 32, 32]               0\n","      Bottleneck-230         [-1, 1024, 32, 32]               0\n","          Conv2d-231         [-1, 1024, 32, 32]       1,048,576\n","     BatchNorm2d-232         [-1, 1024, 32, 32]           2,048\n","            ReLU-233         [-1, 1024, 32, 32]               0\n","          Conv2d-234         [-1, 1024, 32, 32]         294,912\n","     BatchNorm2d-235         [-1, 1024, 32, 32]           2,048\n","            ReLU-236         [-1, 1024, 32, 32]               0\n","          Conv2d-237         [-1, 1024, 32, 32]       1,048,576\n","     BatchNorm2d-238         [-1, 1024, 32, 32]           2,048\n","            ReLU-239         [-1, 1024, 32, 32]               0\n","      Bottleneck-240         [-1, 1024, 32, 32]               0\n","          Conv2d-241         [-1, 1024, 32, 32]       1,048,576\n","     BatchNorm2d-242         [-1, 1024, 32, 32]           2,048\n","            ReLU-243         [-1, 1024, 32, 32]               0\n","          Conv2d-244         [-1, 1024, 32, 32]         294,912\n","     BatchNorm2d-245         [-1, 1024, 32, 32]           2,048\n","            ReLU-246         [-1, 1024, 32, 32]               0\n","          Conv2d-247         [-1, 1024, 32, 32]       1,048,576\n","     BatchNorm2d-248         [-1, 1024, 32, 32]           2,048\n","            ReLU-249         [-1, 1024, 32, 32]               0\n","      Bottleneck-250         [-1, 1024, 32, 32]               0\n","          Conv2d-251         [-1, 1024, 32, 32]       1,048,576\n","     BatchNorm2d-252         [-1, 1024, 32, 32]           2,048\n","            ReLU-253         [-1, 1024, 32, 32]               0\n","          Conv2d-254         [-1, 1024, 32, 32]         294,912\n","     BatchNorm2d-255         [-1, 1024, 32, 32]           2,048\n","            ReLU-256         [-1, 1024, 32, 32]               0\n","          Conv2d-257         [-1, 1024, 32, 32]       1,048,576\n","     BatchNorm2d-258         [-1, 1024, 32, 32]           2,048\n","            ReLU-259         [-1, 1024, 32, 32]               0\n","      Bottleneck-260         [-1, 1024, 32, 32]               0\n","          Conv2d-261         [-1, 1024, 32, 32]       1,048,576\n","     BatchNorm2d-262         [-1, 1024, 32, 32]           2,048\n","            ReLU-263         [-1, 1024, 32, 32]               0\n","          Conv2d-264         [-1, 1024, 32, 32]         294,912\n","     BatchNorm2d-265         [-1, 1024, 32, 32]           2,048\n","            ReLU-266         [-1, 1024, 32, 32]               0\n","          Conv2d-267         [-1, 1024, 32, 32]       1,048,576\n","     BatchNorm2d-268         [-1, 1024, 32, 32]           2,048\n","            ReLU-269         [-1, 1024, 32, 32]               0\n","      Bottleneck-270         [-1, 1024, 32, 32]               0\n","          Conv2d-271         [-1, 1024, 32, 32]       1,048,576\n","     BatchNorm2d-272         [-1, 1024, 32, 32]           2,048\n","            ReLU-273         [-1, 1024, 32, 32]               0\n","          Conv2d-274         [-1, 1024, 32, 32]         294,912\n","     BatchNorm2d-275         [-1, 1024, 32, 32]           2,048\n","            ReLU-276         [-1, 1024, 32, 32]               0\n","          Conv2d-277         [-1, 1024, 32, 32]       1,048,576\n","     BatchNorm2d-278         [-1, 1024, 32, 32]           2,048\n","            ReLU-279         [-1, 1024, 32, 32]               0\n","      Bottleneck-280         [-1, 1024, 32, 32]               0\n","          Conv2d-281         [-1, 1024, 32, 32]       1,048,576\n","     BatchNorm2d-282         [-1, 1024, 32, 32]           2,048\n","            ReLU-283         [-1, 1024, 32, 32]               0\n","          Conv2d-284         [-1, 1024, 32, 32]         294,912\n","     BatchNorm2d-285         [-1, 1024, 32, 32]           2,048\n","            ReLU-286         [-1, 1024, 32, 32]               0\n","          Conv2d-287         [-1, 1024, 32, 32]       1,048,576\n","     BatchNorm2d-288         [-1, 1024, 32, 32]           2,048\n","            ReLU-289         [-1, 1024, 32, 32]               0\n","      Bottleneck-290         [-1, 1024, 32, 32]               0\n","          Conv2d-291         [-1, 1024, 32, 32]       1,048,576\n","     BatchNorm2d-292         [-1, 1024, 32, 32]           2,048\n","            ReLU-293         [-1, 1024, 32, 32]               0\n","          Conv2d-294         [-1, 1024, 32, 32]         294,912\n","     BatchNorm2d-295         [-1, 1024, 32, 32]           2,048\n","            ReLU-296         [-1, 1024, 32, 32]               0\n","          Conv2d-297         [-1, 1024, 32, 32]       1,048,576\n","     BatchNorm2d-298         [-1, 1024, 32, 32]           2,048\n","            ReLU-299         [-1, 1024, 32, 32]               0\n","      Bottleneck-300         [-1, 1024, 32, 32]               0\n","          Conv2d-301         [-1, 1024, 32, 32]       1,048,576\n","     BatchNorm2d-302         [-1, 1024, 32, 32]           2,048\n","            ReLU-303         [-1, 1024, 32, 32]               0\n","          Conv2d-304         [-1, 1024, 32, 32]         294,912\n","     BatchNorm2d-305         [-1, 1024, 32, 32]           2,048\n","            ReLU-306         [-1, 1024, 32, 32]               0\n","          Conv2d-307         [-1, 1024, 32, 32]       1,048,576\n","     BatchNorm2d-308         [-1, 1024, 32, 32]           2,048\n","            ReLU-309         [-1, 1024, 32, 32]               0\n","      Bottleneck-310         [-1, 1024, 32, 32]               0\n","          Conv2d-311         [-1, 2048, 32, 32]       2,097,152\n","     BatchNorm2d-312         [-1, 2048, 32, 32]           4,096\n","            ReLU-313         [-1, 2048, 32, 32]               0\n","          Conv2d-314         [-1, 2048, 16, 16]       1,179,648\n","     BatchNorm2d-315         [-1, 2048, 16, 16]           4,096\n","            ReLU-316         [-1, 2048, 16, 16]               0\n","          Conv2d-317         [-1, 2048, 16, 16]       4,194,304\n","     BatchNorm2d-318         [-1, 2048, 16, 16]           4,096\n","          Conv2d-319         [-1, 2048, 16, 16]       2,097,152\n","     BatchNorm2d-320         [-1, 2048, 16, 16]           4,096\n","            ReLU-321         [-1, 2048, 16, 16]               0\n","      Bottleneck-322         [-1, 2048, 16, 16]               0\n","          Conv2d-323         [-1, 2048, 16, 16]       4,194,304\n","     BatchNorm2d-324         [-1, 2048, 16, 16]           4,096\n","            ReLU-325         [-1, 2048, 16, 16]               0\n","          Conv2d-326         [-1, 2048, 16, 16]       1,179,648\n","     BatchNorm2d-327         [-1, 2048, 16, 16]           4,096\n","            ReLU-328         [-1, 2048, 16, 16]               0\n","          Conv2d-329         [-1, 2048, 16, 16]       4,194,304\n","     BatchNorm2d-330         [-1, 2048, 16, 16]           4,096\n","            ReLU-331         [-1, 2048, 16, 16]               0\n","      Bottleneck-332         [-1, 2048, 16, 16]               0\n","          Conv2d-333         [-1, 2048, 16, 16]       4,194,304\n","     BatchNorm2d-334         [-1, 2048, 16, 16]           4,096\n","            ReLU-335         [-1, 2048, 16, 16]               0\n","          Conv2d-336         [-1, 2048, 16, 16]       1,179,648\n","     BatchNorm2d-337         [-1, 2048, 16, 16]           4,096\n","            ReLU-338         [-1, 2048, 16, 16]               0\n","          Conv2d-339         [-1, 2048, 16, 16]       4,194,304\n","     BatchNorm2d-340         [-1, 2048, 16, 16]           4,096\n","            ReLU-341         [-1, 2048, 16, 16]               0\n","      Bottleneck-342         [-1, 2048, 16, 16]               0\n","          Conv2d-343        [-1, 256, 128, 128]         589,824\n","          Conv2d-344          [-1, 256, 64, 64]       1,179,648\n","          Conv2d-345          [-1, 256, 32, 32]       2,359,296\n","          Conv2d-346          [-1, 256, 16, 16]       4,718,592\n","            ReLU-347          [-1, 256, 16, 16]               0\n","          Conv2d-348          [-1, 256, 16, 16]         590,080\n","            ReLU-349          [-1, 256, 16, 16]               0\n","          Conv2d-350          [-1, 256, 16, 16]         590,080\n","ResidualConvUnit-351          [-1, 256, 16, 16]               0\n","FeatureFusionBlock-352          [-1, 256, 32, 32]               0\n","            ReLU-353          [-1, 256, 32, 32]               0\n","          Conv2d-354          [-1, 256, 32, 32]         590,080\n","            ReLU-355          [-1, 256, 32, 32]               0\n","          Conv2d-356          [-1, 256, 32, 32]         590,080\n","ResidualConvUnit-357          [-1, 256, 32, 32]               0\n","            ReLU-358          [-1, 256, 32, 32]               0\n","          Conv2d-359          [-1, 256, 32, 32]         590,080\n","            ReLU-360          [-1, 256, 32, 32]               0\n","          Conv2d-361          [-1, 256, 32, 32]         590,080\n","ResidualConvUnit-362          [-1, 256, 32, 32]               0\n","FeatureFusionBlock-363          [-1, 256, 64, 64]               0\n","            ReLU-364          [-1, 256, 64, 64]               0\n","          Conv2d-365          [-1, 256, 64, 64]         590,080\n","            ReLU-366          [-1, 256, 64, 64]               0\n","          Conv2d-367          [-1, 256, 64, 64]         590,080\n","ResidualConvUnit-368          [-1, 256, 64, 64]               0\n","            ReLU-369          [-1, 256, 64, 64]               0\n","          Conv2d-370          [-1, 256, 64, 64]         590,080\n","            ReLU-371          [-1, 256, 64, 64]               0\n","          Conv2d-372          [-1, 256, 64, 64]         590,080\n","ResidualConvUnit-373          [-1, 256, 64, 64]               0\n","FeatureFusionBlock-374        [-1, 256, 128, 128]               0\n","            ReLU-375        [-1, 256, 128, 128]               0\n","          Conv2d-376        [-1, 256, 128, 128]         590,080\n","            ReLU-377        [-1, 256, 128, 128]               0\n","          Conv2d-378        [-1, 256, 128, 128]         590,080\n","ResidualConvUnit-379        [-1, 256, 128, 128]               0\n","            ReLU-380        [-1, 256, 128, 128]               0\n","          Conv2d-381        [-1, 256, 128, 128]         590,080\n","            ReLU-382        [-1, 256, 128, 128]               0\n","          Conv2d-383        [-1, 256, 128, 128]         590,080\n","ResidualConvUnit-384        [-1, 256, 128, 128]               0\n","FeatureFusionBlock-385        [-1, 256, 256, 256]               0\n","          Conv2d-386        [-1, 128, 256, 256]         295,040\n","     Interpolate-387        [-1, 128, 512, 512]               0\n","          Conv2d-388         [-1, 32, 512, 512]          36,896\n","            ReLU-389         [-1, 32, 512, 512]               0\n","          Conv2d-390          [-1, 1, 512, 512]              33\n","            ReLU-391          [-1, 1, 512, 512]               0\n","          Conv2d-392        [-1, 256, 256, 256]           6,912\n","     BatchNorm2d-393        [-1, 256, 256, 256]             512\n","            ReLU-394        [-1, 256, 256, 256]               0\n","          Conv2d-395        [-1, 256, 128, 128]         589,824\n","     BatchNorm2d-396        [-1, 256, 128, 128]             512\n","            ReLU-397        [-1, 256, 128, 128]               0\n","          Conv2d-398          [-1, 256, 64, 64]         589,824\n","     BatchNorm2d-399          [-1, 256, 64, 64]             512\n","            ReLU-400          [-1, 256, 64, 64]               0\n","          Conv2d-401          [-1, 512, 32, 32]       1,179,648\n","     BatchNorm2d-402          [-1, 512, 32, 32]           1,024\n","            ReLU-403          [-1, 512, 32, 32]               0\n","          Conv2d-404         [-1, 1024, 16, 16]       4,718,592\n","     BatchNorm2d-405         [-1, 1024, 16, 16]           2,048\n","            ReLU-406         [-1, 1024, 16, 16]               0\n","          Conv2d-407         [-1, 1024, 16, 16]       2,097,152\n","     BatchNorm2d-408         [-1, 1024, 16, 16]           2,048\n","            ReLU-409         [-1, 1024, 16, 16]               0\n","          Conv2d-410           [-1, 27, 16, 16]          27,675\n","       YOLOLayer-411         [-1, 3, 16, 16, 9]               0\n","     Interpolate-412         [-1, 1024, 32, 32]               0\n","          Conv2d-413          [-1, 256, 32, 32]         262,144\n","     BatchNorm2d-414          [-1, 256, 32, 32]             512\n","            ReLU-415          [-1, 256, 32, 32]               0\n","          Conv2d-416          [-1, 512, 32, 32]         524,288\n","     BatchNorm2d-417          [-1, 512, 32, 32]           1,024\n","            ReLU-418          [-1, 512, 32, 32]               0\n","          Conv2d-419          [-1, 256, 32, 32]         196,608\n","     BatchNorm2d-420          [-1, 256, 32, 32]             512\n","            ReLU-421          [-1, 256, 32, 32]               0\n","          Conv2d-422          [-1, 512, 32, 32]       1,179,648\n","     BatchNorm2d-423          [-1, 512, 32, 32]           1,024\n","            ReLU-424          [-1, 512, 32, 32]               0\n","          Conv2d-425          [-1, 256, 32, 32]         131,072\n","     BatchNorm2d-426          [-1, 256, 32, 32]             512\n","            ReLU-427          [-1, 256, 32, 32]               0\n","          Conv2d-428          [-1, 512, 32, 32]       1,179,648\n","     BatchNorm2d-429          [-1, 512, 32, 32]           1,024\n","            ReLU-430          [-1, 512, 32, 32]               0\n","          Conv2d-431          [-1, 256, 32, 32]         131,072\n","     BatchNorm2d-432          [-1, 256, 32, 32]             512\n","            ReLU-433          [-1, 256, 32, 32]               0\n","          Conv2d-434          [-1, 512, 32, 32]       1,179,648\n","     BatchNorm2d-435          [-1, 512, 32, 32]           1,024\n","            ReLU-436          [-1, 512, 32, 32]               0\n","          Conv2d-437           [-1, 27, 32, 32]          13,851\n","       YOLOLayer-438         [-1, 3, 32, 32, 9]               0\n","          Conv2d-439          [-1, 256, 64, 64]         131,072\n","     BatchNorm2d-440          [-1, 256, 64, 64]             512\n","            ReLU-441          [-1, 256, 64, 64]               0\n","     Interpolate-442          [-1, 512, 64, 64]               0\n","          Conv2d-443          [-1, 128, 64, 64]          65,536\n","     BatchNorm2d-444          [-1, 128, 64, 64]             256\n","            ReLU-445          [-1, 128, 64, 64]               0\n","          Conv2d-446          [-1, 128, 64, 64]          49,152\n","     BatchNorm2d-447          [-1, 128, 64, 64]             256\n","            ReLU-448          [-1, 128, 64, 64]               0\n","          Conv2d-449          [-1, 256, 64, 64]         294,912\n","     BatchNorm2d-450          [-1, 256, 64, 64]             512\n","            ReLU-451          [-1, 256, 64, 64]               0\n","          Conv2d-452          [-1, 128, 64, 64]          32,768\n","     BatchNorm2d-453          [-1, 128, 64, 64]             256\n","            ReLU-454          [-1, 128, 64, 64]               0\n","          Conv2d-455          [-1, 256, 64, 64]         294,912\n","     BatchNorm2d-456          [-1, 256, 64, 64]             512\n","            ReLU-457          [-1, 256, 64, 64]               0\n","          Conv2d-458          [-1, 128, 64, 64]          32,768\n","     BatchNorm2d-459          [-1, 128, 64, 64]             256\n","            ReLU-460          [-1, 128, 64, 64]               0\n","          Conv2d-461          [-1, 256, 64, 64]         294,912\n","     BatchNorm2d-462          [-1, 256, 64, 64]             512\n","            ReLU-463          [-1, 256, 64, 64]               0\n","          Conv2d-464           [-1, 27, 64, 64]           6,939\n","       YOLOLayer-465         [-1, 3, 64, 64, 9]               0\n","================================================================\n","Total params: 119,409,234\n","Trainable params: 15,226,449\n","Non-trainable params: 104,182,785\n","----------------------------------------------------------------\n","Input size (MB): 3.00\n","Forward/backward pass size (MB): 5893.21\n","Params size (MB): 455.51\n","Estimated Total Size (MB): 6351.72\n","----------------------------------------------------------------\n","Image sizes 512 - 512 train, 512 test\n","Using 4 dataloader workers\n","Starting training for 300 epochs...\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","  0% 0/346 [00:00<?, ?it/s]/usr/local/lib/python3.6/dist-packages/torch/cuda/memory.py:346: FutureWarning: torch.cuda.memory_cached has been renamed to torch.cuda.memory_reserved\n","  FutureWarning)\n","   158/299     5.09G      4.61      1.15     0.742       6.5        60       512: 100% 346/346 [04:45<00:00,  1.21it/s]\n","               Class    Images   Targets         P         R   mAP@0.5        F1:   0% 0/87 [00:00<?, ?it/s]/content/drive/My Drive/computer_vision/capstone_project/yolo_v3/utils/utils.py:544: UserWarning: This overload of nonzero is deprecated:\n","\tnonzero()\n","Consider using one of the following signatures instead:\n","\tnonzero(*, bool as_tuple) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:882.)\n","  i, j = (x[:, 5:] > conf_thres).nonzero().t()\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 87/87 [00:56<00:00,  1.55it/s]\n","                 all       692  3.06e+03     0.255     0.582     0.342     0.354\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","  0% 0/346 [00:00<?, ?it/s]/usr/local/lib/python3.6/dist-packages/torch/cuda/memory.py:346: FutureWarning: torch.cuda.memory_cached has been renamed to torch.cuda.memory_reserved\n","  FutureWarning)\n","   159/299     5.09G       4.6      1.13     0.706      6.43        50       512: 100% 346/346 [04:45<00:00,  1.21it/s]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 87/87 [00:54<00:00,  1.59it/s]\n","                 all       692  3.06e+03     0.268     0.583      0.36     0.367\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","   160/299     5.09G      4.56      1.13     0.678      6.37        31       512: 100% 346/346 [04:45<00:00,  1.21it/s]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 87/87 [00:54<00:00,  1.59it/s]\n","                 all       692  3.06e+03     0.256     0.586     0.337     0.355\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","   161/299     5.09G      4.55      1.13     0.692      6.37        25       512: 100% 346/346 [04:45<00:00,  1.21it/s]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 87/87 [00:54<00:00,  1.60it/s]\n","                 all       692  3.06e+03     0.266     0.582     0.328     0.364\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","   162/299     5.09G      4.55       1.1     0.672      6.32        42       512: 100% 346/346 [04:45<00:00,  1.21it/s]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 87/87 [00:54<00:00,  1.59it/s]\n","                 all       692  3.06e+03     0.265     0.577     0.353     0.363\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","   163/299     5.09G      4.54      1.14     0.659      6.34        40       512: 100% 346/346 [04:46<00:00,  1.21it/s]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 87/87 [00:54<00:00,  1.59it/s]\n","                 all       692  3.06e+03     0.255     0.572     0.348     0.352\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","   164/299     5.09G      4.54      1.13     0.667      6.33        34       512: 100% 346/346 [04:45<00:00,  1.21it/s]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 87/87 [00:54<00:00,  1.59it/s]\n","                 all       692  3.06e+03     0.246     0.571     0.322     0.343\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","   165/299     5.09G      4.49      1.13     0.694      6.32        77       512:  31% 106/346 [01:28<03:16,  1.22it/s]"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"wsB5XN0blFVK","colab":{"base_uri":"https://localhost:8080/"},"outputId":"0d460c40-fa87-4084-db32-23e373564e57"},"source":["!python train.py --data data/customdata/custom.data --batch 8  --cache --cfg cfg/yolov3-custom.cfg --epochs 300 --weights 'weights/best.pt'  --img-size=256 --midasnet_freeze='True'"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Namespace(accumulate=4, adam=False, batch_size=8, bucket='', cache_images=True, cfg='cfg/yolov3-custom.cfg', data='data/customdata/custom.data', device='', epochs=300, evolve=False, img_size=[256], init_train='False', midas_weights='', midasnet_freeze='True', multi_scale=False, name='', nosave=False, notest=False, rect=False, resume=False, single_cls=False, weights='weights/best.pt', yolo_weights='')\n","Using CUDA device0 _CudaDeviceProperties(name='Tesla P100-PCIE-16GB', total_memory=16280MB)\n","\n","2020-11-14 16:26:57.640865: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n","Run 'tensorboard --logdir=runs' to view tensorboard at http://localhost:6006/\n","cfg - cfg/yolov3-custom.cfg\n","data - data/customdata/custom.data\n","epochs - 300\n","batch_size - 8\n","accumulate - 4\n","yolo weights - \n","midas weights - \n","imgsz_min- 256, imgsz_max- 256, imgsz_test- 256\n","opt.rect - False\n","train_path - data/customdata/train.txt\n","test_path - data/customdata/test.txt\n","init_train - False\n","weights - weights/best.pt\n","midasnet_freeze - True\n","Using cache found in /root/.cache/torch/hub/facebookresearch_WSL-Images_master\n","Caching labels (2623 found, 114 missing, 30 empty, 0 duplicate, for 2767 images): 100% 2767/2767 [00:03<00:00, 881.88it/s]\n","Caching images (0.4GB): 100% 2767/2767 [01:27<00:00, 31.65it/s]\n","Caching labels (657 found, 27 missing, 8 empty, 0 duplicate, for 692 images): 100% 692/692 [00:00<00:00, 854.72it/s]\n","Caching images (0.1GB): 100% 692/692 [00:24<00:00, 28.09it/s]\n","Freezing the midasnet\n","YMP Model Summary\n","----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","            Conv2d-1         [-1, 64, 128, 128]           9,408\n","       BatchNorm2d-2         [-1, 64, 128, 128]             128\n","              ReLU-3         [-1, 64, 128, 128]               0\n","         MaxPool2d-4           [-1, 64, 64, 64]               0\n","            Conv2d-5          [-1, 256, 64, 64]          16,384\n","       BatchNorm2d-6          [-1, 256, 64, 64]             512\n","              ReLU-7          [-1, 256, 64, 64]               0\n","            Conv2d-8          [-1, 256, 64, 64]          18,432\n","       BatchNorm2d-9          [-1, 256, 64, 64]             512\n","             ReLU-10          [-1, 256, 64, 64]               0\n","           Conv2d-11          [-1, 256, 64, 64]          65,536\n","      BatchNorm2d-12          [-1, 256, 64, 64]             512\n","           Conv2d-13          [-1, 256, 64, 64]          16,384\n","      BatchNorm2d-14          [-1, 256, 64, 64]             512\n","             ReLU-15          [-1, 256, 64, 64]               0\n","       Bottleneck-16          [-1, 256, 64, 64]               0\n","           Conv2d-17          [-1, 256, 64, 64]          65,536\n","      BatchNorm2d-18          [-1, 256, 64, 64]             512\n","             ReLU-19          [-1, 256, 64, 64]               0\n","           Conv2d-20          [-1, 256, 64, 64]          18,432\n","      BatchNorm2d-21          [-1, 256, 64, 64]             512\n","             ReLU-22          [-1, 256, 64, 64]               0\n","           Conv2d-23          [-1, 256, 64, 64]          65,536\n","      BatchNorm2d-24          [-1, 256, 64, 64]             512\n","             ReLU-25          [-1, 256, 64, 64]               0\n","       Bottleneck-26          [-1, 256, 64, 64]               0\n","           Conv2d-27          [-1, 256, 64, 64]          65,536\n","      BatchNorm2d-28          [-1, 256, 64, 64]             512\n","             ReLU-29          [-1, 256, 64, 64]               0\n","           Conv2d-30          [-1, 256, 64, 64]          18,432\n","      BatchNorm2d-31          [-1, 256, 64, 64]             512\n","             ReLU-32          [-1, 256, 64, 64]               0\n","           Conv2d-33          [-1, 256, 64, 64]          65,536\n","      BatchNorm2d-34          [-1, 256, 64, 64]             512\n","             ReLU-35          [-1, 256, 64, 64]               0\n","       Bottleneck-36          [-1, 256, 64, 64]               0\n","           Conv2d-37          [-1, 512, 64, 64]         131,072\n","      BatchNorm2d-38          [-1, 512, 64, 64]           1,024\n","             ReLU-39          [-1, 512, 64, 64]               0\n","           Conv2d-40          [-1, 512, 32, 32]          73,728\n","      BatchNorm2d-41          [-1, 512, 32, 32]           1,024\n","             ReLU-42          [-1, 512, 32, 32]               0\n","           Conv2d-43          [-1, 512, 32, 32]         262,144\n","      BatchNorm2d-44          [-1, 512, 32, 32]           1,024\n","           Conv2d-45          [-1, 512, 32, 32]         131,072\n","      BatchNorm2d-46          [-1, 512, 32, 32]           1,024\n","             ReLU-47          [-1, 512, 32, 32]               0\n","       Bottleneck-48          [-1, 512, 32, 32]               0\n","           Conv2d-49          [-1, 512, 32, 32]         262,144\n","      BatchNorm2d-50          [-1, 512, 32, 32]           1,024\n","             ReLU-51          [-1, 512, 32, 32]               0\n","           Conv2d-52          [-1, 512, 32, 32]          73,728\n","      BatchNorm2d-53          [-1, 512, 32, 32]           1,024\n","             ReLU-54          [-1, 512, 32, 32]               0\n","           Conv2d-55          [-1, 512, 32, 32]         262,144\n","      BatchNorm2d-56          [-1, 512, 32, 32]           1,024\n","             ReLU-57          [-1, 512, 32, 32]               0\n","       Bottleneck-58          [-1, 512, 32, 32]               0\n","           Conv2d-59          [-1, 512, 32, 32]         262,144\n","      BatchNorm2d-60          [-1, 512, 32, 32]           1,024\n","             ReLU-61          [-1, 512, 32, 32]               0\n","           Conv2d-62          [-1, 512, 32, 32]          73,728\n","      BatchNorm2d-63          [-1, 512, 32, 32]           1,024\n","             ReLU-64          [-1, 512, 32, 32]               0\n","           Conv2d-65          [-1, 512, 32, 32]         262,144\n","      BatchNorm2d-66          [-1, 512, 32, 32]           1,024\n","             ReLU-67          [-1, 512, 32, 32]               0\n","       Bottleneck-68          [-1, 512, 32, 32]               0\n","           Conv2d-69          [-1, 512, 32, 32]         262,144\n","      BatchNorm2d-70          [-1, 512, 32, 32]           1,024\n","             ReLU-71          [-1, 512, 32, 32]               0\n","           Conv2d-72          [-1, 512, 32, 32]          73,728\n","      BatchNorm2d-73          [-1, 512, 32, 32]           1,024\n","             ReLU-74          [-1, 512, 32, 32]               0\n","           Conv2d-75          [-1, 512, 32, 32]         262,144\n","      BatchNorm2d-76          [-1, 512, 32, 32]           1,024\n","             ReLU-77          [-1, 512, 32, 32]               0\n","       Bottleneck-78          [-1, 512, 32, 32]               0\n","           Conv2d-79         [-1, 1024, 32, 32]         524,288\n","      BatchNorm2d-80         [-1, 1024, 32, 32]           2,048\n","             ReLU-81         [-1, 1024, 32, 32]               0\n","           Conv2d-82         [-1, 1024, 16, 16]         294,912\n","      BatchNorm2d-83         [-1, 1024, 16, 16]           2,048\n","             ReLU-84         [-1, 1024, 16, 16]               0\n","           Conv2d-85         [-1, 1024, 16, 16]       1,048,576\n","      BatchNorm2d-86         [-1, 1024, 16, 16]           2,048\n","           Conv2d-87         [-1, 1024, 16, 16]         524,288\n","      BatchNorm2d-88         [-1, 1024, 16, 16]           2,048\n","             ReLU-89         [-1, 1024, 16, 16]               0\n","       Bottleneck-90         [-1, 1024, 16, 16]               0\n","           Conv2d-91         [-1, 1024, 16, 16]       1,048,576\n","      BatchNorm2d-92         [-1, 1024, 16, 16]           2,048\n","             ReLU-93         [-1, 1024, 16, 16]               0\n","           Conv2d-94         [-1, 1024, 16, 16]         294,912\n","      BatchNorm2d-95         [-1, 1024, 16, 16]           2,048\n","             ReLU-96         [-1, 1024, 16, 16]               0\n","           Conv2d-97         [-1, 1024, 16, 16]       1,048,576\n","      BatchNorm2d-98         [-1, 1024, 16, 16]           2,048\n","             ReLU-99         [-1, 1024, 16, 16]               0\n","      Bottleneck-100         [-1, 1024, 16, 16]               0\n","          Conv2d-101         [-1, 1024, 16, 16]       1,048,576\n","     BatchNorm2d-102         [-1, 1024, 16, 16]           2,048\n","            ReLU-103         [-1, 1024, 16, 16]               0\n","          Conv2d-104         [-1, 1024, 16, 16]         294,912\n","     BatchNorm2d-105         [-1, 1024, 16, 16]           2,048\n","            ReLU-106         [-1, 1024, 16, 16]               0\n","          Conv2d-107         [-1, 1024, 16, 16]       1,048,576\n","     BatchNorm2d-108         [-1, 1024, 16, 16]           2,048\n","            ReLU-109         [-1, 1024, 16, 16]               0\n","      Bottleneck-110         [-1, 1024, 16, 16]               0\n","          Conv2d-111         [-1, 1024, 16, 16]       1,048,576\n","     BatchNorm2d-112         [-1, 1024, 16, 16]           2,048\n","            ReLU-113         [-1, 1024, 16, 16]               0\n","          Conv2d-114         [-1, 1024, 16, 16]         294,912\n","     BatchNorm2d-115         [-1, 1024, 16, 16]           2,048\n","            ReLU-116         [-1, 1024, 16, 16]               0\n","          Conv2d-117         [-1, 1024, 16, 16]       1,048,576\n","     BatchNorm2d-118         [-1, 1024, 16, 16]           2,048\n","            ReLU-119         [-1, 1024, 16, 16]               0\n","      Bottleneck-120         [-1, 1024, 16, 16]               0\n","          Conv2d-121         [-1, 1024, 16, 16]       1,048,576\n","     BatchNorm2d-122         [-1, 1024, 16, 16]           2,048\n","            ReLU-123         [-1, 1024, 16, 16]               0\n","          Conv2d-124         [-1, 1024, 16, 16]         294,912\n","     BatchNorm2d-125         [-1, 1024, 16, 16]           2,048\n","            ReLU-126         [-1, 1024, 16, 16]               0\n","          Conv2d-127         [-1, 1024, 16, 16]       1,048,576\n","     BatchNorm2d-128         [-1, 1024, 16, 16]           2,048\n","            ReLU-129         [-1, 1024, 16, 16]               0\n","      Bottleneck-130         [-1, 1024, 16, 16]               0\n","          Conv2d-131         [-1, 1024, 16, 16]       1,048,576\n","     BatchNorm2d-132         [-1, 1024, 16, 16]           2,048\n","            ReLU-133         [-1, 1024, 16, 16]               0\n","          Conv2d-134         [-1, 1024, 16, 16]         294,912\n","     BatchNorm2d-135         [-1, 1024, 16, 16]           2,048\n","            ReLU-136         [-1, 1024, 16, 16]               0\n","          Conv2d-137         [-1, 1024, 16, 16]       1,048,576\n","     BatchNorm2d-138         [-1, 1024, 16, 16]           2,048\n","            ReLU-139         [-1, 1024, 16, 16]               0\n","      Bottleneck-140         [-1, 1024, 16, 16]               0\n","          Conv2d-141         [-1, 1024, 16, 16]       1,048,576\n","     BatchNorm2d-142         [-1, 1024, 16, 16]           2,048\n","            ReLU-143         [-1, 1024, 16, 16]               0\n","          Conv2d-144         [-1, 1024, 16, 16]         294,912\n","     BatchNorm2d-145         [-1, 1024, 16, 16]           2,048\n","            ReLU-146         [-1, 1024, 16, 16]               0\n","          Conv2d-147         [-1, 1024, 16, 16]       1,048,576\n","     BatchNorm2d-148         [-1, 1024, 16, 16]           2,048\n","            ReLU-149         [-1, 1024, 16, 16]               0\n","      Bottleneck-150         [-1, 1024, 16, 16]               0\n","          Conv2d-151         [-1, 1024, 16, 16]       1,048,576\n","     BatchNorm2d-152         [-1, 1024, 16, 16]           2,048\n","            ReLU-153         [-1, 1024, 16, 16]               0\n","          Conv2d-154         [-1, 1024, 16, 16]         294,912\n","     BatchNorm2d-155         [-1, 1024, 16, 16]           2,048\n","            ReLU-156         [-1, 1024, 16, 16]               0\n","          Conv2d-157         [-1, 1024, 16, 16]       1,048,576\n","     BatchNorm2d-158         [-1, 1024, 16, 16]           2,048\n","            ReLU-159         [-1, 1024, 16, 16]               0\n","      Bottleneck-160         [-1, 1024, 16, 16]               0\n","          Conv2d-161         [-1, 1024, 16, 16]       1,048,576\n","     BatchNorm2d-162         [-1, 1024, 16, 16]           2,048\n","            ReLU-163         [-1, 1024, 16, 16]               0\n","          Conv2d-164         [-1, 1024, 16, 16]         294,912\n","     BatchNorm2d-165         [-1, 1024, 16, 16]           2,048\n","            ReLU-166         [-1, 1024, 16, 16]               0\n","          Conv2d-167         [-1, 1024, 16, 16]       1,048,576\n","     BatchNorm2d-168         [-1, 1024, 16, 16]           2,048\n","            ReLU-169         [-1, 1024, 16, 16]               0\n","      Bottleneck-170         [-1, 1024, 16, 16]               0\n","          Conv2d-171         [-1, 1024, 16, 16]       1,048,576\n","     BatchNorm2d-172         [-1, 1024, 16, 16]           2,048\n","            ReLU-173         [-1, 1024, 16, 16]               0\n","          Conv2d-174         [-1, 1024, 16, 16]         294,912\n","     BatchNorm2d-175         [-1, 1024, 16, 16]           2,048\n","            ReLU-176         [-1, 1024, 16, 16]               0\n","          Conv2d-177         [-1, 1024, 16, 16]       1,048,576\n","     BatchNorm2d-178         [-1, 1024, 16, 16]           2,048\n","            ReLU-179         [-1, 1024, 16, 16]               0\n","      Bottleneck-180         [-1, 1024, 16, 16]               0\n","          Conv2d-181         [-1, 1024, 16, 16]       1,048,576\n","     BatchNorm2d-182         [-1, 1024, 16, 16]           2,048\n","            ReLU-183         [-1, 1024, 16, 16]               0\n","          Conv2d-184         [-1, 1024, 16, 16]         294,912\n","     BatchNorm2d-185         [-1, 1024, 16, 16]           2,048\n","            ReLU-186         [-1, 1024, 16, 16]               0\n","          Conv2d-187         [-1, 1024, 16, 16]       1,048,576\n","     BatchNorm2d-188         [-1, 1024, 16, 16]           2,048\n","            ReLU-189         [-1, 1024, 16, 16]               0\n","      Bottleneck-190         [-1, 1024, 16, 16]               0\n","          Conv2d-191         [-1, 1024, 16, 16]       1,048,576\n","     BatchNorm2d-192         [-1, 1024, 16, 16]           2,048\n","            ReLU-193         [-1, 1024, 16, 16]               0\n","          Conv2d-194         [-1, 1024, 16, 16]         294,912\n","     BatchNorm2d-195         [-1, 1024, 16, 16]           2,048\n","            ReLU-196         [-1, 1024, 16, 16]               0\n","          Conv2d-197         [-1, 1024, 16, 16]       1,048,576\n","     BatchNorm2d-198         [-1, 1024, 16, 16]           2,048\n","            ReLU-199         [-1, 1024, 16, 16]               0\n","      Bottleneck-200         [-1, 1024, 16, 16]               0\n","          Conv2d-201         [-1, 1024, 16, 16]       1,048,576\n","     BatchNorm2d-202         [-1, 1024, 16, 16]           2,048\n","            ReLU-203         [-1, 1024, 16, 16]               0\n","          Conv2d-204         [-1, 1024, 16, 16]         294,912\n","     BatchNorm2d-205         [-1, 1024, 16, 16]           2,048\n","            ReLU-206         [-1, 1024, 16, 16]               0\n","          Conv2d-207         [-1, 1024, 16, 16]       1,048,576\n","     BatchNorm2d-208         [-1, 1024, 16, 16]           2,048\n","            ReLU-209         [-1, 1024, 16, 16]               0\n","      Bottleneck-210         [-1, 1024, 16, 16]               0\n","          Conv2d-211         [-1, 1024, 16, 16]       1,048,576\n","     BatchNorm2d-212         [-1, 1024, 16, 16]           2,048\n","            ReLU-213         [-1, 1024, 16, 16]               0\n","          Conv2d-214         [-1, 1024, 16, 16]         294,912\n","     BatchNorm2d-215         [-1, 1024, 16, 16]           2,048\n","            ReLU-216         [-1, 1024, 16, 16]               0\n","          Conv2d-217         [-1, 1024, 16, 16]       1,048,576\n","     BatchNorm2d-218         [-1, 1024, 16, 16]           2,048\n","            ReLU-219         [-1, 1024, 16, 16]               0\n","      Bottleneck-220         [-1, 1024, 16, 16]               0\n","          Conv2d-221         [-1, 1024, 16, 16]       1,048,576\n","     BatchNorm2d-222         [-1, 1024, 16, 16]           2,048\n","            ReLU-223         [-1, 1024, 16, 16]               0\n","          Conv2d-224         [-1, 1024, 16, 16]         294,912\n","     BatchNorm2d-225         [-1, 1024, 16, 16]           2,048\n","            ReLU-226         [-1, 1024, 16, 16]               0\n","          Conv2d-227         [-1, 1024, 16, 16]       1,048,576\n","     BatchNorm2d-228         [-1, 1024, 16, 16]           2,048\n","            ReLU-229         [-1, 1024, 16, 16]               0\n","      Bottleneck-230         [-1, 1024, 16, 16]               0\n","          Conv2d-231         [-1, 1024, 16, 16]       1,048,576\n","     BatchNorm2d-232         [-1, 1024, 16, 16]           2,048\n","            ReLU-233         [-1, 1024, 16, 16]               0\n","          Conv2d-234         [-1, 1024, 16, 16]         294,912\n","     BatchNorm2d-235         [-1, 1024, 16, 16]           2,048\n","            ReLU-236         [-1, 1024, 16, 16]               0\n","          Conv2d-237         [-1, 1024, 16, 16]       1,048,576\n","     BatchNorm2d-238         [-1, 1024, 16, 16]           2,048\n","            ReLU-239         [-1, 1024, 16, 16]               0\n","      Bottleneck-240         [-1, 1024, 16, 16]               0\n","          Conv2d-241         [-1, 1024, 16, 16]       1,048,576\n","     BatchNorm2d-242         [-1, 1024, 16, 16]           2,048\n","            ReLU-243         [-1, 1024, 16, 16]               0\n","          Conv2d-244         [-1, 1024, 16, 16]         294,912\n","     BatchNorm2d-245         [-1, 1024, 16, 16]           2,048\n","            ReLU-246         [-1, 1024, 16, 16]               0\n","          Conv2d-247         [-1, 1024, 16, 16]       1,048,576\n","     BatchNorm2d-248         [-1, 1024, 16, 16]           2,048\n","            ReLU-249         [-1, 1024, 16, 16]               0\n","      Bottleneck-250         [-1, 1024, 16, 16]               0\n","          Conv2d-251         [-1, 1024, 16, 16]       1,048,576\n","     BatchNorm2d-252         [-1, 1024, 16, 16]           2,048\n","            ReLU-253         [-1, 1024, 16, 16]               0\n","          Conv2d-254         [-1, 1024, 16, 16]         294,912\n","     BatchNorm2d-255         [-1, 1024, 16, 16]           2,048\n","            ReLU-256         [-1, 1024, 16, 16]               0\n","          Conv2d-257         [-1, 1024, 16, 16]       1,048,576\n","     BatchNorm2d-258         [-1, 1024, 16, 16]           2,048\n","            ReLU-259         [-1, 1024, 16, 16]               0\n","      Bottleneck-260         [-1, 1024, 16, 16]               0\n","          Conv2d-261         [-1, 1024, 16, 16]       1,048,576\n","     BatchNorm2d-262         [-1, 1024, 16, 16]           2,048\n","            ReLU-263         [-1, 1024, 16, 16]               0\n","          Conv2d-264         [-1, 1024, 16, 16]         294,912\n","     BatchNorm2d-265         [-1, 1024, 16, 16]           2,048\n","            ReLU-266         [-1, 1024, 16, 16]               0\n","          Conv2d-267         [-1, 1024, 16, 16]       1,048,576\n","     BatchNorm2d-268         [-1, 1024, 16, 16]           2,048\n","            ReLU-269         [-1, 1024, 16, 16]               0\n","      Bottleneck-270         [-1, 1024, 16, 16]               0\n","          Conv2d-271         [-1, 1024, 16, 16]       1,048,576\n","     BatchNorm2d-272         [-1, 1024, 16, 16]           2,048\n","            ReLU-273         [-1, 1024, 16, 16]               0\n","          Conv2d-274         [-1, 1024, 16, 16]         294,912\n","     BatchNorm2d-275         [-1, 1024, 16, 16]           2,048\n","            ReLU-276         [-1, 1024, 16, 16]               0\n","          Conv2d-277         [-1, 1024, 16, 16]       1,048,576\n","     BatchNorm2d-278         [-1, 1024, 16, 16]           2,048\n","            ReLU-279         [-1, 1024, 16, 16]               0\n","      Bottleneck-280         [-1, 1024, 16, 16]               0\n","          Conv2d-281         [-1, 1024, 16, 16]       1,048,576\n","     BatchNorm2d-282         [-1, 1024, 16, 16]           2,048\n","            ReLU-283         [-1, 1024, 16, 16]               0\n","          Conv2d-284         [-1, 1024, 16, 16]         294,912\n","     BatchNorm2d-285         [-1, 1024, 16, 16]           2,048\n","            ReLU-286         [-1, 1024, 16, 16]               0\n","          Conv2d-287         [-1, 1024, 16, 16]       1,048,576\n","     BatchNorm2d-288         [-1, 1024, 16, 16]           2,048\n","            ReLU-289         [-1, 1024, 16, 16]               0\n","      Bottleneck-290         [-1, 1024, 16, 16]               0\n","          Conv2d-291         [-1, 1024, 16, 16]       1,048,576\n","     BatchNorm2d-292         [-1, 1024, 16, 16]           2,048\n","            ReLU-293         [-1, 1024, 16, 16]               0\n","          Conv2d-294         [-1, 1024, 16, 16]         294,912\n","     BatchNorm2d-295         [-1, 1024, 16, 16]           2,048\n","            ReLU-296         [-1, 1024, 16, 16]               0\n","          Conv2d-297         [-1, 1024, 16, 16]       1,048,576\n","     BatchNorm2d-298         [-1, 1024, 16, 16]           2,048\n","            ReLU-299         [-1, 1024, 16, 16]               0\n","      Bottleneck-300         [-1, 1024, 16, 16]               0\n","          Conv2d-301         [-1, 1024, 16, 16]       1,048,576\n","     BatchNorm2d-302         [-1, 1024, 16, 16]           2,048\n","            ReLU-303         [-1, 1024, 16, 16]               0\n","          Conv2d-304         [-1, 1024, 16, 16]         294,912\n","     BatchNorm2d-305         [-1, 1024, 16, 16]           2,048\n","            ReLU-306         [-1, 1024, 16, 16]               0\n","          Conv2d-307         [-1, 1024, 16, 16]       1,048,576\n","     BatchNorm2d-308         [-1, 1024, 16, 16]           2,048\n","            ReLU-309         [-1, 1024, 16, 16]               0\n","      Bottleneck-310         [-1, 1024, 16, 16]               0\n","          Conv2d-311         [-1, 2048, 16, 16]       2,097,152\n","     BatchNorm2d-312         [-1, 2048, 16, 16]           4,096\n","            ReLU-313         [-1, 2048, 16, 16]               0\n","          Conv2d-314           [-1, 2048, 8, 8]       1,179,648\n","     BatchNorm2d-315           [-1, 2048, 8, 8]           4,096\n","            ReLU-316           [-1, 2048, 8, 8]               0\n","          Conv2d-317           [-1, 2048, 8, 8]       4,194,304\n","     BatchNorm2d-318           [-1, 2048, 8, 8]           4,096\n","          Conv2d-319           [-1, 2048, 8, 8]       2,097,152\n","     BatchNorm2d-320           [-1, 2048, 8, 8]           4,096\n","            ReLU-321           [-1, 2048, 8, 8]               0\n","      Bottleneck-322           [-1, 2048, 8, 8]               0\n","          Conv2d-323           [-1, 2048, 8, 8]       4,194,304\n","     BatchNorm2d-324           [-1, 2048, 8, 8]           4,096\n","            ReLU-325           [-1, 2048, 8, 8]               0\n","          Conv2d-326           [-1, 2048, 8, 8]       1,179,648\n","     BatchNorm2d-327           [-1, 2048, 8, 8]           4,096\n","            ReLU-328           [-1, 2048, 8, 8]               0\n","          Conv2d-329           [-1, 2048, 8, 8]       4,194,304\n","     BatchNorm2d-330           [-1, 2048, 8, 8]           4,096\n","            ReLU-331           [-1, 2048, 8, 8]               0\n","      Bottleneck-332           [-1, 2048, 8, 8]               0\n","          Conv2d-333           [-1, 2048, 8, 8]       4,194,304\n","     BatchNorm2d-334           [-1, 2048, 8, 8]           4,096\n","            ReLU-335           [-1, 2048, 8, 8]               0\n","          Conv2d-336           [-1, 2048, 8, 8]       1,179,648\n","     BatchNorm2d-337           [-1, 2048, 8, 8]           4,096\n","            ReLU-338           [-1, 2048, 8, 8]               0\n","          Conv2d-339           [-1, 2048, 8, 8]       4,194,304\n","     BatchNorm2d-340           [-1, 2048, 8, 8]           4,096\n","            ReLU-341           [-1, 2048, 8, 8]               0\n","      Bottleneck-342           [-1, 2048, 8, 8]               0\n","          Conv2d-343          [-1, 256, 64, 64]         589,824\n","          Conv2d-344          [-1, 256, 32, 32]       1,179,648\n","          Conv2d-345          [-1, 256, 16, 16]       2,359,296\n","          Conv2d-346            [-1, 256, 8, 8]       4,718,592\n","            ReLU-347            [-1, 256, 8, 8]               0\n","          Conv2d-348            [-1, 256, 8, 8]         590,080\n","            ReLU-349            [-1, 256, 8, 8]               0\n","          Conv2d-350            [-1, 256, 8, 8]         590,080\n","ResidualConvUnit-351            [-1, 256, 8, 8]               0\n","FeatureFusionBlock-352          [-1, 256, 16, 16]               0\n","            ReLU-353          [-1, 256, 16, 16]               0\n","          Conv2d-354          [-1, 256, 16, 16]         590,080\n","            ReLU-355          [-1, 256, 16, 16]               0\n","          Conv2d-356          [-1, 256, 16, 16]         590,080\n","ResidualConvUnit-357          [-1, 256, 16, 16]               0\n","            ReLU-358          [-1, 256, 16, 16]               0\n","          Conv2d-359          [-1, 256, 16, 16]         590,080\n","            ReLU-360          [-1, 256, 16, 16]               0\n","          Conv2d-361          [-1, 256, 16, 16]         590,080\n","ResidualConvUnit-362          [-1, 256, 16, 16]               0\n","FeatureFusionBlock-363          [-1, 256, 32, 32]               0\n","            ReLU-364          [-1, 256, 32, 32]               0\n","          Conv2d-365          [-1, 256, 32, 32]         590,080\n","            ReLU-366          [-1, 256, 32, 32]               0\n","          Conv2d-367          [-1, 256, 32, 32]         590,080\n","ResidualConvUnit-368          [-1, 256, 32, 32]               0\n","            ReLU-369          [-1, 256, 32, 32]               0\n","          Conv2d-370          [-1, 256, 32, 32]         590,080\n","            ReLU-371          [-1, 256, 32, 32]               0\n","          Conv2d-372          [-1, 256, 32, 32]         590,080\n","ResidualConvUnit-373          [-1, 256, 32, 32]               0\n","FeatureFusionBlock-374          [-1, 256, 64, 64]               0\n","            ReLU-375          [-1, 256, 64, 64]               0\n","          Conv2d-376          [-1, 256, 64, 64]         590,080\n","            ReLU-377          [-1, 256, 64, 64]               0\n","          Conv2d-378          [-1, 256, 64, 64]         590,080\n","ResidualConvUnit-379          [-1, 256, 64, 64]               0\n","            ReLU-380          [-1, 256, 64, 64]               0\n","          Conv2d-381          [-1, 256, 64, 64]         590,080\n","            ReLU-382          [-1, 256, 64, 64]               0\n","          Conv2d-383          [-1, 256, 64, 64]         590,080\n","ResidualConvUnit-384          [-1, 256, 64, 64]               0\n","FeatureFusionBlock-385        [-1, 256, 128, 128]               0\n","          Conv2d-386        [-1, 128, 128, 128]         295,040\n","     Interpolate-387        [-1, 128, 256, 256]               0\n","          Conv2d-388         [-1, 32, 256, 256]          36,896\n","            ReLU-389         [-1, 32, 256, 256]               0\n","          Conv2d-390          [-1, 1, 256, 256]              33\n","            ReLU-391          [-1, 1, 256, 256]               0\n","          Conv2d-392        [-1, 256, 128, 128]           6,912\n","     BatchNorm2d-393        [-1, 256, 128, 128]             512\n","            ReLU-394        [-1, 256, 128, 128]               0\n","          Conv2d-395          [-1, 256, 64, 64]         589,824\n","     BatchNorm2d-396          [-1, 256, 64, 64]             512\n","            ReLU-397          [-1, 256, 64, 64]               0\n","          Conv2d-398          [-1, 256, 32, 32]         589,824\n","     BatchNorm2d-399          [-1, 256, 32, 32]             512\n","            ReLU-400          [-1, 256, 32, 32]               0\n","          Conv2d-401          [-1, 512, 16, 16]       1,179,648\n","     BatchNorm2d-402          [-1, 512, 16, 16]           1,024\n","            ReLU-403          [-1, 512, 16, 16]               0\n","          Conv2d-404           [-1, 1024, 8, 8]       4,718,592\n","     BatchNorm2d-405           [-1, 1024, 8, 8]           2,048\n","            ReLU-406           [-1, 1024, 8, 8]               0\n","          Conv2d-407           [-1, 1024, 8, 8]       2,097,152\n","     BatchNorm2d-408           [-1, 1024, 8, 8]           2,048\n","            ReLU-409           [-1, 1024, 8, 8]               0\n","          Conv2d-410             [-1, 27, 8, 8]          27,675\n","       YOLOLayer-411           [-1, 3, 8, 8, 9]               0\n","     Interpolate-412         [-1, 1024, 16, 16]               0\n","          Conv2d-413          [-1, 256, 16, 16]         262,144\n","     BatchNorm2d-414          [-1, 256, 16, 16]             512\n","            ReLU-415          [-1, 256, 16, 16]               0\n","          Conv2d-416          [-1, 512, 16, 16]         524,288\n","     BatchNorm2d-417          [-1, 512, 16, 16]           1,024\n","            ReLU-418          [-1, 512, 16, 16]               0\n","          Conv2d-419          [-1, 256, 16, 16]         196,608\n","     BatchNorm2d-420          [-1, 256, 16, 16]             512\n","            ReLU-421          [-1, 256, 16, 16]               0\n","          Conv2d-422          [-1, 512, 16, 16]       1,179,648\n","     BatchNorm2d-423          [-1, 512, 16, 16]           1,024\n","            ReLU-424          [-1, 512, 16, 16]               0\n","          Conv2d-425          [-1, 256, 16, 16]         131,072\n","     BatchNorm2d-426          [-1, 256, 16, 16]             512\n","            ReLU-427          [-1, 256, 16, 16]               0\n","          Conv2d-428          [-1, 512, 16, 16]       1,179,648\n","     BatchNorm2d-429          [-1, 512, 16, 16]           1,024\n","            ReLU-430          [-1, 512, 16, 16]               0\n","          Conv2d-431          [-1, 256, 16, 16]         131,072\n","     BatchNorm2d-432          [-1, 256, 16, 16]             512\n","            ReLU-433          [-1, 256, 16, 16]               0\n","          Conv2d-434          [-1, 512, 16, 16]       1,179,648\n","     BatchNorm2d-435          [-1, 512, 16, 16]           1,024\n","            ReLU-436          [-1, 512, 16, 16]               0\n","          Conv2d-437           [-1, 27, 16, 16]          13,851\n","       YOLOLayer-438         [-1, 3, 16, 16, 9]               0\n","          Conv2d-439          [-1, 256, 32, 32]         131,072\n","     BatchNorm2d-440          [-1, 256, 32, 32]             512\n","            ReLU-441          [-1, 256, 32, 32]               0\n","     Interpolate-442          [-1, 512, 32, 32]               0\n","          Conv2d-443          [-1, 128, 32, 32]          65,536\n","     BatchNorm2d-444          [-1, 128, 32, 32]             256\n","            ReLU-445          [-1, 128, 32, 32]               0\n","          Conv2d-446          [-1, 128, 32, 32]          49,152\n","     BatchNorm2d-447          [-1, 128, 32, 32]             256\n","            ReLU-448          [-1, 128, 32, 32]               0\n","          Conv2d-449          [-1, 256, 32, 32]         294,912\n","     BatchNorm2d-450          [-1, 256, 32, 32]             512\n","            ReLU-451          [-1, 256, 32, 32]               0\n","          Conv2d-452          [-1, 128, 32, 32]          32,768\n","     BatchNorm2d-453          [-1, 128, 32, 32]             256\n","            ReLU-454          [-1, 128, 32, 32]               0\n","          Conv2d-455          [-1, 256, 32, 32]         294,912\n","     BatchNorm2d-456          [-1, 256, 32, 32]             512\n","            ReLU-457          [-1, 256, 32, 32]               0\n","          Conv2d-458          [-1, 128, 32, 32]          32,768\n","     BatchNorm2d-459          [-1, 128, 32, 32]             256\n","            ReLU-460          [-1, 128, 32, 32]               0\n","          Conv2d-461          [-1, 256, 32, 32]         294,912\n","     BatchNorm2d-462          [-1, 256, 32, 32]             512\n","            ReLU-463          [-1, 256, 32, 32]               0\n","          Conv2d-464           [-1, 27, 32, 32]           6,939\n","       YOLOLayer-465         [-1, 3, 32, 32, 9]               0\n","================================================================\n","Total params: 119,409,234\n","Trainable params: 15,226,449\n","Non-trainable params: 104,182,785\n","----------------------------------------------------------------\n","Input size (MB): 0.75\n","Forward/backward pass size (MB): 1473.30\n","Params size (MB): 455.51\n","Estimated Total Size (MB): 1929.56\n","----------------------------------------------------------------\n","Image sizes 256 - 256 train, 256 test\n","Using 4 dataloader workers\n","Starting training for 300 epochs...\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","  0% 0/346 [00:00<?, ?it/s]/usr/local/lib/python3.6/dist-packages/torch/cuda/memory.py:346: FutureWarning: torch.cuda.memory_cached has been renamed to torch.cuda.memory_reserved\n","  FutureWarning)\n","   160/299     2.09G       4.9      1.96     0.608      7.47        27       256: 100% 346/346 [02:13<00:00,  2.58it/s]\n","               Class    Images   Targets         P         R   mAP@0.5        F1:   0% 0/87 [00:00<?, ?it/s]/content/drive/My Drive/computer_vision/capstone_project/yolo_v3/utils/utils.py:544: UserWarning: This overload of nonzero is deprecated:\n","\tnonzero()\n","Consider using one of the following signatures instead:\n","\tnonzero(*, bool as_tuple) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:882.)\n","  i, j = (x[:, 5:] > conf_thres).nonzero().t()\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 87/87 [00:23<00:00,  3.78it/s]\n","                 all       692  3.06e+03     0.216     0.485     0.242     0.298\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","  0% 0/346 [00:00<?, ?it/s]/usr/local/lib/python3.6/dist-packages/torch/cuda/memory.py:346: FutureWarning: torch.cuda.memory_cached has been renamed to torch.cuda.memory_reserved\n","  FutureWarning)\n","   161/299     2.09G      4.82      1.88     0.582      7.28        58       256: 100% 346/346 [02:12<00:00,  2.60it/s]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 87/87 [00:21<00:00,  4.07it/s]\n","                 all       692  3.06e+03     0.216     0.475     0.243     0.297\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","   162/299     2.09G      4.81      1.87     0.569      7.25        38       256: 100% 346/346 [02:13<00:00,  2.59it/s]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 87/87 [00:21<00:00,  4.10it/s]\n","                 all       692  3.06e+03     0.213     0.483     0.237     0.296\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","   163/299     2.09G      4.82      1.85     0.515      7.19        37       256:  68% 235/346 [01:31<00:41,  2.67it/s]"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"-Xv2yAaJmgb0","colab":{"base_uri":"https://localhost:8080/"},"outputId":"636679fb-22aa-44fe-8af9-2b8b874ce796"},"source":["!python train.py --data data/customdata/custom.data --batch 16  --cache --cfg cfg/yolov3-custom.cfg --epochs 300 --weights 'weights/best.pt'  --img-size=448 --midasnet_freeze='True'"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Namespace(accumulate=4, adam=False, batch_size=16, bucket='', cache_images=True, cfg='cfg/yolov3-custom.cfg', data='data/customdata/custom.data', device='', epochs=300, evolve=False, img_size=[448], init_train='False', midas_weights='', midasnet_freeze='True', multi_scale=False, name='', nosave=False, notest=False, rect=False, resume=False, single_cls=False, weights='weights/best.pt', yolo_weights='')\n","Using CUDA device0 _CudaDeviceProperties(name='Tesla P100-PCIE-16GB', total_memory=16280MB)\n","\n","2020-11-14 16:39:16.272632: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n","Run 'tensorboard --logdir=runs' to view tensorboard at http://localhost:6006/\n","cfg - cfg/yolov3-custom.cfg\n","data - data/customdata/custom.data\n","epochs - 300\n","batch_size - 16\n","accumulate - 4\n","yolo weights - \n","midas weights - \n","imgsz_min- 448, imgsz_max- 448, imgsz_test- 448\n","opt.rect - False\n","train_path - data/customdata/train.txt\n","test_path - data/customdata/test.txt\n","init_train - False\n","weights - weights/best.pt\n","midasnet_freeze - True\n","Using cache found in /root/.cache/torch/hub/facebookresearch_WSL-Images_master\n","Caching labels (2623 found, 114 missing, 30 empty, 0 duplicate, for 2767 images): 100% 2767/2767 [00:03<00:00, 708.58it/s]\n","Caching images (1.2GB): 100% 2767/2767 [01:37<00:00, 28.33it/s]\n","Caching labels (657 found, 27 missing, 8 empty, 0 duplicate, for 692 images): 100% 692/692 [00:00<00:00, 814.10it/s]\n","Caching images (0.2GB): 100% 692/692 [00:26<00:00, 26.39it/s]\n","Freezing the midasnet\n","YMP Model Summary\n","----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","            Conv2d-1         [-1, 64, 224, 224]           9,408\n","       BatchNorm2d-2         [-1, 64, 224, 224]             128\n","              ReLU-3         [-1, 64, 224, 224]               0\n","         MaxPool2d-4         [-1, 64, 112, 112]               0\n","            Conv2d-5        [-1, 256, 112, 112]          16,384\n","       BatchNorm2d-6        [-1, 256, 112, 112]             512\n","              ReLU-7        [-1, 256, 112, 112]               0\n","            Conv2d-8        [-1, 256, 112, 112]          18,432\n","       BatchNorm2d-9        [-1, 256, 112, 112]             512\n","             ReLU-10        [-1, 256, 112, 112]               0\n","           Conv2d-11        [-1, 256, 112, 112]          65,536\n","      BatchNorm2d-12        [-1, 256, 112, 112]             512\n","           Conv2d-13        [-1, 256, 112, 112]          16,384\n","      BatchNorm2d-14        [-1, 256, 112, 112]             512\n","             ReLU-15        [-1, 256, 112, 112]               0\n","       Bottleneck-16        [-1, 256, 112, 112]               0\n","           Conv2d-17        [-1, 256, 112, 112]          65,536\n","      BatchNorm2d-18        [-1, 256, 112, 112]             512\n","             ReLU-19        [-1, 256, 112, 112]               0\n","           Conv2d-20        [-1, 256, 112, 112]          18,432\n","      BatchNorm2d-21        [-1, 256, 112, 112]             512\n","             ReLU-22        [-1, 256, 112, 112]               0\n","           Conv2d-23        [-1, 256, 112, 112]          65,536\n","      BatchNorm2d-24        [-1, 256, 112, 112]             512\n","             ReLU-25        [-1, 256, 112, 112]               0\n","       Bottleneck-26        [-1, 256, 112, 112]               0\n","           Conv2d-27        [-1, 256, 112, 112]          65,536\n","      BatchNorm2d-28        [-1, 256, 112, 112]             512\n","             ReLU-29        [-1, 256, 112, 112]               0\n","           Conv2d-30        [-1, 256, 112, 112]          18,432\n","      BatchNorm2d-31        [-1, 256, 112, 112]             512\n","             ReLU-32        [-1, 256, 112, 112]               0\n","           Conv2d-33        [-1, 256, 112, 112]          65,536\n","      BatchNorm2d-34        [-1, 256, 112, 112]             512\n","             ReLU-35        [-1, 256, 112, 112]               0\n","       Bottleneck-36        [-1, 256, 112, 112]               0\n","           Conv2d-37        [-1, 512, 112, 112]         131,072\n","      BatchNorm2d-38        [-1, 512, 112, 112]           1,024\n","             ReLU-39        [-1, 512, 112, 112]               0\n","           Conv2d-40          [-1, 512, 56, 56]          73,728\n","      BatchNorm2d-41          [-1, 512, 56, 56]           1,024\n","             ReLU-42          [-1, 512, 56, 56]               0\n","           Conv2d-43          [-1, 512, 56, 56]         262,144\n","      BatchNorm2d-44          [-1, 512, 56, 56]           1,024\n","           Conv2d-45          [-1, 512, 56, 56]         131,072\n","      BatchNorm2d-46          [-1, 512, 56, 56]           1,024\n","             ReLU-47          [-1, 512, 56, 56]               0\n","       Bottleneck-48          [-1, 512, 56, 56]               0\n","           Conv2d-49          [-1, 512, 56, 56]         262,144\n","      BatchNorm2d-50          [-1, 512, 56, 56]           1,024\n","             ReLU-51          [-1, 512, 56, 56]               0\n","           Conv2d-52          [-1, 512, 56, 56]          73,728\n","      BatchNorm2d-53          [-1, 512, 56, 56]           1,024\n","             ReLU-54          [-1, 512, 56, 56]               0\n","           Conv2d-55          [-1, 512, 56, 56]         262,144\n","      BatchNorm2d-56          [-1, 512, 56, 56]           1,024\n","             ReLU-57          [-1, 512, 56, 56]               0\n","       Bottleneck-58          [-1, 512, 56, 56]               0\n","           Conv2d-59          [-1, 512, 56, 56]         262,144\n","      BatchNorm2d-60          [-1, 512, 56, 56]           1,024\n","             ReLU-61          [-1, 512, 56, 56]               0\n","           Conv2d-62          [-1, 512, 56, 56]          73,728\n","      BatchNorm2d-63          [-1, 512, 56, 56]           1,024\n","             ReLU-64          [-1, 512, 56, 56]               0\n","           Conv2d-65          [-1, 512, 56, 56]         262,144\n","      BatchNorm2d-66          [-1, 512, 56, 56]           1,024\n","             ReLU-67          [-1, 512, 56, 56]               0\n","       Bottleneck-68          [-1, 512, 56, 56]               0\n","           Conv2d-69          [-1, 512, 56, 56]         262,144\n","      BatchNorm2d-70          [-1, 512, 56, 56]           1,024\n","             ReLU-71          [-1, 512, 56, 56]               0\n","           Conv2d-72          [-1, 512, 56, 56]          73,728\n","      BatchNorm2d-73          [-1, 512, 56, 56]           1,024\n","             ReLU-74          [-1, 512, 56, 56]               0\n","           Conv2d-75          [-1, 512, 56, 56]         262,144\n","      BatchNorm2d-76          [-1, 512, 56, 56]           1,024\n","             ReLU-77          [-1, 512, 56, 56]               0\n","       Bottleneck-78          [-1, 512, 56, 56]               0\n","           Conv2d-79         [-1, 1024, 56, 56]         524,288\n","      BatchNorm2d-80         [-1, 1024, 56, 56]           2,048\n","             ReLU-81         [-1, 1024, 56, 56]               0\n","           Conv2d-82         [-1, 1024, 28, 28]         294,912\n","      BatchNorm2d-83         [-1, 1024, 28, 28]           2,048\n","             ReLU-84         [-1, 1024, 28, 28]               0\n","           Conv2d-85         [-1, 1024, 28, 28]       1,048,576\n","      BatchNorm2d-86         [-1, 1024, 28, 28]           2,048\n","           Conv2d-87         [-1, 1024, 28, 28]         524,288\n","      BatchNorm2d-88         [-1, 1024, 28, 28]           2,048\n","             ReLU-89         [-1, 1024, 28, 28]               0\n","       Bottleneck-90         [-1, 1024, 28, 28]               0\n","           Conv2d-91         [-1, 1024, 28, 28]       1,048,576\n","      BatchNorm2d-92         [-1, 1024, 28, 28]           2,048\n","             ReLU-93         [-1, 1024, 28, 28]               0\n","           Conv2d-94         [-1, 1024, 28, 28]         294,912\n","      BatchNorm2d-95         [-1, 1024, 28, 28]           2,048\n","             ReLU-96         [-1, 1024, 28, 28]               0\n","           Conv2d-97         [-1, 1024, 28, 28]       1,048,576\n","      BatchNorm2d-98         [-1, 1024, 28, 28]           2,048\n","             ReLU-99         [-1, 1024, 28, 28]               0\n","      Bottleneck-100         [-1, 1024, 28, 28]               0\n","          Conv2d-101         [-1, 1024, 28, 28]       1,048,576\n","     BatchNorm2d-102         [-1, 1024, 28, 28]           2,048\n","            ReLU-103         [-1, 1024, 28, 28]               0\n","          Conv2d-104         [-1, 1024, 28, 28]         294,912\n","     BatchNorm2d-105         [-1, 1024, 28, 28]           2,048\n","            ReLU-106         [-1, 1024, 28, 28]               0\n","          Conv2d-107         [-1, 1024, 28, 28]       1,048,576\n","     BatchNorm2d-108         [-1, 1024, 28, 28]           2,048\n","            ReLU-109         [-1, 1024, 28, 28]               0\n","      Bottleneck-110         [-1, 1024, 28, 28]               0\n","          Conv2d-111         [-1, 1024, 28, 28]       1,048,576\n","     BatchNorm2d-112         [-1, 1024, 28, 28]           2,048\n","            ReLU-113         [-1, 1024, 28, 28]               0\n","          Conv2d-114         [-1, 1024, 28, 28]         294,912\n","     BatchNorm2d-115         [-1, 1024, 28, 28]           2,048\n","            ReLU-116         [-1, 1024, 28, 28]               0\n","          Conv2d-117         [-1, 1024, 28, 28]       1,048,576\n","     BatchNorm2d-118         [-1, 1024, 28, 28]           2,048\n","            ReLU-119         [-1, 1024, 28, 28]               0\n","      Bottleneck-120         [-1, 1024, 28, 28]               0\n","          Conv2d-121         [-1, 1024, 28, 28]       1,048,576\n","     BatchNorm2d-122         [-1, 1024, 28, 28]           2,048\n","            ReLU-123         [-1, 1024, 28, 28]               0\n","          Conv2d-124         [-1, 1024, 28, 28]         294,912\n","     BatchNorm2d-125         [-1, 1024, 28, 28]           2,048\n","            ReLU-126         [-1, 1024, 28, 28]               0\n","          Conv2d-127         [-1, 1024, 28, 28]       1,048,576\n","     BatchNorm2d-128         [-1, 1024, 28, 28]           2,048\n","            ReLU-129         [-1, 1024, 28, 28]               0\n","      Bottleneck-130         [-1, 1024, 28, 28]               0\n","          Conv2d-131         [-1, 1024, 28, 28]       1,048,576\n","     BatchNorm2d-132         [-1, 1024, 28, 28]           2,048\n","            ReLU-133         [-1, 1024, 28, 28]               0\n","          Conv2d-134         [-1, 1024, 28, 28]         294,912\n","     BatchNorm2d-135         [-1, 1024, 28, 28]           2,048\n","            ReLU-136         [-1, 1024, 28, 28]               0\n","          Conv2d-137         [-1, 1024, 28, 28]       1,048,576\n","     BatchNorm2d-138         [-1, 1024, 28, 28]           2,048\n","            ReLU-139         [-1, 1024, 28, 28]               0\n","      Bottleneck-140         [-1, 1024, 28, 28]               0\n","          Conv2d-141         [-1, 1024, 28, 28]       1,048,576\n","     BatchNorm2d-142         [-1, 1024, 28, 28]           2,048\n","            ReLU-143         [-1, 1024, 28, 28]               0\n","          Conv2d-144         [-1, 1024, 28, 28]         294,912\n","     BatchNorm2d-145         [-1, 1024, 28, 28]           2,048\n","            ReLU-146         [-1, 1024, 28, 28]               0\n","          Conv2d-147         [-1, 1024, 28, 28]       1,048,576\n","     BatchNorm2d-148         [-1, 1024, 28, 28]           2,048\n","            ReLU-149         [-1, 1024, 28, 28]               0\n","      Bottleneck-150         [-1, 1024, 28, 28]               0\n","          Conv2d-151         [-1, 1024, 28, 28]       1,048,576\n","     BatchNorm2d-152         [-1, 1024, 28, 28]           2,048\n","            ReLU-153         [-1, 1024, 28, 28]               0\n","          Conv2d-154         [-1, 1024, 28, 28]         294,912\n","     BatchNorm2d-155         [-1, 1024, 28, 28]           2,048\n","            ReLU-156         [-1, 1024, 28, 28]               0\n","          Conv2d-157         [-1, 1024, 28, 28]       1,048,576\n","     BatchNorm2d-158         [-1, 1024, 28, 28]           2,048\n","            ReLU-159         [-1, 1024, 28, 28]               0\n","      Bottleneck-160         [-1, 1024, 28, 28]               0\n","          Conv2d-161         [-1, 1024, 28, 28]       1,048,576\n","     BatchNorm2d-162         [-1, 1024, 28, 28]           2,048\n","            ReLU-163         [-1, 1024, 28, 28]               0\n","          Conv2d-164         [-1, 1024, 28, 28]         294,912\n","     BatchNorm2d-165         [-1, 1024, 28, 28]           2,048\n","            ReLU-166         [-1, 1024, 28, 28]               0\n","          Conv2d-167         [-1, 1024, 28, 28]       1,048,576\n","     BatchNorm2d-168         [-1, 1024, 28, 28]           2,048\n","            ReLU-169         [-1, 1024, 28, 28]               0\n","      Bottleneck-170         [-1, 1024, 28, 28]               0\n","          Conv2d-171         [-1, 1024, 28, 28]       1,048,576\n","     BatchNorm2d-172         [-1, 1024, 28, 28]           2,048\n","            ReLU-173         [-1, 1024, 28, 28]               0\n","          Conv2d-174         [-1, 1024, 28, 28]         294,912\n","     BatchNorm2d-175         [-1, 1024, 28, 28]           2,048\n","            ReLU-176         [-1, 1024, 28, 28]               0\n","          Conv2d-177         [-1, 1024, 28, 28]       1,048,576\n","     BatchNorm2d-178         [-1, 1024, 28, 28]           2,048\n","            ReLU-179         [-1, 1024, 28, 28]               0\n","      Bottleneck-180         [-1, 1024, 28, 28]               0\n","          Conv2d-181         [-1, 1024, 28, 28]       1,048,576\n","     BatchNorm2d-182         [-1, 1024, 28, 28]           2,048\n","            ReLU-183         [-1, 1024, 28, 28]               0\n","          Conv2d-184         [-1, 1024, 28, 28]         294,912\n","     BatchNorm2d-185         [-1, 1024, 28, 28]           2,048\n","            ReLU-186         [-1, 1024, 28, 28]               0\n","          Conv2d-187         [-1, 1024, 28, 28]       1,048,576\n","     BatchNorm2d-188         [-1, 1024, 28, 28]           2,048\n","            ReLU-189         [-1, 1024, 28, 28]               0\n","      Bottleneck-190         [-1, 1024, 28, 28]               0\n","          Conv2d-191         [-1, 1024, 28, 28]       1,048,576\n","     BatchNorm2d-192         [-1, 1024, 28, 28]           2,048\n","            ReLU-193         [-1, 1024, 28, 28]               0\n","          Conv2d-194         [-1, 1024, 28, 28]         294,912\n","     BatchNorm2d-195         [-1, 1024, 28, 28]           2,048\n","            ReLU-196         [-1, 1024, 28, 28]               0\n","          Conv2d-197         [-1, 1024, 28, 28]       1,048,576\n","     BatchNorm2d-198         [-1, 1024, 28, 28]           2,048\n","            ReLU-199         [-1, 1024, 28, 28]               0\n","      Bottleneck-200         [-1, 1024, 28, 28]               0\n","          Conv2d-201         [-1, 1024, 28, 28]       1,048,576\n","     BatchNorm2d-202         [-1, 1024, 28, 28]           2,048\n","            ReLU-203         [-1, 1024, 28, 28]               0\n","          Conv2d-204         [-1, 1024, 28, 28]         294,912\n","     BatchNorm2d-205         [-1, 1024, 28, 28]           2,048\n","            ReLU-206         [-1, 1024, 28, 28]               0\n","          Conv2d-207         [-1, 1024, 28, 28]       1,048,576\n","     BatchNorm2d-208         [-1, 1024, 28, 28]           2,048\n","            ReLU-209         [-1, 1024, 28, 28]               0\n","      Bottleneck-210         [-1, 1024, 28, 28]               0\n","          Conv2d-211         [-1, 1024, 28, 28]       1,048,576\n","     BatchNorm2d-212         [-1, 1024, 28, 28]           2,048\n","            ReLU-213         [-1, 1024, 28, 28]               0\n","          Conv2d-214         [-1, 1024, 28, 28]         294,912\n","     BatchNorm2d-215         [-1, 1024, 28, 28]           2,048\n","            ReLU-216         [-1, 1024, 28, 28]               0\n","          Conv2d-217         [-1, 1024, 28, 28]       1,048,576\n","     BatchNorm2d-218         [-1, 1024, 28, 28]           2,048\n","            ReLU-219         [-1, 1024, 28, 28]               0\n","      Bottleneck-220         [-1, 1024, 28, 28]               0\n","          Conv2d-221         [-1, 1024, 28, 28]       1,048,576\n","     BatchNorm2d-222         [-1, 1024, 28, 28]           2,048\n","            ReLU-223         [-1, 1024, 28, 28]               0\n","          Conv2d-224         [-1, 1024, 28, 28]         294,912\n","     BatchNorm2d-225         [-1, 1024, 28, 28]           2,048\n","            ReLU-226         [-1, 1024, 28, 28]               0\n","          Conv2d-227         [-1, 1024, 28, 28]       1,048,576\n","     BatchNorm2d-228         [-1, 1024, 28, 28]           2,048\n","            ReLU-229         [-1, 1024, 28, 28]               0\n","      Bottleneck-230         [-1, 1024, 28, 28]               0\n","          Conv2d-231         [-1, 1024, 28, 28]       1,048,576\n","     BatchNorm2d-232         [-1, 1024, 28, 28]           2,048\n","            ReLU-233         [-1, 1024, 28, 28]               0\n","          Conv2d-234         [-1, 1024, 28, 28]         294,912\n","     BatchNorm2d-235         [-1, 1024, 28, 28]           2,048\n","            ReLU-236         [-1, 1024, 28, 28]               0\n","          Conv2d-237         [-1, 1024, 28, 28]       1,048,576\n","     BatchNorm2d-238         [-1, 1024, 28, 28]           2,048\n","            ReLU-239         [-1, 1024, 28, 28]               0\n","      Bottleneck-240         [-1, 1024, 28, 28]               0\n","          Conv2d-241         [-1, 1024, 28, 28]       1,048,576\n","     BatchNorm2d-242         [-1, 1024, 28, 28]           2,048\n","            ReLU-243         [-1, 1024, 28, 28]               0\n","          Conv2d-244         [-1, 1024, 28, 28]         294,912\n","     BatchNorm2d-245         [-1, 1024, 28, 28]           2,048\n","            ReLU-246         [-1, 1024, 28, 28]               0\n","          Conv2d-247         [-1, 1024, 28, 28]       1,048,576\n","     BatchNorm2d-248         [-1, 1024, 28, 28]           2,048\n","            ReLU-249         [-1, 1024, 28, 28]               0\n","      Bottleneck-250         [-1, 1024, 28, 28]               0\n","          Conv2d-251         [-1, 1024, 28, 28]       1,048,576\n","     BatchNorm2d-252         [-1, 1024, 28, 28]           2,048\n","            ReLU-253         [-1, 1024, 28, 28]               0\n","          Conv2d-254         [-1, 1024, 28, 28]         294,912\n","     BatchNorm2d-255         [-1, 1024, 28, 28]           2,048\n","            ReLU-256         [-1, 1024, 28, 28]               0\n","          Conv2d-257         [-1, 1024, 28, 28]       1,048,576\n","     BatchNorm2d-258         [-1, 1024, 28, 28]           2,048\n","            ReLU-259         [-1, 1024, 28, 28]               0\n","      Bottleneck-260         [-1, 1024, 28, 28]               0\n","          Conv2d-261         [-1, 1024, 28, 28]       1,048,576\n","     BatchNorm2d-262         [-1, 1024, 28, 28]           2,048\n","            ReLU-263         [-1, 1024, 28, 28]               0\n","          Conv2d-264         [-1, 1024, 28, 28]         294,912\n","     BatchNorm2d-265         [-1, 1024, 28, 28]           2,048\n","            ReLU-266         [-1, 1024, 28, 28]               0\n","          Conv2d-267         [-1, 1024, 28, 28]       1,048,576\n","     BatchNorm2d-268         [-1, 1024, 28, 28]           2,048\n","            ReLU-269         [-1, 1024, 28, 28]               0\n","      Bottleneck-270         [-1, 1024, 28, 28]               0\n","          Conv2d-271         [-1, 1024, 28, 28]       1,048,576\n","     BatchNorm2d-272         [-1, 1024, 28, 28]           2,048\n","            ReLU-273         [-1, 1024, 28, 28]               0\n","          Conv2d-274         [-1, 1024, 28, 28]         294,912\n","     BatchNorm2d-275         [-1, 1024, 28, 28]           2,048\n","            ReLU-276         [-1, 1024, 28, 28]               0\n","          Conv2d-277         [-1, 1024, 28, 28]       1,048,576\n","     BatchNorm2d-278         [-1, 1024, 28, 28]           2,048\n","            ReLU-279         [-1, 1024, 28, 28]               0\n","      Bottleneck-280         [-1, 1024, 28, 28]               0\n","          Conv2d-281         [-1, 1024, 28, 28]       1,048,576\n","     BatchNorm2d-282         [-1, 1024, 28, 28]           2,048\n","            ReLU-283         [-1, 1024, 28, 28]               0\n","          Conv2d-284         [-1, 1024, 28, 28]         294,912\n","     BatchNorm2d-285         [-1, 1024, 28, 28]           2,048\n","            ReLU-286         [-1, 1024, 28, 28]               0\n","          Conv2d-287         [-1, 1024, 28, 28]       1,048,576\n","     BatchNorm2d-288         [-1, 1024, 28, 28]           2,048\n","            ReLU-289         [-1, 1024, 28, 28]               0\n","      Bottleneck-290         [-1, 1024, 28, 28]               0\n","          Conv2d-291         [-1, 1024, 28, 28]       1,048,576\n","     BatchNorm2d-292         [-1, 1024, 28, 28]           2,048\n","            ReLU-293         [-1, 1024, 28, 28]               0\n","          Conv2d-294         [-1, 1024, 28, 28]         294,912\n","     BatchNorm2d-295         [-1, 1024, 28, 28]           2,048\n","            ReLU-296         [-1, 1024, 28, 28]               0\n","          Conv2d-297         [-1, 1024, 28, 28]       1,048,576\n","     BatchNorm2d-298         [-1, 1024, 28, 28]           2,048\n","            ReLU-299         [-1, 1024, 28, 28]               0\n","      Bottleneck-300         [-1, 1024, 28, 28]               0\n","          Conv2d-301         [-1, 1024, 28, 28]       1,048,576\n","     BatchNorm2d-302         [-1, 1024, 28, 28]           2,048\n","            ReLU-303         [-1, 1024, 28, 28]               0\n","          Conv2d-304         [-1, 1024, 28, 28]         294,912\n","     BatchNorm2d-305         [-1, 1024, 28, 28]           2,048\n","            ReLU-306         [-1, 1024, 28, 28]               0\n","          Conv2d-307         [-1, 1024, 28, 28]       1,048,576\n","     BatchNorm2d-308         [-1, 1024, 28, 28]           2,048\n","            ReLU-309         [-1, 1024, 28, 28]               0\n","      Bottleneck-310         [-1, 1024, 28, 28]               0\n","          Conv2d-311         [-1, 2048, 28, 28]       2,097,152\n","     BatchNorm2d-312         [-1, 2048, 28, 28]           4,096\n","            ReLU-313         [-1, 2048, 28, 28]               0\n","          Conv2d-314         [-1, 2048, 14, 14]       1,179,648\n","     BatchNorm2d-315         [-1, 2048, 14, 14]           4,096\n","            ReLU-316         [-1, 2048, 14, 14]               0\n","          Conv2d-317         [-1, 2048, 14, 14]       4,194,304\n","     BatchNorm2d-318         [-1, 2048, 14, 14]           4,096\n","          Conv2d-319         [-1, 2048, 14, 14]       2,097,152\n","     BatchNorm2d-320         [-1, 2048, 14, 14]           4,096\n","            ReLU-321         [-1, 2048, 14, 14]               0\n","      Bottleneck-322         [-1, 2048, 14, 14]               0\n","          Conv2d-323         [-1, 2048, 14, 14]       4,194,304\n","     BatchNorm2d-324         [-1, 2048, 14, 14]           4,096\n","            ReLU-325         [-1, 2048, 14, 14]               0\n","          Conv2d-326         [-1, 2048, 14, 14]       1,179,648\n","     BatchNorm2d-327         [-1, 2048, 14, 14]           4,096\n","            ReLU-328         [-1, 2048, 14, 14]               0\n","          Conv2d-329         [-1, 2048, 14, 14]       4,194,304\n","     BatchNorm2d-330         [-1, 2048, 14, 14]           4,096\n","            ReLU-331         [-1, 2048, 14, 14]               0\n","      Bottleneck-332         [-1, 2048, 14, 14]               0\n","          Conv2d-333         [-1, 2048, 14, 14]       4,194,304\n","     BatchNorm2d-334         [-1, 2048, 14, 14]           4,096\n","            ReLU-335         [-1, 2048, 14, 14]               0\n","          Conv2d-336         [-1, 2048, 14, 14]       1,179,648\n","     BatchNorm2d-337         [-1, 2048, 14, 14]           4,096\n","            ReLU-338         [-1, 2048, 14, 14]               0\n","          Conv2d-339         [-1, 2048, 14, 14]       4,194,304\n","     BatchNorm2d-340         [-1, 2048, 14, 14]           4,096\n","            ReLU-341         [-1, 2048, 14, 14]               0\n","      Bottleneck-342         [-1, 2048, 14, 14]               0\n","          Conv2d-343        [-1, 256, 112, 112]         589,824\n","          Conv2d-344          [-1, 256, 56, 56]       1,179,648\n","          Conv2d-345          [-1, 256, 28, 28]       2,359,296\n","          Conv2d-346          [-1, 256, 14, 14]       4,718,592\n","            ReLU-347          [-1, 256, 14, 14]               0\n","          Conv2d-348          [-1, 256, 14, 14]         590,080\n","            ReLU-349          [-1, 256, 14, 14]               0\n","          Conv2d-350          [-1, 256, 14, 14]         590,080\n","ResidualConvUnit-351          [-1, 256, 14, 14]               0\n","FeatureFusionBlock-352          [-1, 256, 28, 28]               0\n","            ReLU-353          [-1, 256, 28, 28]               0\n","          Conv2d-354          [-1, 256, 28, 28]         590,080\n","            ReLU-355          [-1, 256, 28, 28]               0\n","          Conv2d-356          [-1, 256, 28, 28]         590,080\n","ResidualConvUnit-357          [-1, 256, 28, 28]               0\n","            ReLU-358          [-1, 256, 28, 28]               0\n","          Conv2d-359          [-1, 256, 28, 28]         590,080\n","            ReLU-360          [-1, 256, 28, 28]               0\n","          Conv2d-361          [-1, 256, 28, 28]         590,080\n","ResidualConvUnit-362          [-1, 256, 28, 28]               0\n","FeatureFusionBlock-363          [-1, 256, 56, 56]               0\n","            ReLU-364          [-1, 256, 56, 56]               0\n","          Conv2d-365          [-1, 256, 56, 56]         590,080\n","            ReLU-366          [-1, 256, 56, 56]               0\n","          Conv2d-367          [-1, 256, 56, 56]         590,080\n","ResidualConvUnit-368          [-1, 256, 56, 56]               0\n","            ReLU-369          [-1, 256, 56, 56]               0\n","          Conv2d-370          [-1, 256, 56, 56]         590,080\n","            ReLU-371          [-1, 256, 56, 56]               0\n","          Conv2d-372          [-1, 256, 56, 56]         590,080\n","ResidualConvUnit-373          [-1, 256, 56, 56]               0\n","FeatureFusionBlock-374        [-1, 256, 112, 112]               0\n","            ReLU-375        [-1, 256, 112, 112]               0\n","          Conv2d-376        [-1, 256, 112, 112]         590,080\n","            ReLU-377        [-1, 256, 112, 112]               0\n","          Conv2d-378        [-1, 256, 112, 112]         590,080\n","ResidualConvUnit-379        [-1, 256, 112, 112]               0\n","            ReLU-380        [-1, 256, 112, 112]               0\n","          Conv2d-381        [-1, 256, 112, 112]         590,080\n","            ReLU-382        [-1, 256, 112, 112]               0\n","          Conv2d-383        [-1, 256, 112, 112]         590,080\n","ResidualConvUnit-384        [-1, 256, 112, 112]               0\n","FeatureFusionBlock-385        [-1, 256, 224, 224]               0\n","          Conv2d-386        [-1, 128, 224, 224]         295,040\n","     Interpolate-387        [-1, 128, 448, 448]               0\n","          Conv2d-388         [-1, 32, 448, 448]          36,896\n","            ReLU-389         [-1, 32, 448, 448]               0\n","          Conv2d-390          [-1, 1, 448, 448]              33\n","            ReLU-391          [-1, 1, 448, 448]               0\n","          Conv2d-392        [-1, 256, 224, 224]           6,912\n","     BatchNorm2d-393        [-1, 256, 224, 224]             512\n","            ReLU-394        [-1, 256, 224, 224]               0\n","          Conv2d-395        [-1, 256, 112, 112]         589,824\n","     BatchNorm2d-396        [-1, 256, 112, 112]             512\n","            ReLU-397        [-1, 256, 112, 112]               0\n","          Conv2d-398          [-1, 256, 56, 56]         589,824\n","     BatchNorm2d-399          [-1, 256, 56, 56]             512\n","            ReLU-400          [-1, 256, 56, 56]               0\n","          Conv2d-401          [-1, 512, 28, 28]       1,179,648\n","     BatchNorm2d-402          [-1, 512, 28, 28]           1,024\n","            ReLU-403          [-1, 512, 28, 28]               0\n","          Conv2d-404         [-1, 1024, 14, 14]       4,718,592\n","     BatchNorm2d-405         [-1, 1024, 14, 14]           2,048\n","            ReLU-406         [-1, 1024, 14, 14]               0\n","          Conv2d-407         [-1, 1024, 14, 14]       2,097,152\n","     BatchNorm2d-408         [-1, 1024, 14, 14]           2,048\n","            ReLU-409         [-1, 1024, 14, 14]               0\n","          Conv2d-410           [-1, 27, 14, 14]          27,675\n","       YOLOLayer-411         [-1, 3, 14, 14, 9]               0\n","     Interpolate-412         [-1, 1024, 28, 28]               0\n","          Conv2d-413          [-1, 256, 28, 28]         262,144\n","     BatchNorm2d-414          [-1, 256, 28, 28]             512\n","            ReLU-415          [-1, 256, 28, 28]               0\n","          Conv2d-416          [-1, 512, 28, 28]         524,288\n","     BatchNorm2d-417          [-1, 512, 28, 28]           1,024\n","            ReLU-418          [-1, 512, 28, 28]               0\n","          Conv2d-419          [-1, 256, 28, 28]         196,608\n","     BatchNorm2d-420          [-1, 256, 28, 28]             512\n","            ReLU-421          [-1, 256, 28, 28]               0\n","          Conv2d-422          [-1, 512, 28, 28]       1,179,648\n","     BatchNorm2d-423          [-1, 512, 28, 28]           1,024\n","            ReLU-424          [-1, 512, 28, 28]               0\n","          Conv2d-425          [-1, 256, 28, 28]         131,072\n","     BatchNorm2d-426          [-1, 256, 28, 28]             512\n","            ReLU-427          [-1, 256, 28, 28]               0\n","          Conv2d-428          [-1, 512, 28, 28]       1,179,648\n","     BatchNorm2d-429          [-1, 512, 28, 28]           1,024\n","            ReLU-430          [-1, 512, 28, 28]               0\n","          Conv2d-431          [-1, 256, 28, 28]         131,072\n","     BatchNorm2d-432          [-1, 256, 28, 28]             512\n","            ReLU-433          [-1, 256, 28, 28]               0\n","          Conv2d-434          [-1, 512, 28, 28]       1,179,648\n","     BatchNorm2d-435          [-1, 512, 28, 28]           1,024\n","            ReLU-436          [-1, 512, 28, 28]               0\n","          Conv2d-437           [-1, 27, 28, 28]          13,851\n","       YOLOLayer-438         [-1, 3, 28, 28, 9]               0\n","          Conv2d-439          [-1, 256, 56, 56]         131,072\n","     BatchNorm2d-440          [-1, 256, 56, 56]             512\n","            ReLU-441          [-1, 256, 56, 56]               0\n","     Interpolate-442          [-1, 512, 56, 56]               0\n","          Conv2d-443          [-1, 128, 56, 56]          65,536\n","     BatchNorm2d-444          [-1, 128, 56, 56]             256\n","            ReLU-445          [-1, 128, 56, 56]               0\n","          Conv2d-446          [-1, 128, 56, 56]          49,152\n","     BatchNorm2d-447          [-1, 128, 56, 56]             256\n","            ReLU-448          [-1, 128, 56, 56]               0\n","          Conv2d-449          [-1, 256, 56, 56]         294,912\n","     BatchNorm2d-450          [-1, 256, 56, 56]             512\n","            ReLU-451          [-1, 256, 56, 56]               0\n","          Conv2d-452          [-1, 128, 56, 56]          32,768\n","     BatchNorm2d-453          [-1, 128, 56, 56]             256\n","            ReLU-454          [-1, 128, 56, 56]               0\n","          Conv2d-455          [-1, 256, 56, 56]         294,912\n","     BatchNorm2d-456          [-1, 256, 56, 56]             512\n","            ReLU-457          [-1, 256, 56, 56]               0\n","          Conv2d-458          [-1, 128, 56, 56]          32,768\n","     BatchNorm2d-459          [-1, 128, 56, 56]             256\n","            ReLU-460          [-1, 128, 56, 56]               0\n","          Conv2d-461          [-1, 256, 56, 56]         294,912\n","     BatchNorm2d-462          [-1, 256, 56, 56]             512\n","            ReLU-463          [-1, 256, 56, 56]               0\n","          Conv2d-464           [-1, 27, 56, 56]           6,939\n","       YOLOLayer-465         [-1, 3, 56, 56, 9]               0\n","================================================================\n","Total params: 119,409,234\n","Trainable params: 15,226,449\n","Non-trainable params: 104,182,785\n","----------------------------------------------------------------\n","Input size (MB): 2.30\n","Forward/backward pass size (MB): 4511.99\n","Params size (MB): 455.51\n","Estimated Total Size (MB): 4969.80\n","----------------------------------------------------------------\n","Image sizes 448 - 448 train, 448 test\n","Using 4 dataloader workers\n","Starting training for 300 epochs...\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","  0% 0/173 [00:00<?, ?it/s]/usr/local/lib/python3.6/dist-packages/torch/cuda/memory.py:346: FutureWarning: torch.cuda.memory_cached has been renamed to torch.cuda.memory_reserved\n","  FutureWarning)\n","   160/299     7.25G      4.57      1.25     0.583       6.4       113       448: 100% 173/173 [03:26<00:00,  1.19s/it]\n","               Class    Images   Targets         P         R   mAP@0.5        F1:   0% 0/44 [00:00<?, ?it/s]/content/drive/My Drive/computer_vision/capstone_project/yolo_v3/utils/utils.py:544: UserWarning: This overload of nonzero is deprecated:\n","\tnonzero()\n","Consider using one of the following signatures instead:\n","\tnonzero(*, bool as_tuple) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:882.)\n","  i, j = (x[:, 5:] > conf_thres).nonzero().t()\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 44/44 [00:43<00:00,  1.01it/s]\n","                 all       692  3.06e+03     0.251     0.585      0.35     0.351\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","  0% 0/173 [00:00<?, ?it/s]/usr/local/lib/python3.6/dist-packages/torch/cuda/memory.py:346: FutureWarning: torch.cuda.memory_cached has been renamed to torch.cuda.memory_reserved\n","  FutureWarning)\n","   161/299     7.26G      4.53      1.23     0.565      6.33       113       448: 100% 173/173 [03:26<00:00,  1.19s/it]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 44/44 [00:41<00:00,  1.07it/s]\n","                 all       692  3.06e+03     0.254     0.586     0.359     0.354\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","   162/299     7.26G      4.52      1.24     0.584      6.35       114       448: 100% 173/173 [03:26<00:00,  1.19s/it]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 44/44 [00:41<00:00,  1.07it/s]\n","                 all       692  3.06e+03     0.243     0.591     0.344     0.344\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","   163/299     7.26G      4.53      1.22     0.572      6.32        85       448: 100% 173/173 [03:26<00:00,  1.19s/it]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 44/44 [00:41<00:00,  1.07it/s]\n","                 all       692  3.06e+03     0.255      0.58     0.348     0.354\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","   164/299     7.26G      4.56      1.23     0.571      6.37       101       448: 100% 173/173 [03:26<00:00,  1.19s/it]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 44/44 [00:41<00:00,  1.07it/s]\n","                 all       692  3.06e+03     0.253     0.583     0.326     0.352\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","   165/299     7.26G      4.55      1.24     0.613       6.4        87       448: 100% 173/173 [03:26<00:00,  1.19s/it]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 44/44 [00:41<00:00,  1.07it/s]\n","                 all       692  3.06e+03     0.254     0.575     0.331     0.352\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","   166/299     7.26G      4.53      1.22     0.585      6.34        92       448: 100% 173/173 [03:26<00:00,  1.19s/it]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 44/44 [00:41<00:00,  1.07it/s]\n","                 all       692  3.06e+03     0.254     0.589     0.358     0.354\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","   167/299     7.26G      4.53      1.21     0.582      6.33        91       448: 100% 173/173 [03:27<00:00,  1.20s/it]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 44/44 [00:41<00:00,  1.07it/s]\n","                 all       692  3.06e+03     0.251      0.59     0.351     0.352\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","   168/299     7.26G      4.53      1.24     0.542       6.3        78       448: 100% 173/173 [03:26<00:00,  1.19s/it]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 44/44 [00:41<00:00,  1.07it/s]\n","                 all       692  3.06e+03     0.249     0.575      0.33     0.347\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","   169/299     7.26G       4.5      1.23     0.538      6.26       100       448: 100% 173/173 [03:26<00:00,  1.19s/it]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 44/44 [00:41<00:00,  1.07it/s]\n","                 all       692  3.06e+03     0.247     0.586     0.333     0.347\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","   170/299     7.26G      4.52      1.22     0.538      6.28       114       448:  42% 72/173 [01:27<01:58,  1.18s/it]"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"VXhG0c6HyhnP","colab":{"base_uri":"https://localhost:8080/"},"outputId":"eb29ec0c-24ec-4bdc-be99-a97bc94bb00a"},"source":["!python train.py --data data/customdata/custom.data --batch 8  --cache --cfg cfg/yolov3-custom.cfg --epochs 300 --weights 'weights/best.pt'  --img-size=512 --midasnet_freeze='True'"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Namespace(accumulate=4, adam=False, batch_size=8, bucket='', cache_images=True, cfg='cfg/yolov3-custom.cfg', data='data/customdata/custom.data', device='', epochs=300, evolve=False, img_size=[512], init_train='False', midas_weights='', midasnet_freeze='True', multi_scale=False, name='', nosave=False, notest=False, rect=False, resume=False, single_cls=False, weights='weights/best.pt', yolo_weights='')\n","Using CUDA device0 _CudaDeviceProperties(name='Tesla P100-PCIE-16GB', total_memory=16280MB)\n","\n","2020-11-14 17:25:46.233087: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n","Run 'tensorboard --logdir=runs' to view tensorboard at http://localhost:6006/\n","cfg - cfg/yolov3-custom.cfg\n","data - data/customdata/custom.data\n","epochs - 300\n","batch_size - 8\n","accumulate - 4\n","yolo weights - \n","midas weights - \n","imgsz_min- 512, imgsz_max- 512, imgsz_test- 512\n","opt.rect - False\n","train_path - data/customdata/train.txt\n","test_path - data/customdata/test.txt\n","init_train - False\n","weights - weights/best.pt\n","midasnet_freeze - True\n","Using cache found in /root/.cache/torch/hub/facebookresearch_WSL-Images_master\n","Caching labels (2623 found, 114 missing, 30 empty, 0 duplicate, for 2767 images): 100% 2767/2767 [00:03<00:00, 716.73it/s]\n","Caching images (1.5GB): 100% 2767/2767 [01:26<00:00, 31.80it/s]\n","Caching labels (657 found, 27 missing, 8 empty, 0 duplicate, for 692 images): 100% 692/692 [00:00<00:00, 910.67it/s]\n","Caching images (0.3GB): 100% 692/692 [00:23<00:00, 29.99it/s]\n","Freezing the midasnet\n","YMP Model Summary\n","----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","            Conv2d-1         [-1, 64, 256, 256]           9,408\n","       BatchNorm2d-2         [-1, 64, 256, 256]             128\n","              ReLU-3         [-1, 64, 256, 256]               0\n","         MaxPool2d-4         [-1, 64, 128, 128]               0\n","            Conv2d-5        [-1, 256, 128, 128]          16,384\n","       BatchNorm2d-6        [-1, 256, 128, 128]             512\n","              ReLU-7        [-1, 256, 128, 128]               0\n","            Conv2d-8        [-1, 256, 128, 128]          18,432\n","       BatchNorm2d-9        [-1, 256, 128, 128]             512\n","             ReLU-10        [-1, 256, 128, 128]               0\n","           Conv2d-11        [-1, 256, 128, 128]          65,536\n","      BatchNorm2d-12        [-1, 256, 128, 128]             512\n","           Conv2d-13        [-1, 256, 128, 128]          16,384\n","      BatchNorm2d-14        [-1, 256, 128, 128]             512\n","             ReLU-15        [-1, 256, 128, 128]               0\n","       Bottleneck-16        [-1, 256, 128, 128]               0\n","           Conv2d-17        [-1, 256, 128, 128]          65,536\n","      BatchNorm2d-18        [-1, 256, 128, 128]             512\n","             ReLU-19        [-1, 256, 128, 128]               0\n","           Conv2d-20        [-1, 256, 128, 128]          18,432\n","      BatchNorm2d-21        [-1, 256, 128, 128]             512\n","             ReLU-22        [-1, 256, 128, 128]               0\n","           Conv2d-23        [-1, 256, 128, 128]          65,536\n","      BatchNorm2d-24        [-1, 256, 128, 128]             512\n","             ReLU-25        [-1, 256, 128, 128]               0\n","       Bottleneck-26        [-1, 256, 128, 128]               0\n","           Conv2d-27        [-1, 256, 128, 128]          65,536\n","      BatchNorm2d-28        [-1, 256, 128, 128]             512\n","             ReLU-29        [-1, 256, 128, 128]               0\n","           Conv2d-30        [-1, 256, 128, 128]          18,432\n","      BatchNorm2d-31        [-1, 256, 128, 128]             512\n","             ReLU-32        [-1, 256, 128, 128]               0\n","           Conv2d-33        [-1, 256, 128, 128]          65,536\n","      BatchNorm2d-34        [-1, 256, 128, 128]             512\n","             ReLU-35        [-1, 256, 128, 128]               0\n","       Bottleneck-36        [-1, 256, 128, 128]               0\n","           Conv2d-37        [-1, 512, 128, 128]         131,072\n","      BatchNorm2d-38        [-1, 512, 128, 128]           1,024\n","             ReLU-39        [-1, 512, 128, 128]               0\n","           Conv2d-40          [-1, 512, 64, 64]          73,728\n","      BatchNorm2d-41          [-1, 512, 64, 64]           1,024\n","             ReLU-42          [-1, 512, 64, 64]               0\n","           Conv2d-43          [-1, 512, 64, 64]         262,144\n","      BatchNorm2d-44          [-1, 512, 64, 64]           1,024\n","           Conv2d-45          [-1, 512, 64, 64]         131,072\n","      BatchNorm2d-46          [-1, 512, 64, 64]           1,024\n","             ReLU-47          [-1, 512, 64, 64]               0\n","       Bottleneck-48          [-1, 512, 64, 64]               0\n","           Conv2d-49          [-1, 512, 64, 64]         262,144\n","      BatchNorm2d-50          [-1, 512, 64, 64]           1,024\n","             ReLU-51          [-1, 512, 64, 64]               0\n","           Conv2d-52          [-1, 512, 64, 64]          73,728\n","      BatchNorm2d-53          [-1, 512, 64, 64]           1,024\n","             ReLU-54          [-1, 512, 64, 64]               0\n","           Conv2d-55          [-1, 512, 64, 64]         262,144\n","      BatchNorm2d-56          [-1, 512, 64, 64]           1,024\n","             ReLU-57          [-1, 512, 64, 64]               0\n","       Bottleneck-58          [-1, 512, 64, 64]               0\n","           Conv2d-59          [-1, 512, 64, 64]         262,144\n","      BatchNorm2d-60          [-1, 512, 64, 64]           1,024\n","             ReLU-61          [-1, 512, 64, 64]               0\n","           Conv2d-62          [-1, 512, 64, 64]          73,728\n","      BatchNorm2d-63          [-1, 512, 64, 64]           1,024\n","             ReLU-64          [-1, 512, 64, 64]               0\n","           Conv2d-65          [-1, 512, 64, 64]         262,144\n","      BatchNorm2d-66          [-1, 512, 64, 64]           1,024\n","             ReLU-67          [-1, 512, 64, 64]               0\n","       Bottleneck-68          [-1, 512, 64, 64]               0\n","           Conv2d-69          [-1, 512, 64, 64]         262,144\n","      BatchNorm2d-70          [-1, 512, 64, 64]           1,024\n","             ReLU-71          [-1, 512, 64, 64]               0\n","           Conv2d-72          [-1, 512, 64, 64]          73,728\n","      BatchNorm2d-73          [-1, 512, 64, 64]           1,024\n","             ReLU-74          [-1, 512, 64, 64]               0\n","           Conv2d-75          [-1, 512, 64, 64]         262,144\n","      BatchNorm2d-76          [-1, 512, 64, 64]           1,024\n","             ReLU-77          [-1, 512, 64, 64]               0\n","       Bottleneck-78          [-1, 512, 64, 64]               0\n","           Conv2d-79         [-1, 1024, 64, 64]         524,288\n","      BatchNorm2d-80         [-1, 1024, 64, 64]           2,048\n","             ReLU-81         [-1, 1024, 64, 64]               0\n","           Conv2d-82         [-1, 1024, 32, 32]         294,912\n","      BatchNorm2d-83         [-1, 1024, 32, 32]           2,048\n","             ReLU-84         [-1, 1024, 32, 32]               0\n","           Conv2d-85         [-1, 1024, 32, 32]       1,048,576\n","      BatchNorm2d-86         [-1, 1024, 32, 32]           2,048\n","           Conv2d-87         [-1, 1024, 32, 32]         524,288\n","      BatchNorm2d-88         [-1, 1024, 32, 32]           2,048\n","             ReLU-89         [-1, 1024, 32, 32]               0\n","       Bottleneck-90         [-1, 1024, 32, 32]               0\n","           Conv2d-91         [-1, 1024, 32, 32]       1,048,576\n","      BatchNorm2d-92         [-1, 1024, 32, 32]           2,048\n","             ReLU-93         [-1, 1024, 32, 32]               0\n","           Conv2d-94         [-1, 1024, 32, 32]         294,912\n","      BatchNorm2d-95         [-1, 1024, 32, 32]           2,048\n","             ReLU-96         [-1, 1024, 32, 32]               0\n","           Conv2d-97         [-1, 1024, 32, 32]       1,048,576\n","      BatchNorm2d-98         [-1, 1024, 32, 32]           2,048\n","             ReLU-99         [-1, 1024, 32, 32]               0\n","      Bottleneck-100         [-1, 1024, 32, 32]               0\n","          Conv2d-101         [-1, 1024, 32, 32]       1,048,576\n","     BatchNorm2d-102         [-1, 1024, 32, 32]           2,048\n","            ReLU-103         [-1, 1024, 32, 32]               0\n","          Conv2d-104         [-1, 1024, 32, 32]         294,912\n","     BatchNorm2d-105         [-1, 1024, 32, 32]           2,048\n","            ReLU-106         [-1, 1024, 32, 32]               0\n","          Conv2d-107         [-1, 1024, 32, 32]       1,048,576\n","     BatchNorm2d-108         [-1, 1024, 32, 32]           2,048\n","            ReLU-109         [-1, 1024, 32, 32]               0\n","      Bottleneck-110         [-1, 1024, 32, 32]               0\n","          Conv2d-111         [-1, 1024, 32, 32]       1,048,576\n","     BatchNorm2d-112         [-1, 1024, 32, 32]           2,048\n","            ReLU-113         [-1, 1024, 32, 32]               0\n","          Conv2d-114         [-1, 1024, 32, 32]         294,912\n","     BatchNorm2d-115         [-1, 1024, 32, 32]           2,048\n","            ReLU-116         [-1, 1024, 32, 32]               0\n","          Conv2d-117         [-1, 1024, 32, 32]       1,048,576\n","     BatchNorm2d-118         [-1, 1024, 32, 32]           2,048\n","            ReLU-119         [-1, 1024, 32, 32]               0\n","      Bottleneck-120         [-1, 1024, 32, 32]               0\n","          Conv2d-121         [-1, 1024, 32, 32]       1,048,576\n","     BatchNorm2d-122         [-1, 1024, 32, 32]           2,048\n","            ReLU-123         [-1, 1024, 32, 32]               0\n","          Conv2d-124         [-1, 1024, 32, 32]         294,912\n","     BatchNorm2d-125         [-1, 1024, 32, 32]           2,048\n","            ReLU-126         [-1, 1024, 32, 32]               0\n","          Conv2d-127         [-1, 1024, 32, 32]       1,048,576\n","     BatchNorm2d-128         [-1, 1024, 32, 32]           2,048\n","            ReLU-129         [-1, 1024, 32, 32]               0\n","      Bottleneck-130         [-1, 1024, 32, 32]               0\n","          Conv2d-131         [-1, 1024, 32, 32]       1,048,576\n","     BatchNorm2d-132         [-1, 1024, 32, 32]           2,048\n","            ReLU-133         [-1, 1024, 32, 32]               0\n","          Conv2d-134         [-1, 1024, 32, 32]         294,912\n","     BatchNorm2d-135         [-1, 1024, 32, 32]           2,048\n","            ReLU-136         [-1, 1024, 32, 32]               0\n","          Conv2d-137         [-1, 1024, 32, 32]       1,048,576\n","     BatchNorm2d-138         [-1, 1024, 32, 32]           2,048\n","            ReLU-139         [-1, 1024, 32, 32]               0\n","      Bottleneck-140         [-1, 1024, 32, 32]               0\n","          Conv2d-141         [-1, 1024, 32, 32]       1,048,576\n","     BatchNorm2d-142         [-1, 1024, 32, 32]           2,048\n","            ReLU-143         [-1, 1024, 32, 32]               0\n","          Conv2d-144         [-1, 1024, 32, 32]         294,912\n","     BatchNorm2d-145         [-1, 1024, 32, 32]           2,048\n","            ReLU-146         [-1, 1024, 32, 32]               0\n","          Conv2d-147         [-1, 1024, 32, 32]       1,048,576\n","     BatchNorm2d-148         [-1, 1024, 32, 32]           2,048\n","            ReLU-149         [-1, 1024, 32, 32]               0\n","      Bottleneck-150         [-1, 1024, 32, 32]               0\n","          Conv2d-151         [-1, 1024, 32, 32]       1,048,576\n","     BatchNorm2d-152         [-1, 1024, 32, 32]           2,048\n","            ReLU-153         [-1, 1024, 32, 32]               0\n","          Conv2d-154         [-1, 1024, 32, 32]         294,912\n","     BatchNorm2d-155         [-1, 1024, 32, 32]           2,048\n","            ReLU-156         [-1, 1024, 32, 32]               0\n","          Conv2d-157         [-1, 1024, 32, 32]       1,048,576\n","     BatchNorm2d-158         [-1, 1024, 32, 32]           2,048\n","            ReLU-159         [-1, 1024, 32, 32]               0\n","      Bottleneck-160         [-1, 1024, 32, 32]               0\n","          Conv2d-161         [-1, 1024, 32, 32]       1,048,576\n","     BatchNorm2d-162         [-1, 1024, 32, 32]           2,048\n","            ReLU-163         [-1, 1024, 32, 32]               0\n","          Conv2d-164         [-1, 1024, 32, 32]         294,912\n","     BatchNorm2d-165         [-1, 1024, 32, 32]           2,048\n","            ReLU-166         [-1, 1024, 32, 32]               0\n","          Conv2d-167         [-1, 1024, 32, 32]       1,048,576\n","     BatchNorm2d-168         [-1, 1024, 32, 32]           2,048\n","            ReLU-169         [-1, 1024, 32, 32]               0\n","      Bottleneck-170         [-1, 1024, 32, 32]               0\n","          Conv2d-171         [-1, 1024, 32, 32]       1,048,576\n","     BatchNorm2d-172         [-1, 1024, 32, 32]           2,048\n","            ReLU-173         [-1, 1024, 32, 32]               0\n","          Conv2d-174         [-1, 1024, 32, 32]         294,912\n","     BatchNorm2d-175         [-1, 1024, 32, 32]           2,048\n","            ReLU-176         [-1, 1024, 32, 32]               0\n","          Conv2d-177         [-1, 1024, 32, 32]       1,048,576\n","     BatchNorm2d-178         [-1, 1024, 32, 32]           2,048\n","            ReLU-179         [-1, 1024, 32, 32]               0\n","      Bottleneck-180         [-1, 1024, 32, 32]               0\n","          Conv2d-181         [-1, 1024, 32, 32]       1,048,576\n","     BatchNorm2d-182         [-1, 1024, 32, 32]           2,048\n","            ReLU-183         [-1, 1024, 32, 32]               0\n","          Conv2d-184         [-1, 1024, 32, 32]         294,912\n","     BatchNorm2d-185         [-1, 1024, 32, 32]           2,048\n","            ReLU-186         [-1, 1024, 32, 32]               0\n","          Conv2d-187         [-1, 1024, 32, 32]       1,048,576\n","     BatchNorm2d-188         [-1, 1024, 32, 32]           2,048\n","            ReLU-189         [-1, 1024, 32, 32]               0\n","      Bottleneck-190         [-1, 1024, 32, 32]               0\n","          Conv2d-191         [-1, 1024, 32, 32]       1,048,576\n","     BatchNorm2d-192         [-1, 1024, 32, 32]           2,048\n","            ReLU-193         [-1, 1024, 32, 32]               0\n","          Conv2d-194         [-1, 1024, 32, 32]         294,912\n","     BatchNorm2d-195         [-1, 1024, 32, 32]           2,048\n","            ReLU-196         [-1, 1024, 32, 32]               0\n","          Conv2d-197         [-1, 1024, 32, 32]       1,048,576\n","     BatchNorm2d-198         [-1, 1024, 32, 32]           2,048\n","            ReLU-199         [-1, 1024, 32, 32]               0\n","      Bottleneck-200         [-1, 1024, 32, 32]               0\n","          Conv2d-201         [-1, 1024, 32, 32]       1,048,576\n","     BatchNorm2d-202         [-1, 1024, 32, 32]           2,048\n","            ReLU-203         [-1, 1024, 32, 32]               0\n","          Conv2d-204         [-1, 1024, 32, 32]         294,912\n","     BatchNorm2d-205         [-1, 1024, 32, 32]           2,048\n","            ReLU-206         [-1, 1024, 32, 32]               0\n","          Conv2d-207         [-1, 1024, 32, 32]       1,048,576\n","     BatchNorm2d-208         [-1, 1024, 32, 32]           2,048\n","            ReLU-209         [-1, 1024, 32, 32]               0\n","      Bottleneck-210         [-1, 1024, 32, 32]               0\n","          Conv2d-211         [-1, 1024, 32, 32]       1,048,576\n","     BatchNorm2d-212         [-1, 1024, 32, 32]           2,048\n","            ReLU-213         [-1, 1024, 32, 32]               0\n","          Conv2d-214         [-1, 1024, 32, 32]         294,912\n","     BatchNorm2d-215         [-1, 1024, 32, 32]           2,048\n","            ReLU-216         [-1, 1024, 32, 32]               0\n","          Conv2d-217         [-1, 1024, 32, 32]       1,048,576\n","     BatchNorm2d-218         [-1, 1024, 32, 32]           2,048\n","            ReLU-219         [-1, 1024, 32, 32]               0\n","      Bottleneck-220         [-1, 1024, 32, 32]               0\n","          Conv2d-221         [-1, 1024, 32, 32]       1,048,576\n","     BatchNorm2d-222         [-1, 1024, 32, 32]           2,048\n","            ReLU-223         [-1, 1024, 32, 32]               0\n","          Conv2d-224         [-1, 1024, 32, 32]         294,912\n","     BatchNorm2d-225         [-1, 1024, 32, 32]           2,048\n","            ReLU-226         [-1, 1024, 32, 32]               0\n","          Conv2d-227         [-1, 1024, 32, 32]       1,048,576\n","     BatchNorm2d-228         [-1, 1024, 32, 32]           2,048\n","            ReLU-229         [-1, 1024, 32, 32]               0\n","      Bottleneck-230         [-1, 1024, 32, 32]               0\n","          Conv2d-231         [-1, 1024, 32, 32]       1,048,576\n","     BatchNorm2d-232         [-1, 1024, 32, 32]           2,048\n","            ReLU-233         [-1, 1024, 32, 32]               0\n","          Conv2d-234         [-1, 1024, 32, 32]         294,912\n","     BatchNorm2d-235         [-1, 1024, 32, 32]           2,048\n","            ReLU-236         [-1, 1024, 32, 32]               0\n","          Conv2d-237         [-1, 1024, 32, 32]       1,048,576\n","     BatchNorm2d-238         [-1, 1024, 32, 32]           2,048\n","            ReLU-239         [-1, 1024, 32, 32]               0\n","      Bottleneck-240         [-1, 1024, 32, 32]               0\n","          Conv2d-241         [-1, 1024, 32, 32]       1,048,576\n","     BatchNorm2d-242         [-1, 1024, 32, 32]           2,048\n","            ReLU-243         [-1, 1024, 32, 32]               0\n","          Conv2d-244         [-1, 1024, 32, 32]         294,912\n","     BatchNorm2d-245         [-1, 1024, 32, 32]           2,048\n","            ReLU-246         [-1, 1024, 32, 32]               0\n","          Conv2d-247         [-1, 1024, 32, 32]       1,048,576\n","     BatchNorm2d-248         [-1, 1024, 32, 32]           2,048\n","            ReLU-249         [-1, 1024, 32, 32]               0\n","      Bottleneck-250         [-1, 1024, 32, 32]               0\n","          Conv2d-251         [-1, 1024, 32, 32]       1,048,576\n","     BatchNorm2d-252         [-1, 1024, 32, 32]           2,048\n","            ReLU-253         [-1, 1024, 32, 32]               0\n","          Conv2d-254         [-1, 1024, 32, 32]         294,912\n","     BatchNorm2d-255         [-1, 1024, 32, 32]           2,048\n","            ReLU-256         [-1, 1024, 32, 32]               0\n","          Conv2d-257         [-1, 1024, 32, 32]       1,048,576\n","     BatchNorm2d-258         [-1, 1024, 32, 32]           2,048\n","            ReLU-259         [-1, 1024, 32, 32]               0\n","      Bottleneck-260         [-1, 1024, 32, 32]               0\n","          Conv2d-261         [-1, 1024, 32, 32]       1,048,576\n","     BatchNorm2d-262         [-1, 1024, 32, 32]           2,048\n","            ReLU-263         [-1, 1024, 32, 32]               0\n","          Conv2d-264         [-1, 1024, 32, 32]         294,912\n","     BatchNorm2d-265         [-1, 1024, 32, 32]           2,048\n","            ReLU-266         [-1, 1024, 32, 32]               0\n","          Conv2d-267         [-1, 1024, 32, 32]       1,048,576\n","     BatchNorm2d-268         [-1, 1024, 32, 32]           2,048\n","            ReLU-269         [-1, 1024, 32, 32]               0\n","      Bottleneck-270         [-1, 1024, 32, 32]               0\n","          Conv2d-271         [-1, 1024, 32, 32]       1,048,576\n","     BatchNorm2d-272         [-1, 1024, 32, 32]           2,048\n","            ReLU-273         [-1, 1024, 32, 32]               0\n","          Conv2d-274         [-1, 1024, 32, 32]         294,912\n","     BatchNorm2d-275         [-1, 1024, 32, 32]           2,048\n","            ReLU-276         [-1, 1024, 32, 32]               0\n","          Conv2d-277         [-1, 1024, 32, 32]       1,048,576\n","     BatchNorm2d-278         [-1, 1024, 32, 32]           2,048\n","            ReLU-279         [-1, 1024, 32, 32]               0\n","      Bottleneck-280         [-1, 1024, 32, 32]               0\n","          Conv2d-281         [-1, 1024, 32, 32]       1,048,576\n","     BatchNorm2d-282         [-1, 1024, 32, 32]           2,048\n","            ReLU-283         [-1, 1024, 32, 32]               0\n","          Conv2d-284         [-1, 1024, 32, 32]         294,912\n","     BatchNorm2d-285         [-1, 1024, 32, 32]           2,048\n","            ReLU-286         [-1, 1024, 32, 32]               0\n","          Conv2d-287         [-1, 1024, 32, 32]       1,048,576\n","     BatchNorm2d-288         [-1, 1024, 32, 32]           2,048\n","            ReLU-289         [-1, 1024, 32, 32]               0\n","      Bottleneck-290         [-1, 1024, 32, 32]               0\n","          Conv2d-291         [-1, 1024, 32, 32]       1,048,576\n","     BatchNorm2d-292         [-1, 1024, 32, 32]           2,048\n","            ReLU-293         [-1, 1024, 32, 32]               0\n","          Conv2d-294         [-1, 1024, 32, 32]         294,912\n","     BatchNorm2d-295         [-1, 1024, 32, 32]           2,048\n","            ReLU-296         [-1, 1024, 32, 32]               0\n","          Conv2d-297         [-1, 1024, 32, 32]       1,048,576\n","     BatchNorm2d-298         [-1, 1024, 32, 32]           2,048\n","            ReLU-299         [-1, 1024, 32, 32]               0\n","      Bottleneck-300         [-1, 1024, 32, 32]               0\n","          Conv2d-301         [-1, 1024, 32, 32]       1,048,576\n","     BatchNorm2d-302         [-1, 1024, 32, 32]           2,048\n","            ReLU-303         [-1, 1024, 32, 32]               0\n","          Conv2d-304         [-1, 1024, 32, 32]         294,912\n","     BatchNorm2d-305         [-1, 1024, 32, 32]           2,048\n","            ReLU-306         [-1, 1024, 32, 32]               0\n","          Conv2d-307         [-1, 1024, 32, 32]       1,048,576\n","     BatchNorm2d-308         [-1, 1024, 32, 32]           2,048\n","            ReLU-309         [-1, 1024, 32, 32]               0\n","      Bottleneck-310         [-1, 1024, 32, 32]               0\n","          Conv2d-311         [-1, 2048, 32, 32]       2,097,152\n","     BatchNorm2d-312         [-1, 2048, 32, 32]           4,096\n","            ReLU-313         [-1, 2048, 32, 32]               0\n","          Conv2d-314         [-1, 2048, 16, 16]       1,179,648\n","     BatchNorm2d-315         [-1, 2048, 16, 16]           4,096\n","            ReLU-316         [-1, 2048, 16, 16]               0\n","          Conv2d-317         [-1, 2048, 16, 16]       4,194,304\n","     BatchNorm2d-318         [-1, 2048, 16, 16]           4,096\n","          Conv2d-319         [-1, 2048, 16, 16]       2,097,152\n","     BatchNorm2d-320         [-1, 2048, 16, 16]           4,096\n","            ReLU-321         [-1, 2048, 16, 16]               0\n","      Bottleneck-322         [-1, 2048, 16, 16]               0\n","          Conv2d-323         [-1, 2048, 16, 16]       4,194,304\n","     BatchNorm2d-324         [-1, 2048, 16, 16]           4,096\n","            ReLU-325         [-1, 2048, 16, 16]               0\n","          Conv2d-326         [-1, 2048, 16, 16]       1,179,648\n","     BatchNorm2d-327         [-1, 2048, 16, 16]           4,096\n","            ReLU-328         [-1, 2048, 16, 16]               0\n","          Conv2d-329         [-1, 2048, 16, 16]       4,194,304\n","     BatchNorm2d-330         [-1, 2048, 16, 16]           4,096\n","            ReLU-331         [-1, 2048, 16, 16]               0\n","      Bottleneck-332         [-1, 2048, 16, 16]               0\n","          Conv2d-333         [-1, 2048, 16, 16]       4,194,304\n","     BatchNorm2d-334         [-1, 2048, 16, 16]           4,096\n","            ReLU-335         [-1, 2048, 16, 16]               0\n","          Conv2d-336         [-1, 2048, 16, 16]       1,179,648\n","     BatchNorm2d-337         [-1, 2048, 16, 16]           4,096\n","            ReLU-338         [-1, 2048, 16, 16]               0\n","          Conv2d-339         [-1, 2048, 16, 16]       4,194,304\n","     BatchNorm2d-340         [-1, 2048, 16, 16]           4,096\n","            ReLU-341         [-1, 2048, 16, 16]               0\n","      Bottleneck-342         [-1, 2048, 16, 16]               0\n","          Conv2d-343        [-1, 256, 128, 128]         589,824\n","          Conv2d-344          [-1, 256, 64, 64]       1,179,648\n","          Conv2d-345          [-1, 256, 32, 32]       2,359,296\n","          Conv2d-346          [-1, 256, 16, 16]       4,718,592\n","            ReLU-347          [-1, 256, 16, 16]               0\n","          Conv2d-348          [-1, 256, 16, 16]         590,080\n","            ReLU-349          [-1, 256, 16, 16]               0\n","          Conv2d-350          [-1, 256, 16, 16]         590,080\n","ResidualConvUnit-351          [-1, 256, 16, 16]               0\n","FeatureFusionBlock-352          [-1, 256, 32, 32]               0\n","            ReLU-353          [-1, 256, 32, 32]               0\n","          Conv2d-354          [-1, 256, 32, 32]         590,080\n","            ReLU-355          [-1, 256, 32, 32]               0\n","          Conv2d-356          [-1, 256, 32, 32]         590,080\n","ResidualConvUnit-357          [-1, 256, 32, 32]               0\n","            ReLU-358          [-1, 256, 32, 32]               0\n","          Conv2d-359          [-1, 256, 32, 32]         590,080\n","            ReLU-360          [-1, 256, 32, 32]               0\n","          Conv2d-361          [-1, 256, 32, 32]         590,080\n","ResidualConvUnit-362          [-1, 256, 32, 32]               0\n","FeatureFusionBlock-363          [-1, 256, 64, 64]               0\n","            ReLU-364          [-1, 256, 64, 64]               0\n","          Conv2d-365          [-1, 256, 64, 64]         590,080\n","            ReLU-366          [-1, 256, 64, 64]               0\n","          Conv2d-367          [-1, 256, 64, 64]         590,080\n","ResidualConvUnit-368          [-1, 256, 64, 64]               0\n","            ReLU-369          [-1, 256, 64, 64]               0\n","          Conv2d-370          [-1, 256, 64, 64]         590,080\n","            ReLU-371          [-1, 256, 64, 64]               0\n","          Conv2d-372          [-1, 256, 64, 64]         590,080\n","ResidualConvUnit-373          [-1, 256, 64, 64]               0\n","FeatureFusionBlock-374        [-1, 256, 128, 128]               0\n","            ReLU-375        [-1, 256, 128, 128]               0\n","          Conv2d-376        [-1, 256, 128, 128]         590,080\n","            ReLU-377        [-1, 256, 128, 128]               0\n","          Conv2d-378        [-1, 256, 128, 128]         590,080\n","ResidualConvUnit-379        [-1, 256, 128, 128]               0\n","            ReLU-380        [-1, 256, 128, 128]               0\n","          Conv2d-381        [-1, 256, 128, 128]         590,080\n","            ReLU-382        [-1, 256, 128, 128]               0\n","          Conv2d-383        [-1, 256, 128, 128]         590,080\n","ResidualConvUnit-384        [-1, 256, 128, 128]               0\n","FeatureFusionBlock-385        [-1, 256, 256, 256]               0\n","          Conv2d-386        [-1, 128, 256, 256]         295,040\n","     Interpolate-387        [-1, 128, 512, 512]               0\n","          Conv2d-388         [-1, 32, 512, 512]          36,896\n","            ReLU-389         [-1, 32, 512, 512]               0\n","          Conv2d-390          [-1, 1, 512, 512]              33\n","            ReLU-391          [-1, 1, 512, 512]               0\n","          Conv2d-392        [-1, 256, 256, 256]           6,912\n","     BatchNorm2d-393        [-1, 256, 256, 256]             512\n","            ReLU-394        [-1, 256, 256, 256]               0\n","          Conv2d-395        [-1, 256, 128, 128]         589,824\n","     BatchNorm2d-396        [-1, 256, 128, 128]             512\n","            ReLU-397        [-1, 256, 128, 128]               0\n","          Conv2d-398          [-1, 256, 64, 64]         589,824\n","     BatchNorm2d-399          [-1, 256, 64, 64]             512\n","            ReLU-400          [-1, 256, 64, 64]               0\n","          Conv2d-401          [-1, 512, 32, 32]       1,179,648\n","     BatchNorm2d-402          [-1, 512, 32, 32]           1,024\n","            ReLU-403          [-1, 512, 32, 32]               0\n","          Conv2d-404         [-1, 1024, 16, 16]       4,718,592\n","     BatchNorm2d-405         [-1, 1024, 16, 16]           2,048\n","            ReLU-406         [-1, 1024, 16, 16]               0\n","          Conv2d-407         [-1, 1024, 16, 16]       2,097,152\n","     BatchNorm2d-408         [-1, 1024, 16, 16]           2,048\n","            ReLU-409         [-1, 1024, 16, 16]               0\n","          Conv2d-410           [-1, 27, 16, 16]          27,675\n","       YOLOLayer-411         [-1, 3, 16, 16, 9]               0\n","     Interpolate-412         [-1, 1024, 32, 32]               0\n","          Conv2d-413          [-1, 256, 32, 32]         262,144\n","     BatchNorm2d-414          [-1, 256, 32, 32]             512\n","            ReLU-415          [-1, 256, 32, 32]               0\n","          Conv2d-416          [-1, 512, 32, 32]         524,288\n","     BatchNorm2d-417          [-1, 512, 32, 32]           1,024\n","            ReLU-418          [-1, 512, 32, 32]               0\n","          Conv2d-419          [-1, 256, 32, 32]         196,608\n","     BatchNorm2d-420          [-1, 256, 32, 32]             512\n","            ReLU-421          [-1, 256, 32, 32]               0\n","          Conv2d-422          [-1, 512, 32, 32]       1,179,648\n","     BatchNorm2d-423          [-1, 512, 32, 32]           1,024\n","            ReLU-424          [-1, 512, 32, 32]               0\n","          Conv2d-425          [-1, 256, 32, 32]         131,072\n","     BatchNorm2d-426          [-1, 256, 32, 32]             512\n","            ReLU-427          [-1, 256, 32, 32]               0\n","          Conv2d-428          [-1, 512, 32, 32]       1,179,648\n","     BatchNorm2d-429          [-1, 512, 32, 32]           1,024\n","            ReLU-430          [-1, 512, 32, 32]               0\n","          Conv2d-431          [-1, 256, 32, 32]         131,072\n","     BatchNorm2d-432          [-1, 256, 32, 32]             512\n","            ReLU-433          [-1, 256, 32, 32]               0\n","          Conv2d-434          [-1, 512, 32, 32]       1,179,648\n","     BatchNorm2d-435          [-1, 512, 32, 32]           1,024\n","            ReLU-436          [-1, 512, 32, 32]               0\n","          Conv2d-437           [-1, 27, 32, 32]          13,851\n","       YOLOLayer-438         [-1, 3, 32, 32, 9]               0\n","          Conv2d-439          [-1, 256, 64, 64]         131,072\n","     BatchNorm2d-440          [-1, 256, 64, 64]             512\n","            ReLU-441          [-1, 256, 64, 64]               0\n","     Interpolate-442          [-1, 512, 64, 64]               0\n","          Conv2d-443          [-1, 128, 64, 64]          65,536\n","     BatchNorm2d-444          [-1, 128, 64, 64]             256\n","            ReLU-445          [-1, 128, 64, 64]               0\n","          Conv2d-446          [-1, 128, 64, 64]          49,152\n","     BatchNorm2d-447          [-1, 128, 64, 64]             256\n","            ReLU-448          [-1, 128, 64, 64]               0\n","          Conv2d-449          [-1, 256, 64, 64]         294,912\n","     BatchNorm2d-450          [-1, 256, 64, 64]             512\n","            ReLU-451          [-1, 256, 64, 64]               0\n","          Conv2d-452          [-1, 128, 64, 64]          32,768\n","     BatchNorm2d-453          [-1, 128, 64, 64]             256\n","            ReLU-454          [-1, 128, 64, 64]               0\n","          Conv2d-455          [-1, 256, 64, 64]         294,912\n","     BatchNorm2d-456          [-1, 256, 64, 64]             512\n","            ReLU-457          [-1, 256, 64, 64]               0\n","          Conv2d-458          [-1, 128, 64, 64]          32,768\n","     BatchNorm2d-459          [-1, 128, 64, 64]             256\n","            ReLU-460          [-1, 128, 64, 64]               0\n","          Conv2d-461          [-1, 256, 64, 64]         294,912\n","     BatchNorm2d-462          [-1, 256, 64, 64]             512\n","            ReLU-463          [-1, 256, 64, 64]               0\n","          Conv2d-464           [-1, 27, 64, 64]           6,939\n","       YOLOLayer-465         [-1, 3, 64, 64, 9]               0\n","================================================================\n","Total params: 119,409,234\n","Trainable params: 15,226,449\n","Non-trainable params: 104,182,785\n","----------------------------------------------------------------\n","Input size (MB): 3.00\n","Forward/backward pass size (MB): 5893.21\n","Params size (MB): 455.51\n","Estimated Total Size (MB): 6351.72\n","----------------------------------------------------------------\n","Image sizes 512 - 512 train, 512 test\n","Using 4 dataloader workers\n","Starting training for 300 epochs...\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","  0% 0/346 [00:00<?, ?it/s]/usr/local/lib/python3.6/dist-packages/torch/cuda/memory.py:346: FutureWarning: torch.cuda.memory_cached has been renamed to torch.cuda.memory_reserved\n","  FutureWarning)\n","   160/299     5.09G      4.45      1.14     0.594      6.18        60       512: 100% 346/346 [04:45<00:00,  1.21it/s]\n","               Class    Images   Targets         P         R   mAP@0.5        F1:   0% 0/87 [00:00<?, ?it/s]/content/drive/My Drive/computer_vision/capstone_project/yolo_v3/utils/utils.py:544: UserWarning: This overload of nonzero is deprecated:\n","\tnonzero()\n","Consider using one of the following signatures instead:\n","\tnonzero(*, bool as_tuple) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:882.)\n","  i, j = (x[:, 5:] > conf_thres).nonzero().t()\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 87/87 [00:56<00:00,  1.54it/s]\n","                 all       692  3.06e+03     0.248     0.585     0.339     0.348\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","  0% 0/346 [00:00<?, ?it/s]/usr/local/lib/python3.6/dist-packages/torch/cuda/memory.py:346: FutureWarning: torch.cuda.memory_cached has been renamed to torch.cuda.memory_reserved\n","  FutureWarning)\n","   161/299     5.09G      4.45      1.12      0.56      6.13        50       512: 100% 346/346 [04:45<00:00,  1.21it/s]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 87/87 [00:54<00:00,  1.60it/s]\n","                 all       692  3.06e+03     0.265     0.589     0.363     0.365\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","   162/299     5.09G      4.54      1.12      0.65      6.31        31       512: 100% 346/346 [04:45<00:00,  1.21it/s]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 87/87 [00:54<00:00,  1.59it/s]\n","                 all       692  3.06e+03     0.253     0.586     0.336     0.352\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","   163/299     5.09G      4.53      1.12      0.67      6.32        25       512: 100% 346/346 [04:45<00:00,  1.21it/s]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 87/87 [00:54<00:00,  1.59it/s]\n","                 all       692  3.06e+03     0.259     0.577     0.322     0.357\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","   164/299     5.09G      4.52       1.1     0.651      6.27        42       512: 100% 346/346 [04:46<00:00,  1.21it/s]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 87/87 [00:54<00:00,  1.59it/s]\n","                 all       692  3.06e+03     0.262     0.576      0.35     0.359\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","   165/299     5.09G      4.51      1.14     0.641      6.29        40       512: 100% 346/346 [04:46<00:00,  1.21it/s]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 87/87 [00:54<00:00,  1.59it/s]\n","                 all       692  3.06e+03     0.255     0.574     0.351     0.352\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","   166/299     5.09G      4.51      1.12      0.65      6.29        34       512: 100% 346/346 [04:45<00:00,  1.21it/s]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 87/87 [00:54<00:00,  1.59it/s]\n","                 all       692  3.06e+03     0.242      0.57     0.318     0.339\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","   167/299     5.09G      4.48      1.12     0.642      6.24        59       512: 100% 346/346 [04:45<00:00,  1.21it/s]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 87/87 [00:54<00:00,  1.59it/s]\n","                 all       692  3.06e+03     0.259     0.576     0.363     0.357\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","   168/299     5.09G      4.47      1.12     0.603       6.2        29       512: 100% 346/346 [04:46<00:00,  1.21it/s]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 87/87 [00:54<00:00,  1.59it/s]\n","                 all       692  3.06e+03     0.268     0.591     0.355     0.367\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","   169/299     5.09G      4.48      1.11     0.605      6.19        39       512: 100% 346/346 [04:45<00:00,  1.21it/s]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 87/87 [00:54<00:00,  1.59it/s]\n","                 all       692  3.06e+03     0.266      0.57     0.331     0.361\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","   170/299     5.09G      4.43      1.11     0.557       6.1        31       512: 100% 346/346 [04:46<00:00,  1.21it/s]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 87/87 [00:54<00:00,  1.59it/s]\n","                 all       692  3.06e+03     0.262     0.594     0.364     0.363\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","   171/299     5.09G      4.44      1.12      0.56      6.12        51       512: 100% 346/346 [04:46<00:00,  1.21it/s]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 87/87 [00:54<00:00,  1.59it/s]\n","                 all       692  3.06e+03     0.259     0.593     0.348      0.36\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","   172/299     5.09G      4.44      1.11      0.56      6.12        31       512: 100% 346/346 [04:46<00:00,  1.21it/s]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 87/87 [00:54<00:00,  1.60it/s]\n","                 all       692  3.06e+03     0.249     0.588     0.344     0.349\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","   173/299     5.09G      4.42      1.09     0.547      6.06        57       512: 100% 346/346 [04:45<00:00,  1.21it/s]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 87/87 [00:54<00:00,  1.59it/s]\n","                 all       692  3.06e+03     0.261     0.591     0.367     0.362\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","   174/299     5.09G      4.41      1.08     0.568      6.05        42       512: 100% 346/346 [04:46<00:00,  1.21it/s]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 87/87 [00:54<00:00,  1.59it/s]\n","                 all       692  3.06e+03     0.256     0.589      0.36     0.356\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","   175/299     5.09G      4.42      1.11     0.562      6.09        41       512: 100% 346/346 [04:45<00:00,  1.21it/s]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 87/87 [00:54<00:00,  1.59it/s]\n","                 all       692  3.06e+03     0.263      0.59      0.36     0.363\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","   176/299     5.09G      4.39       1.1      0.54      6.03        66       512: 100% 346/346 [04:46<00:00,  1.21it/s]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 87/87 [00:54<00:00,  1.59it/s]\n","                 all       692  3.06e+03     0.254     0.588     0.347     0.354\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","   177/299     5.09G      4.37      1.11     0.539      6.01        36       512: 100% 346/346 [04:46<00:00,  1.21it/s]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 87/87 [00:54<00:00,  1.59it/s]\n","                 all       692  3.06e+03     0.247     0.596     0.353     0.349\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","   178/299     5.09G      4.37      1.09     0.516      5.97        58       512: 100% 346/346 [04:46<00:00,  1.21it/s]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 87/87 [00:54<00:00,  1.59it/s]\n","                 all       692  3.06e+03     0.243      0.59     0.364     0.344\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","   179/299     5.09G      4.36      1.08      0.53      5.97        52       512: 100% 346/346 [04:46<00:00,  1.21it/s]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 87/87 [00:54<00:00,  1.60it/s]\n","                 all       692  3.06e+03     0.254      0.59      0.35     0.354\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","   180/299     5.09G      4.37      1.07     0.548      5.98        36       512: 100% 346/346 [04:46<00:00,  1.21it/s]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 87/87 [00:54<00:00,  1.59it/s]\n","                 all       692  3.06e+03     0.266     0.586     0.355     0.365\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","   181/299     5.09G      4.35      1.08     0.542      5.98        23       512: 100% 346/346 [04:46<00:00,  1.21it/s]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 87/87 [00:54<00:00,  1.59it/s]\n","                 all       692  3.06e+03     0.264     0.589     0.359     0.364\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","   182/299     5.09G      4.35      1.07     0.498      5.91        38       512: 100% 346/346 [04:46<00:00,  1.21it/s]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 87/87 [00:54<00:00,  1.59it/s]\n","                 all       692  3.06e+03     0.248     0.585     0.343     0.347\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","   183/299     5.09G      4.32      1.09     0.502      5.91        60       512: 100% 346/346 [04:46<00:00,  1.21it/s]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 87/87 [00:54<00:00,  1.59it/s]\n","                 all       692  3.06e+03     0.259     0.598     0.351     0.362\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","   184/299     5.09G      4.33      1.08     0.509      5.92        39       512: 100% 346/346 [04:46<00:00,  1.21it/s]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 87/87 [00:54<00:00,  1.60it/s]\n","                 all       692  3.06e+03     0.259     0.595     0.338      0.36\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","   185/299     5.09G      4.29      1.09     0.515       5.9        46       512: 100% 346/346 [04:45<00:00,  1.21it/s]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 87/87 [00:54<00:00,  1.59it/s]\n","                 all       692  3.06e+03     0.259     0.592     0.364     0.359\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","   186/299     5.09G       4.3      1.07     0.484      5.86        58       512: 100% 346/346 [04:45<00:00,  1.21it/s]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 87/87 [00:54<00:00,  1.60it/s]\n","                 all       692  3.06e+03     0.244     0.592     0.347     0.345\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","   187/299     5.09G       4.3      1.08     0.488      5.87        55       512: 100% 346/346 [04:45<00:00,  1.21it/s]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 87/87 [00:54<00:00,  1.60it/s]\n","                 all       692  3.06e+03     0.257     0.594     0.354     0.357\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","   188/299     5.09G      4.29      1.07     0.506      5.87        47       512: 100% 346/346 [04:45<00:00,  1.21it/s]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 87/87 [00:54<00:00,  1.60it/s]\n","                 all       692  3.06e+03     0.252     0.606     0.353     0.355\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","   189/299     5.09G      4.27      1.07     0.475      5.81        51       512: 100% 346/346 [04:45<00:00,  1.21it/s]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 87/87 [00:54<00:00,  1.60it/s]\n","                 all       692  3.06e+03     0.253      0.59     0.337     0.353\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","   190/299     5.09G      4.28      1.07     0.477      5.82        38       512: 100% 346/346 [04:45<00:00,  1.21it/s]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 87/87 [00:54<00:00,  1.60it/s]\n","                 all       692  3.06e+03     0.246     0.593     0.329     0.347\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","   191/299     5.09G      4.36      1.15     0.602      6.11        60       512:   1% 3/346 [00:03<08:36,  1.50s/it]"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"yN76URKIb6NO","colab":{"base_uri":"https://localhost:8080/"},"outputId":"e93af291-5841-4d97-d11a-16f627490390"},"source":["!python train.py --data data/customdata/custom.data --batch 8  --cache --cfg cfg/yolov3-custom.cfg --epochs 300 --weights 'weights/best.pt'  --img-size=512 --midasnet_freeze='True'"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Namespace(accumulate=4, adam=False, batch_size=8, bucket='', cache_images=True, cfg='cfg/yolov3-custom.cfg', data='data/customdata/custom.data', device='', epochs=300, evolve=False, img_size=[512], init_train='False', midas_weights='', midasnet_freeze='True', multi_scale=False, name='', nosave=False, notest=False, rect=False, resume=False, single_cls=False, weights='weights/best.pt', yolo_weights='')\n","Using CUDA device0 _CudaDeviceProperties(name='Tesla P100-PCIE-16GB', total_memory=16280MB)\n","\n","2020-11-14 20:26:13.979827: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n","Run 'tensorboard --logdir=runs' to view tensorboard at http://localhost:6006/\n","cfg - cfg/yolov3-custom.cfg\n","data - data/customdata/custom.data\n","epochs - 300\n","batch_size - 8\n","accumulate - 4\n","yolo weights - \n","midas weights - \n","imgsz_min- 512, imgsz_max- 512, imgsz_test- 512\n","opt.rect - False\n","train_path - data/customdata/train.txt\n","test_path - data/customdata/test.txt\n","init_train - False\n","weights - weights/best.pt\n","midasnet_freeze - True\n","Using cache found in /root/.cache/torch/hub/facebookresearch_WSL-Images_master\n","Caching labels (2623 found, 114 missing, 30 empty, 0 duplicate, for 2767 images): 100% 2767/2767 [00:03<00:00, 830.90it/s]\n","Caching images (1.5GB): 100% 2767/2767 [01:26<00:00, 32.06it/s]\n","Caching labels (657 found, 27 missing, 8 empty, 0 duplicate, for 692 images): 100% 692/692 [00:00<00:00, 763.68it/s]\n","Caching images (0.3GB): 100% 692/692 [00:23<00:00, 29.32it/s]\n","Freezing the midasnet\n","YMP Model Summary\n","----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","            Conv2d-1         [-1, 64, 256, 256]           9,408\n","       BatchNorm2d-2         [-1, 64, 256, 256]             128\n","              ReLU-3         [-1, 64, 256, 256]               0\n","         MaxPool2d-4         [-1, 64, 128, 128]               0\n","            Conv2d-5        [-1, 256, 128, 128]          16,384\n","       BatchNorm2d-6        [-1, 256, 128, 128]             512\n","              ReLU-7        [-1, 256, 128, 128]               0\n","            Conv2d-8        [-1, 256, 128, 128]          18,432\n","       BatchNorm2d-9        [-1, 256, 128, 128]             512\n","             ReLU-10        [-1, 256, 128, 128]               0\n","           Conv2d-11        [-1, 256, 128, 128]          65,536\n","      BatchNorm2d-12        [-1, 256, 128, 128]             512\n","           Conv2d-13        [-1, 256, 128, 128]          16,384\n","      BatchNorm2d-14        [-1, 256, 128, 128]             512\n","             ReLU-15        [-1, 256, 128, 128]               0\n","       Bottleneck-16        [-1, 256, 128, 128]               0\n","           Conv2d-17        [-1, 256, 128, 128]          65,536\n","      BatchNorm2d-18        [-1, 256, 128, 128]             512\n","             ReLU-19        [-1, 256, 128, 128]               0\n","           Conv2d-20        [-1, 256, 128, 128]          18,432\n","      BatchNorm2d-21        [-1, 256, 128, 128]             512\n","             ReLU-22        [-1, 256, 128, 128]               0\n","           Conv2d-23        [-1, 256, 128, 128]          65,536\n","      BatchNorm2d-24        [-1, 256, 128, 128]             512\n","             ReLU-25        [-1, 256, 128, 128]               0\n","       Bottleneck-26        [-1, 256, 128, 128]               0\n","           Conv2d-27        [-1, 256, 128, 128]          65,536\n","      BatchNorm2d-28        [-1, 256, 128, 128]             512\n","             ReLU-29        [-1, 256, 128, 128]               0\n","           Conv2d-30        [-1, 256, 128, 128]          18,432\n","      BatchNorm2d-31        [-1, 256, 128, 128]             512\n","             ReLU-32        [-1, 256, 128, 128]               0\n","           Conv2d-33        [-1, 256, 128, 128]          65,536\n","      BatchNorm2d-34        [-1, 256, 128, 128]             512\n","             ReLU-35        [-1, 256, 128, 128]               0\n","       Bottleneck-36        [-1, 256, 128, 128]               0\n","           Conv2d-37        [-1, 512, 128, 128]         131,072\n","      BatchNorm2d-38        [-1, 512, 128, 128]           1,024\n","             ReLU-39        [-1, 512, 128, 128]               0\n","           Conv2d-40          [-1, 512, 64, 64]          73,728\n","      BatchNorm2d-41          [-1, 512, 64, 64]           1,024\n","             ReLU-42          [-1, 512, 64, 64]               0\n","           Conv2d-43          [-1, 512, 64, 64]         262,144\n","      BatchNorm2d-44          [-1, 512, 64, 64]           1,024\n","           Conv2d-45          [-1, 512, 64, 64]         131,072\n","      BatchNorm2d-46          [-1, 512, 64, 64]           1,024\n","             ReLU-47          [-1, 512, 64, 64]               0\n","       Bottleneck-48          [-1, 512, 64, 64]               0\n","           Conv2d-49          [-1, 512, 64, 64]         262,144\n","      BatchNorm2d-50          [-1, 512, 64, 64]           1,024\n","             ReLU-51          [-1, 512, 64, 64]               0\n","           Conv2d-52          [-1, 512, 64, 64]          73,728\n","      BatchNorm2d-53          [-1, 512, 64, 64]           1,024\n","             ReLU-54          [-1, 512, 64, 64]               0\n","           Conv2d-55          [-1, 512, 64, 64]         262,144\n","      BatchNorm2d-56          [-1, 512, 64, 64]           1,024\n","             ReLU-57          [-1, 512, 64, 64]               0\n","       Bottleneck-58          [-1, 512, 64, 64]               0\n","           Conv2d-59          [-1, 512, 64, 64]         262,144\n","      BatchNorm2d-60          [-1, 512, 64, 64]           1,024\n","             ReLU-61          [-1, 512, 64, 64]               0\n","           Conv2d-62          [-1, 512, 64, 64]          73,728\n","      BatchNorm2d-63          [-1, 512, 64, 64]           1,024\n","             ReLU-64          [-1, 512, 64, 64]               0\n","           Conv2d-65          [-1, 512, 64, 64]         262,144\n","      BatchNorm2d-66          [-1, 512, 64, 64]           1,024\n","             ReLU-67          [-1, 512, 64, 64]               0\n","       Bottleneck-68          [-1, 512, 64, 64]               0\n","           Conv2d-69          [-1, 512, 64, 64]         262,144\n","      BatchNorm2d-70          [-1, 512, 64, 64]           1,024\n","             ReLU-71          [-1, 512, 64, 64]               0\n","           Conv2d-72          [-1, 512, 64, 64]          73,728\n","      BatchNorm2d-73          [-1, 512, 64, 64]           1,024\n","             ReLU-74          [-1, 512, 64, 64]               0\n","           Conv2d-75          [-1, 512, 64, 64]         262,144\n","      BatchNorm2d-76          [-1, 512, 64, 64]           1,024\n","             ReLU-77          [-1, 512, 64, 64]               0\n","       Bottleneck-78          [-1, 512, 64, 64]               0\n","           Conv2d-79         [-1, 1024, 64, 64]         524,288\n","      BatchNorm2d-80         [-1, 1024, 64, 64]           2,048\n","             ReLU-81         [-1, 1024, 64, 64]               0\n","           Conv2d-82         [-1, 1024, 32, 32]         294,912\n","      BatchNorm2d-83         [-1, 1024, 32, 32]           2,048\n","             ReLU-84         [-1, 1024, 32, 32]               0\n","           Conv2d-85         [-1, 1024, 32, 32]       1,048,576\n","      BatchNorm2d-86         [-1, 1024, 32, 32]           2,048\n","           Conv2d-87         [-1, 1024, 32, 32]         524,288\n","      BatchNorm2d-88         [-1, 1024, 32, 32]           2,048\n","             ReLU-89         [-1, 1024, 32, 32]               0\n","       Bottleneck-90         [-1, 1024, 32, 32]               0\n","           Conv2d-91         [-1, 1024, 32, 32]       1,048,576\n","      BatchNorm2d-92         [-1, 1024, 32, 32]           2,048\n","             ReLU-93         [-1, 1024, 32, 32]               0\n","           Conv2d-94         [-1, 1024, 32, 32]         294,912\n","      BatchNorm2d-95         [-1, 1024, 32, 32]           2,048\n","             ReLU-96         [-1, 1024, 32, 32]               0\n","           Conv2d-97         [-1, 1024, 32, 32]       1,048,576\n","      BatchNorm2d-98         [-1, 1024, 32, 32]           2,048\n","             ReLU-99         [-1, 1024, 32, 32]               0\n","      Bottleneck-100         [-1, 1024, 32, 32]               0\n","          Conv2d-101         [-1, 1024, 32, 32]       1,048,576\n","     BatchNorm2d-102         [-1, 1024, 32, 32]           2,048\n","            ReLU-103         [-1, 1024, 32, 32]               0\n","          Conv2d-104         [-1, 1024, 32, 32]         294,912\n","     BatchNorm2d-105         [-1, 1024, 32, 32]           2,048\n","            ReLU-106         [-1, 1024, 32, 32]               0\n","          Conv2d-107         [-1, 1024, 32, 32]       1,048,576\n","     BatchNorm2d-108         [-1, 1024, 32, 32]           2,048\n","            ReLU-109         [-1, 1024, 32, 32]               0\n","      Bottleneck-110         [-1, 1024, 32, 32]               0\n","          Conv2d-111         [-1, 1024, 32, 32]       1,048,576\n","     BatchNorm2d-112         [-1, 1024, 32, 32]           2,048\n","            ReLU-113         [-1, 1024, 32, 32]               0\n","          Conv2d-114         [-1, 1024, 32, 32]         294,912\n","     BatchNorm2d-115         [-1, 1024, 32, 32]           2,048\n","            ReLU-116         [-1, 1024, 32, 32]               0\n","          Conv2d-117         [-1, 1024, 32, 32]       1,048,576\n","     BatchNorm2d-118         [-1, 1024, 32, 32]           2,048\n","            ReLU-119         [-1, 1024, 32, 32]               0\n","      Bottleneck-120         [-1, 1024, 32, 32]               0\n","          Conv2d-121         [-1, 1024, 32, 32]       1,048,576\n","     BatchNorm2d-122         [-1, 1024, 32, 32]           2,048\n","            ReLU-123         [-1, 1024, 32, 32]               0\n","          Conv2d-124         [-1, 1024, 32, 32]         294,912\n","     BatchNorm2d-125         [-1, 1024, 32, 32]           2,048\n","            ReLU-126         [-1, 1024, 32, 32]               0\n","          Conv2d-127         [-1, 1024, 32, 32]       1,048,576\n","     BatchNorm2d-128         [-1, 1024, 32, 32]           2,048\n","            ReLU-129         [-1, 1024, 32, 32]               0\n","      Bottleneck-130         [-1, 1024, 32, 32]               0\n","          Conv2d-131         [-1, 1024, 32, 32]       1,048,576\n","     BatchNorm2d-132         [-1, 1024, 32, 32]           2,048\n","            ReLU-133         [-1, 1024, 32, 32]               0\n","          Conv2d-134         [-1, 1024, 32, 32]         294,912\n","     BatchNorm2d-135         [-1, 1024, 32, 32]           2,048\n","            ReLU-136         [-1, 1024, 32, 32]               0\n","          Conv2d-137         [-1, 1024, 32, 32]       1,048,576\n","     BatchNorm2d-138         [-1, 1024, 32, 32]           2,048\n","            ReLU-139         [-1, 1024, 32, 32]               0\n","      Bottleneck-140         [-1, 1024, 32, 32]               0\n","          Conv2d-141         [-1, 1024, 32, 32]       1,048,576\n","     BatchNorm2d-142         [-1, 1024, 32, 32]           2,048\n","            ReLU-143         [-1, 1024, 32, 32]               0\n","          Conv2d-144         [-1, 1024, 32, 32]         294,912\n","     BatchNorm2d-145         [-1, 1024, 32, 32]           2,048\n","            ReLU-146         [-1, 1024, 32, 32]               0\n","          Conv2d-147         [-1, 1024, 32, 32]       1,048,576\n","     BatchNorm2d-148         [-1, 1024, 32, 32]           2,048\n","            ReLU-149         [-1, 1024, 32, 32]               0\n","      Bottleneck-150         [-1, 1024, 32, 32]               0\n","          Conv2d-151         [-1, 1024, 32, 32]       1,048,576\n","     BatchNorm2d-152         [-1, 1024, 32, 32]           2,048\n","            ReLU-153         [-1, 1024, 32, 32]               0\n","          Conv2d-154         [-1, 1024, 32, 32]         294,912\n","     BatchNorm2d-155         [-1, 1024, 32, 32]           2,048\n","            ReLU-156         [-1, 1024, 32, 32]               0\n","          Conv2d-157         [-1, 1024, 32, 32]       1,048,576\n","     BatchNorm2d-158         [-1, 1024, 32, 32]           2,048\n","            ReLU-159         [-1, 1024, 32, 32]               0\n","      Bottleneck-160         [-1, 1024, 32, 32]               0\n","          Conv2d-161         [-1, 1024, 32, 32]       1,048,576\n","     BatchNorm2d-162         [-1, 1024, 32, 32]           2,048\n","            ReLU-163         [-1, 1024, 32, 32]               0\n","          Conv2d-164         [-1, 1024, 32, 32]         294,912\n","     BatchNorm2d-165         [-1, 1024, 32, 32]           2,048\n","            ReLU-166         [-1, 1024, 32, 32]               0\n","          Conv2d-167         [-1, 1024, 32, 32]       1,048,576\n","     BatchNorm2d-168         [-1, 1024, 32, 32]           2,048\n","            ReLU-169         [-1, 1024, 32, 32]               0\n","      Bottleneck-170         [-1, 1024, 32, 32]               0\n","          Conv2d-171         [-1, 1024, 32, 32]       1,048,576\n","     BatchNorm2d-172         [-1, 1024, 32, 32]           2,048\n","            ReLU-173         [-1, 1024, 32, 32]               0\n","          Conv2d-174         [-1, 1024, 32, 32]         294,912\n","     BatchNorm2d-175         [-1, 1024, 32, 32]           2,048\n","            ReLU-176         [-1, 1024, 32, 32]               0\n","          Conv2d-177         [-1, 1024, 32, 32]       1,048,576\n","     BatchNorm2d-178         [-1, 1024, 32, 32]           2,048\n","            ReLU-179         [-1, 1024, 32, 32]               0\n","      Bottleneck-180         [-1, 1024, 32, 32]               0\n","          Conv2d-181         [-1, 1024, 32, 32]       1,048,576\n","     BatchNorm2d-182         [-1, 1024, 32, 32]           2,048\n","            ReLU-183         [-1, 1024, 32, 32]               0\n","          Conv2d-184         [-1, 1024, 32, 32]         294,912\n","     BatchNorm2d-185         [-1, 1024, 32, 32]           2,048\n","            ReLU-186         [-1, 1024, 32, 32]               0\n","          Conv2d-187         [-1, 1024, 32, 32]       1,048,576\n","     BatchNorm2d-188         [-1, 1024, 32, 32]           2,048\n","            ReLU-189         [-1, 1024, 32, 32]               0\n","      Bottleneck-190         [-1, 1024, 32, 32]               0\n","          Conv2d-191         [-1, 1024, 32, 32]       1,048,576\n","     BatchNorm2d-192         [-1, 1024, 32, 32]           2,048\n","            ReLU-193         [-1, 1024, 32, 32]               0\n","          Conv2d-194         [-1, 1024, 32, 32]         294,912\n","     BatchNorm2d-195         [-1, 1024, 32, 32]           2,048\n","            ReLU-196         [-1, 1024, 32, 32]               0\n","          Conv2d-197         [-1, 1024, 32, 32]       1,048,576\n","     BatchNorm2d-198         [-1, 1024, 32, 32]           2,048\n","            ReLU-199         [-1, 1024, 32, 32]               0\n","      Bottleneck-200         [-1, 1024, 32, 32]               0\n","          Conv2d-201         [-1, 1024, 32, 32]       1,048,576\n","     BatchNorm2d-202         [-1, 1024, 32, 32]           2,048\n","            ReLU-203         [-1, 1024, 32, 32]               0\n","          Conv2d-204         [-1, 1024, 32, 32]         294,912\n","     BatchNorm2d-205         [-1, 1024, 32, 32]           2,048\n","            ReLU-206         [-1, 1024, 32, 32]               0\n","          Conv2d-207         [-1, 1024, 32, 32]       1,048,576\n","     BatchNorm2d-208         [-1, 1024, 32, 32]           2,048\n","            ReLU-209         [-1, 1024, 32, 32]               0\n","      Bottleneck-210         [-1, 1024, 32, 32]               0\n","          Conv2d-211         [-1, 1024, 32, 32]       1,048,576\n","     BatchNorm2d-212         [-1, 1024, 32, 32]           2,048\n","            ReLU-213         [-1, 1024, 32, 32]               0\n","          Conv2d-214         [-1, 1024, 32, 32]         294,912\n","     BatchNorm2d-215         [-1, 1024, 32, 32]           2,048\n","            ReLU-216         [-1, 1024, 32, 32]               0\n","          Conv2d-217         [-1, 1024, 32, 32]       1,048,576\n","     BatchNorm2d-218         [-1, 1024, 32, 32]           2,048\n","            ReLU-219         [-1, 1024, 32, 32]               0\n","      Bottleneck-220         [-1, 1024, 32, 32]               0\n","          Conv2d-221         [-1, 1024, 32, 32]       1,048,576\n","     BatchNorm2d-222         [-1, 1024, 32, 32]           2,048\n","            ReLU-223         [-1, 1024, 32, 32]               0\n","          Conv2d-224         [-1, 1024, 32, 32]         294,912\n","     BatchNorm2d-225         [-1, 1024, 32, 32]           2,048\n","            ReLU-226         [-1, 1024, 32, 32]               0\n","          Conv2d-227         [-1, 1024, 32, 32]       1,048,576\n","     BatchNorm2d-228         [-1, 1024, 32, 32]           2,048\n","            ReLU-229         [-1, 1024, 32, 32]               0\n","      Bottleneck-230         [-1, 1024, 32, 32]               0\n","          Conv2d-231         [-1, 1024, 32, 32]       1,048,576\n","     BatchNorm2d-232         [-1, 1024, 32, 32]           2,048\n","            ReLU-233         [-1, 1024, 32, 32]               0\n","          Conv2d-234         [-1, 1024, 32, 32]         294,912\n","     BatchNorm2d-235         [-1, 1024, 32, 32]           2,048\n","            ReLU-236         [-1, 1024, 32, 32]               0\n","          Conv2d-237         [-1, 1024, 32, 32]       1,048,576\n","     BatchNorm2d-238         [-1, 1024, 32, 32]           2,048\n","            ReLU-239         [-1, 1024, 32, 32]               0\n","      Bottleneck-240         [-1, 1024, 32, 32]               0\n","          Conv2d-241         [-1, 1024, 32, 32]       1,048,576\n","     BatchNorm2d-242         [-1, 1024, 32, 32]           2,048\n","            ReLU-243         [-1, 1024, 32, 32]               0\n","          Conv2d-244         [-1, 1024, 32, 32]         294,912\n","     BatchNorm2d-245         [-1, 1024, 32, 32]           2,048\n","            ReLU-246         [-1, 1024, 32, 32]               0\n","          Conv2d-247         [-1, 1024, 32, 32]       1,048,576\n","     BatchNorm2d-248         [-1, 1024, 32, 32]           2,048\n","            ReLU-249         [-1, 1024, 32, 32]               0\n","      Bottleneck-250         [-1, 1024, 32, 32]               0\n","          Conv2d-251         [-1, 1024, 32, 32]       1,048,576\n","     BatchNorm2d-252         [-1, 1024, 32, 32]           2,048\n","            ReLU-253         [-1, 1024, 32, 32]               0\n","          Conv2d-254         [-1, 1024, 32, 32]         294,912\n","     BatchNorm2d-255         [-1, 1024, 32, 32]           2,048\n","            ReLU-256         [-1, 1024, 32, 32]               0\n","          Conv2d-257         [-1, 1024, 32, 32]       1,048,576\n","     BatchNorm2d-258         [-1, 1024, 32, 32]           2,048\n","            ReLU-259         [-1, 1024, 32, 32]               0\n","      Bottleneck-260         [-1, 1024, 32, 32]               0\n","          Conv2d-261         [-1, 1024, 32, 32]       1,048,576\n","     BatchNorm2d-262         [-1, 1024, 32, 32]           2,048\n","            ReLU-263         [-1, 1024, 32, 32]               0\n","          Conv2d-264         [-1, 1024, 32, 32]         294,912\n","     BatchNorm2d-265         [-1, 1024, 32, 32]           2,048\n","            ReLU-266         [-1, 1024, 32, 32]               0\n","          Conv2d-267         [-1, 1024, 32, 32]       1,048,576\n","     BatchNorm2d-268         [-1, 1024, 32, 32]           2,048\n","            ReLU-269         [-1, 1024, 32, 32]               0\n","      Bottleneck-270         [-1, 1024, 32, 32]               0\n","          Conv2d-271         [-1, 1024, 32, 32]       1,048,576\n","     BatchNorm2d-272         [-1, 1024, 32, 32]           2,048\n","            ReLU-273         [-1, 1024, 32, 32]               0\n","          Conv2d-274         [-1, 1024, 32, 32]         294,912\n","     BatchNorm2d-275         [-1, 1024, 32, 32]           2,048\n","            ReLU-276         [-1, 1024, 32, 32]               0\n","          Conv2d-277         [-1, 1024, 32, 32]       1,048,576\n","     BatchNorm2d-278         [-1, 1024, 32, 32]           2,048\n","            ReLU-279         [-1, 1024, 32, 32]               0\n","      Bottleneck-280         [-1, 1024, 32, 32]               0\n","          Conv2d-281         [-1, 1024, 32, 32]       1,048,576\n","     BatchNorm2d-282         [-1, 1024, 32, 32]           2,048\n","            ReLU-283         [-1, 1024, 32, 32]               0\n","          Conv2d-284         [-1, 1024, 32, 32]         294,912\n","     BatchNorm2d-285         [-1, 1024, 32, 32]           2,048\n","            ReLU-286         [-1, 1024, 32, 32]               0\n","          Conv2d-287         [-1, 1024, 32, 32]       1,048,576\n","     BatchNorm2d-288         [-1, 1024, 32, 32]           2,048\n","            ReLU-289         [-1, 1024, 32, 32]               0\n","      Bottleneck-290         [-1, 1024, 32, 32]               0\n","          Conv2d-291         [-1, 1024, 32, 32]       1,048,576\n","     BatchNorm2d-292         [-1, 1024, 32, 32]           2,048\n","            ReLU-293         [-1, 1024, 32, 32]               0\n","          Conv2d-294         [-1, 1024, 32, 32]         294,912\n","     BatchNorm2d-295         [-1, 1024, 32, 32]           2,048\n","            ReLU-296         [-1, 1024, 32, 32]               0\n","          Conv2d-297         [-1, 1024, 32, 32]       1,048,576\n","     BatchNorm2d-298         [-1, 1024, 32, 32]           2,048\n","            ReLU-299         [-1, 1024, 32, 32]               0\n","      Bottleneck-300         [-1, 1024, 32, 32]               0\n","          Conv2d-301         [-1, 1024, 32, 32]       1,048,576\n","     BatchNorm2d-302         [-1, 1024, 32, 32]           2,048\n","            ReLU-303         [-1, 1024, 32, 32]               0\n","          Conv2d-304         [-1, 1024, 32, 32]         294,912\n","     BatchNorm2d-305         [-1, 1024, 32, 32]           2,048\n","            ReLU-306         [-1, 1024, 32, 32]               0\n","          Conv2d-307         [-1, 1024, 32, 32]       1,048,576\n","     BatchNorm2d-308         [-1, 1024, 32, 32]           2,048\n","            ReLU-309         [-1, 1024, 32, 32]               0\n","      Bottleneck-310         [-1, 1024, 32, 32]               0\n","          Conv2d-311         [-1, 2048, 32, 32]       2,097,152\n","     BatchNorm2d-312         [-1, 2048, 32, 32]           4,096\n","            ReLU-313         [-1, 2048, 32, 32]               0\n","          Conv2d-314         [-1, 2048, 16, 16]       1,179,648\n","     BatchNorm2d-315         [-1, 2048, 16, 16]           4,096\n","            ReLU-316         [-1, 2048, 16, 16]               0\n","          Conv2d-317         [-1, 2048, 16, 16]       4,194,304\n","     BatchNorm2d-318         [-1, 2048, 16, 16]           4,096\n","          Conv2d-319         [-1, 2048, 16, 16]       2,097,152\n","     BatchNorm2d-320         [-1, 2048, 16, 16]           4,096\n","            ReLU-321         [-1, 2048, 16, 16]               0\n","      Bottleneck-322         [-1, 2048, 16, 16]               0\n","          Conv2d-323         [-1, 2048, 16, 16]       4,194,304\n","     BatchNorm2d-324         [-1, 2048, 16, 16]           4,096\n","            ReLU-325         [-1, 2048, 16, 16]               0\n","          Conv2d-326         [-1, 2048, 16, 16]       1,179,648\n","     BatchNorm2d-327         [-1, 2048, 16, 16]           4,096\n","            ReLU-328         [-1, 2048, 16, 16]               0\n","          Conv2d-329         [-1, 2048, 16, 16]       4,194,304\n","     BatchNorm2d-330         [-1, 2048, 16, 16]           4,096\n","            ReLU-331         [-1, 2048, 16, 16]               0\n","      Bottleneck-332         [-1, 2048, 16, 16]               0\n","          Conv2d-333         [-1, 2048, 16, 16]       4,194,304\n","     BatchNorm2d-334         [-1, 2048, 16, 16]           4,096\n","            ReLU-335         [-1, 2048, 16, 16]               0\n","          Conv2d-336         [-1, 2048, 16, 16]       1,179,648\n","     BatchNorm2d-337         [-1, 2048, 16, 16]           4,096\n","            ReLU-338         [-1, 2048, 16, 16]               0\n","          Conv2d-339         [-1, 2048, 16, 16]       4,194,304\n","     BatchNorm2d-340         [-1, 2048, 16, 16]           4,096\n","            ReLU-341         [-1, 2048, 16, 16]               0\n","      Bottleneck-342         [-1, 2048, 16, 16]               0\n","          Conv2d-343        [-1, 256, 128, 128]         589,824\n","          Conv2d-344          [-1, 256, 64, 64]       1,179,648\n","          Conv2d-345          [-1, 256, 32, 32]       2,359,296\n","          Conv2d-346          [-1, 256, 16, 16]       4,718,592\n","            ReLU-347          [-1, 256, 16, 16]               0\n","          Conv2d-348          [-1, 256, 16, 16]         590,080\n","            ReLU-349          [-1, 256, 16, 16]               0\n","          Conv2d-350          [-1, 256, 16, 16]         590,080\n","ResidualConvUnit-351          [-1, 256, 16, 16]               0\n","FeatureFusionBlock-352          [-1, 256, 32, 32]               0\n","            ReLU-353          [-1, 256, 32, 32]               0\n","          Conv2d-354          [-1, 256, 32, 32]         590,080\n","            ReLU-355          [-1, 256, 32, 32]               0\n","          Conv2d-356          [-1, 256, 32, 32]         590,080\n","ResidualConvUnit-357          [-1, 256, 32, 32]               0\n","            ReLU-358          [-1, 256, 32, 32]               0\n","          Conv2d-359          [-1, 256, 32, 32]         590,080\n","            ReLU-360          [-1, 256, 32, 32]               0\n","          Conv2d-361          [-1, 256, 32, 32]         590,080\n","ResidualConvUnit-362          [-1, 256, 32, 32]               0\n","FeatureFusionBlock-363          [-1, 256, 64, 64]               0\n","            ReLU-364          [-1, 256, 64, 64]               0\n","          Conv2d-365          [-1, 256, 64, 64]         590,080\n","            ReLU-366          [-1, 256, 64, 64]               0\n","          Conv2d-367          [-1, 256, 64, 64]         590,080\n","ResidualConvUnit-368          [-1, 256, 64, 64]               0\n","            ReLU-369          [-1, 256, 64, 64]               0\n","          Conv2d-370          [-1, 256, 64, 64]         590,080\n","            ReLU-371          [-1, 256, 64, 64]               0\n","          Conv2d-372          [-1, 256, 64, 64]         590,080\n","ResidualConvUnit-373          [-1, 256, 64, 64]               0\n","FeatureFusionBlock-374        [-1, 256, 128, 128]               0\n","            ReLU-375        [-1, 256, 128, 128]               0\n","          Conv2d-376        [-1, 256, 128, 128]         590,080\n","            ReLU-377        [-1, 256, 128, 128]               0\n","          Conv2d-378        [-1, 256, 128, 128]         590,080\n","ResidualConvUnit-379        [-1, 256, 128, 128]               0\n","            ReLU-380        [-1, 256, 128, 128]               0\n","          Conv2d-381        [-1, 256, 128, 128]         590,080\n","            ReLU-382        [-1, 256, 128, 128]               0\n","          Conv2d-383        [-1, 256, 128, 128]         590,080\n","ResidualConvUnit-384        [-1, 256, 128, 128]               0\n","FeatureFusionBlock-385        [-1, 256, 256, 256]               0\n","          Conv2d-386        [-1, 128, 256, 256]         295,040\n","     Interpolate-387        [-1, 128, 512, 512]               0\n","          Conv2d-388         [-1, 32, 512, 512]          36,896\n","            ReLU-389         [-1, 32, 512, 512]               0\n","          Conv2d-390          [-1, 1, 512, 512]              33\n","            ReLU-391          [-1, 1, 512, 512]               0\n","          Conv2d-392        [-1, 256, 256, 256]           6,912\n","     BatchNorm2d-393        [-1, 256, 256, 256]             512\n","            ReLU-394        [-1, 256, 256, 256]               0\n","          Conv2d-395        [-1, 256, 128, 128]         589,824\n","     BatchNorm2d-396        [-1, 256, 128, 128]             512\n","            ReLU-397        [-1, 256, 128, 128]               0\n","          Conv2d-398          [-1, 256, 64, 64]         589,824\n","     BatchNorm2d-399          [-1, 256, 64, 64]             512\n","            ReLU-400          [-1, 256, 64, 64]               0\n","          Conv2d-401          [-1, 512, 32, 32]       1,179,648\n","     BatchNorm2d-402          [-1, 512, 32, 32]           1,024\n","            ReLU-403          [-1, 512, 32, 32]               0\n","          Conv2d-404         [-1, 1024, 16, 16]       4,718,592\n","     BatchNorm2d-405         [-1, 1024, 16, 16]           2,048\n","            ReLU-406         [-1, 1024, 16, 16]               0\n","          Conv2d-407         [-1, 1024, 16, 16]       2,097,152\n","     BatchNorm2d-408         [-1, 1024, 16, 16]           2,048\n","            ReLU-409         [-1, 1024, 16, 16]               0\n","          Conv2d-410           [-1, 27, 16, 16]          27,675\n","       YOLOLayer-411         [-1, 3, 16, 16, 9]               0\n","     Interpolate-412         [-1, 1024, 32, 32]               0\n","          Conv2d-413          [-1, 256, 32, 32]         262,144\n","     BatchNorm2d-414          [-1, 256, 32, 32]             512\n","            ReLU-415          [-1, 256, 32, 32]               0\n","          Conv2d-416          [-1, 512, 32, 32]         524,288\n","     BatchNorm2d-417          [-1, 512, 32, 32]           1,024\n","            ReLU-418          [-1, 512, 32, 32]               0\n","          Conv2d-419          [-1, 256, 32, 32]         196,608\n","     BatchNorm2d-420          [-1, 256, 32, 32]             512\n","            ReLU-421          [-1, 256, 32, 32]               0\n","          Conv2d-422          [-1, 512, 32, 32]       1,179,648\n","     BatchNorm2d-423          [-1, 512, 32, 32]           1,024\n","            ReLU-424          [-1, 512, 32, 32]               0\n","          Conv2d-425          [-1, 256, 32, 32]         131,072\n","     BatchNorm2d-426          [-1, 256, 32, 32]             512\n","            ReLU-427          [-1, 256, 32, 32]               0\n","          Conv2d-428          [-1, 512, 32, 32]       1,179,648\n","     BatchNorm2d-429          [-1, 512, 32, 32]           1,024\n","            ReLU-430          [-1, 512, 32, 32]               0\n","          Conv2d-431          [-1, 256, 32, 32]         131,072\n","     BatchNorm2d-432          [-1, 256, 32, 32]             512\n","            ReLU-433          [-1, 256, 32, 32]               0\n","          Conv2d-434          [-1, 512, 32, 32]       1,179,648\n","     BatchNorm2d-435          [-1, 512, 32, 32]           1,024\n","            ReLU-436          [-1, 512, 32, 32]               0\n","          Conv2d-437           [-1, 27, 32, 32]          13,851\n","       YOLOLayer-438         [-1, 3, 32, 32, 9]               0\n","          Conv2d-439          [-1, 256, 64, 64]         131,072\n","     BatchNorm2d-440          [-1, 256, 64, 64]             512\n","            ReLU-441          [-1, 256, 64, 64]               0\n","     Interpolate-442          [-1, 512, 64, 64]               0\n","          Conv2d-443          [-1, 128, 64, 64]          65,536\n","     BatchNorm2d-444          [-1, 128, 64, 64]             256\n","            ReLU-445          [-1, 128, 64, 64]               0\n","          Conv2d-446          [-1, 128, 64, 64]          49,152\n","     BatchNorm2d-447          [-1, 128, 64, 64]             256\n","            ReLU-448          [-1, 128, 64, 64]               0\n","          Conv2d-449          [-1, 256, 64, 64]         294,912\n","     BatchNorm2d-450          [-1, 256, 64, 64]             512\n","            ReLU-451          [-1, 256, 64, 64]               0\n","          Conv2d-452          [-1, 128, 64, 64]          32,768\n","     BatchNorm2d-453          [-1, 128, 64, 64]             256\n","            ReLU-454          [-1, 128, 64, 64]               0\n","          Conv2d-455          [-1, 256, 64, 64]         294,912\n","     BatchNorm2d-456          [-1, 256, 64, 64]             512\n","            ReLU-457          [-1, 256, 64, 64]               0\n","          Conv2d-458          [-1, 128, 64, 64]          32,768\n","     BatchNorm2d-459          [-1, 128, 64, 64]             256\n","            ReLU-460          [-1, 128, 64, 64]               0\n","          Conv2d-461          [-1, 256, 64, 64]         294,912\n","     BatchNorm2d-462          [-1, 256, 64, 64]             512\n","            ReLU-463          [-1, 256, 64, 64]               0\n","          Conv2d-464           [-1, 27, 64, 64]           6,939\n","       YOLOLayer-465         [-1, 3, 64, 64, 9]               0\n","================================================================\n","Total params: 119,409,234\n","Trainable params: 15,226,449\n","Non-trainable params: 104,182,785\n","----------------------------------------------------------------\n","Input size (MB): 3.00\n","Forward/backward pass size (MB): 5893.21\n","Params size (MB): 455.51\n","Estimated Total Size (MB): 6351.72\n","----------------------------------------------------------------\n","Image sizes 512 - 512 train, 512 test\n","Using 4 dataloader workers\n","Starting training for 300 epochs...\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","  0% 0/346 [00:00<?, ?it/s]/usr/local/lib/python3.6/dist-packages/torch/cuda/memory.py:346: FutureWarning: torch.cuda.memory_cached has been renamed to torch.cuda.memory_reserved\n","  FutureWarning)\n","   174/299     5.09G      4.28      1.09     0.465      5.84        60       512: 100% 346/346 [04:45<00:00,  1.21it/s]\n","               Class    Images   Targets         P         R   mAP@0.5        F1:   0% 0/87 [00:00<?, ?it/s]/content/drive/My Drive/computer_vision/capstone_project/yolo_v3/utils/utils.py:544: UserWarning: This overload of nonzero is deprecated:\n","\tnonzero()\n","Consider using one of the following signatures instead:\n","\tnonzero(*, bool as_tuple) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:882.)\n","  i, j = (x[:, 5:] > conf_thres).nonzero().t()\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 87/87 [00:56<00:00,  1.55it/s]\n","                 all       692  3.06e+03     0.248     0.578     0.349     0.347\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","  0% 0/346 [00:00<?, ?it/s]/usr/local/lib/python3.6/dist-packages/torch/cuda/memory.py:346: FutureWarning: torch.cuda.memory_cached has been renamed to torch.cuda.memory_reserved\n","  FutureWarning)\n","   175/299     5.09G      4.28      1.08     0.445      5.81        50       512: 100% 346/346 [04:45<00:00,  1.21it/s]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 87/87 [00:54<00:00,  1.60it/s]\n","                 all       692  3.06e+03     0.255     0.593     0.368     0.356\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","   176/299     5.09G       4.3      1.08     0.461      5.85        31       512: 100% 346/346 [04:46<00:00,  1.21it/s]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 87/87 [00:54<00:00,  1.59it/s]\n","                 all       692  3.06e+03     0.256     0.593     0.356     0.358\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","   177/299     5.09G       4.3      1.09     0.481      5.87        25       512: 100% 346/346 [04:45<00:00,  1.21it/s]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 87/87 [00:54<00:00,  1.59it/s]\n","                 all       692  3.06e+03     0.257     0.587     0.343     0.356\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","   178/299     5.09G      4.31      1.06     0.479      5.85        42       512: 100% 346/346 [04:45<00:00,  1.21it/s]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 87/87 [00:54<00:00,  1.59it/s]\n","                 all       692  3.06e+03     0.257     0.587      0.35     0.357\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","   179/299     5.09G       4.3       1.1     0.482      5.89        40       512: 100% 346/346 [04:45<00:00,  1.21it/s]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 87/87 [00:54<00:00,  1.59it/s]\n","                 all       692  3.06e+03     0.256     0.591     0.355     0.356\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","   180/299     5.09G      4.31      1.09     0.492      5.89        34       512: 100% 346/346 [04:45<00:00,  1.21it/s]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 87/87 [00:54<00:00,  1.60it/s]\n","                 all       692  3.06e+03     0.241     0.578     0.335      0.34\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","   181/299     5.09G      4.27      1.08     0.489      5.85        59       512: 100% 346/346 [04:45<00:00,  1.21it/s]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 87/87 [00:54<00:00,  1.60it/s]\n","                 all       692  3.06e+03     0.251     0.582     0.349      0.35\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","   182/299     5.09G      4.28      1.09     0.461      5.83        29       512: 100% 346/346 [04:45<00:00,  1.21it/s]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 87/87 [00:54<00:00,  1.59it/s]\n","                 all       692  3.06e+03     0.256     0.588     0.348     0.356\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","   183/299     5.09G      4.28      1.08     0.476      5.84        39       512: 100% 346/346 [04:45<00:00,  1.21it/s]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 87/87 [00:54<00:00,  1.60it/s]\n","                 all       692  3.06e+03     0.257     0.578     0.344     0.355\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","   184/299     5.09G      4.24      1.08     0.437      5.76        31       512: 100% 346/346 [04:45<00:00,  1.21it/s]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 87/87 [00:54<00:00,  1.60it/s]\n","                 all       692  3.06e+03     0.251     0.596      0.36     0.353\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","   185/299     5.09G      4.25      1.09     0.437      5.79        51       512: 100% 346/346 [04:45<00:00,  1.21it/s]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 87/87 [00:54<00:00,  1.60it/s]\n","                 all       692  3.06e+03     0.255     0.589     0.348     0.355\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","   186/299     5.09G      4.26      1.08     0.458       5.8        31       512: 100% 346/346 [04:46<00:00,  1.21it/s]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 87/87 [00:54<00:00,  1.60it/s]\n","                 all       692  3.06e+03     0.251     0.588     0.346     0.351\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","   187/299     5.09G      4.24      1.07     0.436      5.74        57       512: 100% 346/346 [04:45<00:00,  1.21it/s]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 87/87 [00:54<00:00,  1.60it/s]\n","                 all       692  3.06e+03     0.257     0.585     0.357     0.356\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","   188/299     5.09G      4.31      1.05     0.518      5.88        42       512: 100% 346/346 [04:45<00:00,  1.21it/s]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 87/87 [00:54<00:00,  1.60it/s]\n","                 all       692  3.06e+03     0.255     0.585     0.353     0.354\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","   189/299     5.09G      4.32      1.09     0.517      5.93        41       512: 100% 346/346 [04:45<00:00,  1.21it/s]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 87/87 [00:54<00:00,  1.60it/s]\n","                 all       692  3.06e+03     0.258     0.579     0.356     0.356\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","   190/299     5.09G      4.29      1.08     0.494      5.87        66       512: 100% 346/346 [04:45<00:00,  1.21it/s]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 87/87 [00:54<00:00,  1.60it/s]\n","                 all       692  3.06e+03     0.254     0.588      0.35     0.354\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","   191/299     5.09G      4.28      1.08     0.495      5.86        36       512: 100% 346/346 [04:45<00:00,  1.21it/s]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 87/87 [00:54<00:00,  1.60it/s]\n","                 all       692  3.06e+03     0.246     0.593     0.335     0.347\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","   192/299     5.09G      4.28      1.07     0.473      5.82        58       512: 100% 346/346 [04:45<00:00,  1.21it/s]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 87/87 [00:54<00:00,  1.60it/s]\n","                 all       692  3.06e+03     0.243     0.594      0.36     0.344\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","   193/299     5.09G      4.26      1.06     0.486      5.81        52       512: 100% 346/346 [04:45<00:00,  1.21it/s]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 87/87 [00:54<00:00,  1.60it/s]\n","                 all       692  3.06e+03     0.255     0.588     0.346     0.355\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","   194/299     5.09G      4.28      1.04      0.51      5.84        36       512: 100% 346/346 [04:45<00:00,  1.21it/s]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 87/87 [00:54<00:00,  1.60it/s]\n","                 all       692  3.06e+03     0.264     0.589     0.361     0.364\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","   195/299     5.09G      4.26      1.06     0.506      5.83        23       512: 100% 346/346 [04:45<00:00,  1.21it/s]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 87/87 [00:54<00:00,  1.60it/s]\n","                 all       692  3.06e+03     0.262     0.588     0.356     0.361\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","   196/299     5.09G      4.26      1.05     0.465      5.77        38       512: 100% 346/346 [04:46<00:00,  1.21it/s]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 87/87 [00:54<00:00,  1.60it/s]\n","                 all       692  3.06e+03     0.251      0.59      0.35     0.351\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","   197/299     5.09G      4.24      1.07     0.467      5.78        60       512: 100% 346/346 [04:45<00:00,  1.21it/s]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 87/87 [00:54<00:00,  1.60it/s]\n","                 all       692  3.06e+03     0.255     0.592     0.345     0.356\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","   198/299     5.09G      4.25      1.06     0.474      5.78        39       512: 100% 346/346 [04:45<00:00,  1.21it/s]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 87/87 [00:54<00:00,  1.60it/s]\n","                 all       692  3.06e+03     0.254     0.592     0.337     0.355\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","   199/299     5.09G      4.22      1.07     0.484      5.77        46       512: 100% 346/346 [04:45<00:00,  1.21it/s]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 87/87 [00:54<00:00,  1.60it/s]\n","                 all       692  3.06e+03     0.257     0.592     0.353     0.358\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","   200/299     5.09G      4.22      1.05     0.454      5.73        58       512: 100% 346/346 [04:45<00:00,  1.21it/s]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 87/87 [00:54<00:00,  1.60it/s]\n","                 all       692  3.06e+03     0.248     0.594     0.345      0.35\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","   201/299     5.09G      4.22      1.06      0.46      5.74        55       512: 100% 346/346 [04:45<00:00,  1.21it/s]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 87/87 [00:54<00:00,  1.60it/s]\n","                 all       692  3.06e+03     0.256     0.589      0.35     0.356\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","   202/299     5.09G      4.21      1.05     0.476      5.74        47       512: 100% 346/346 [04:45<00:00,  1.21it/s]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 87/87 [00:54<00:00,  1.59it/s]\n","                 all       692  3.06e+03     0.249     0.596     0.348      0.35\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","   203/299     5.09G       4.2      1.05     0.447      5.69        51       512: 100% 346/346 [04:45<00:00,  1.21it/s]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 87/87 [00:54<00:00,  1.60it/s]\n","                 all       692  3.06e+03     0.254     0.596     0.342     0.355\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","   204/299     5.09G      4.21      1.05     0.447       5.7        38       512: 100% 346/346 [04:45<00:00,  1.21it/s]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 87/87 [00:54<00:00,  1.60it/s]\n","                 all       692  3.06e+03     0.252     0.593     0.335     0.353\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","   205/299     5.09G       4.2      1.06      0.46      5.71        77       512: 100% 346/346 [04:45<00:00,  1.21it/s]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 87/87 [00:54<00:00,  1.60it/s]\n","                 all       692  3.06e+03     0.262     0.577     0.332     0.359\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","   206/299     5.09G       4.2      1.04      0.44      5.69        63       512: 100% 346/346 [04:45<00:00,  1.21it/s]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 87/87 [00:54<00:00,  1.60it/s]\n","                 all       692  3.06e+03     0.255     0.581     0.337     0.353\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","   207/299     5.09G      4.18      1.05     0.447      5.68        45       512: 100% 346/346 [04:45<00:00,  1.21it/s]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 87/87 [00:54<00:00,  1.60it/s]\n","                 all       692  3.06e+03     0.252      0.59      0.35     0.353\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","   208/299     5.09G      4.18      1.05     0.459      5.69        42       512: 100% 346/346 [04:45<00:00,  1.21it/s]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 87/87 [00:54<00:00,  1.59it/s]\n","                 all       692  3.06e+03     0.256     0.601     0.361     0.358\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","   209/299     5.09G       4.2      1.03     0.442      5.68        46       512: 100% 346/346 [04:45<00:00,  1.21it/s]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 87/87 [00:54<00:00,  1.60it/s]\n","                 all       692  3.06e+03     0.257     0.587     0.352     0.357\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","   210/299     5.09G      4.21      1.04     0.454       5.7        43       512: 100% 346/346 [04:45<00:00,  1.21it/s]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 87/87 [00:54<00:00,  1.60it/s]\n","                 all       692  3.06e+03     0.253     0.588     0.329     0.352\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","   211/299     5.09G      4.19      1.05     0.455      5.69        47       512: 100% 346/346 [04:45<00:00,  1.21it/s]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 87/87 [00:54<00:00,  1.60it/s]\n","                 all       692  3.06e+03     0.248     0.589     0.331     0.348\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","   212/299     5.09G       4.2      1.04     0.456       5.7        54       512: 100% 346/346 [04:45<00:00,  1.21it/s]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 87/87 [00:54<00:00,  1.60it/s]\n","                 all       692  3.06e+03     0.256     0.597     0.344     0.357\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","   213/299     5.09G      4.16      1.04     0.433      5.64        40       512: 100% 346/346 [04:45<00:00,  1.21it/s]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 87/87 [00:54<00:00,  1.60it/s]\n","                 all       692  3.06e+03     0.251     0.587      0.35     0.351\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","   214/299     5.09G      4.16      1.05     0.454      5.67        45       512: 100% 346/346 [04:45<00:00,  1.21it/s]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 87/87 [00:54<00:00,  1.60it/s]\n","                 all       692  3.06e+03     0.259     0.595     0.356      0.36\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","   215/299     5.09G      4.15      1.02     0.447      5.63        46       512: 100% 346/346 [04:45<00:00,  1.21it/s]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 87/87 [00:54<00:00,  1.60it/s]\n","                 all       692  3.06e+03     0.255     0.585     0.334     0.355\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","   216/299     5.09G      4.17      1.04     0.431      5.64        41       512: 100% 346/346 [04:45<00:00,  1.21it/s]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 87/87 [00:54<00:00,  1.60it/s]\n","                 all       692  3.06e+03     0.257     0.579     0.343     0.355\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","   217/299     5.09G      4.16      1.04     0.445      5.65        41       512: 100% 346/346 [04:45<00:00,  1.21it/s]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 87/87 [00:54<00:00,  1.60it/s]\n","                 all       692  3.06e+03     0.251     0.594     0.349     0.352\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","   218/299     5.09G      4.14      1.03     0.434      5.61        65       512: 100% 346/346 [04:45<00:00,  1.21it/s]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 87/87 [00:54<00:00,  1.60it/s]\n","                 all       692  3.06e+03     0.251     0.584     0.337      0.35\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","   219/299     5.09G      4.17      1.03     0.449      5.64        62       512: 100% 346/346 [04:45<00:00,  1.21it/s]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 87/87 [00:54<00:00,  1.60it/s]\n","                 all       692  3.06e+03     0.259     0.587      0.34     0.359\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","   220/299     5.09G      4.13      1.03     0.436       5.6        48       512: 100% 346/346 [04:45<00:00,  1.21it/s]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 87/87 [00:54<00:00,  1.60it/s]\n","                 all       692  3.06e+03     0.259      0.59     0.345     0.359\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","   221/299     5.09G      4.14      1.05     0.431      5.62        51       512: 100% 346/346 [04:46<00:00,  1.21it/s]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 87/87 [00:54<00:00,  1.60it/s]\n","                 all       692  3.06e+03     0.254     0.593     0.345     0.356\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","   222/299     5.09G      4.13      1.02     0.447       5.6        37       512: 100% 346/346 [04:45<00:00,  1.21it/s]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 87/87 [00:54<00:00,  1.60it/s]\n","                 all       692  3.06e+03     0.253     0.587     0.336     0.353\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","   223/299     5.09G      4.12      1.02     0.413      5.55        52       512: 100% 346/346 [04:45<00:00,  1.21it/s]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 87/87 [00:54<00:00,  1.60it/s]\n","                 all       692  3.06e+03     0.259     0.585     0.344     0.358\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","   224/299     5.09G      4.13      1.04     0.426      5.59        48       512: 100% 346/346 [04:45<00:00,  1.21it/s]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 87/87 [00:54<00:00,  1.60it/s]\n","                 all       692  3.06e+03     0.252     0.583     0.329     0.351\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","   225/299     5.09G      4.13      1.03     0.411      5.57        59       512: 100% 346/346 [04:45<00:00,  1.21it/s]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 87/87 [00:54<00:00,  1.60it/s]\n","                 all       692  3.06e+03     0.258     0.582     0.331     0.357\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","   226/299     5.09G      4.13      1.03     0.413      5.57        37       512: 100% 346/346 [04:45<00:00,  1.21it/s]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 87/87 [00:54<00:00,  1.60it/s]\n","                 all       692  3.06e+03      0.26     0.585     0.331      0.36\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","   227/299     5.09G      4.11      1.02     0.442      5.57        55       512: 100% 346/346 [04:45<00:00,  1.21it/s]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 87/87 [00:54<00:00,  1.60it/s]\n","                 all       692  3.06e+03     0.257     0.585     0.339     0.356\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","   228/299     5.09G      4.11      1.04     0.418      5.57        52       512: 100% 346/346 [04:45<00:00,  1.21it/s]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 87/87 [00:54<00:00,  1.60it/s]\n","                 all       692  3.06e+03     0.257     0.588     0.342     0.357\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","   229/299     5.09G      4.12      1.04     0.412      5.58        68       512:  84% 290/346 [03:59<00:45,  1.22it/s]"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"F_rxDA0KntAY","colab":{"base_uri":"https://localhost:8080/"},"outputId":"b4ecf5ae-7d7f-4c1d-eeff-e1b67e04a345"},"source":["!python train.py --data data/customdata/custom.data --batch 8  --cache --cfg cfg/yolov3-custom.cfg --epochs 300 --weights 'weights/best.pt'  --img-size=512 --midasnet_freeze='True'"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Namespace(accumulate=4, adam=False, batch_size=8, bucket='', cache_images=True, cfg='cfg/yolov3-custom.cfg', data='data/customdata/custom.data', device='', epochs=300, evolve=False, img_size=[512], init_train='False', midas_weights='', midasnet_freeze='True', multi_scale=False, name='', nosave=False, notest=False, rect=False, resume=False, single_cls=False, weights='weights/best.pt', yolo_weights='')\n","Using CUDA device0 _CudaDeviceProperties(name='Tesla P100-PCIE-16GB', total_memory=16280MB)\n","\n","2020-11-15 08:42:24.436491: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n","Run 'tensorboard --logdir=runs' to view tensorboard at http://localhost:6006/\n","cfg - cfg/yolov3-custom.cfg\n","data - data/customdata/custom.data\n","epochs - 300\n","batch_size - 8\n","accumulate - 4\n","yolo weights - \n","midas weights - \n","imgsz_min- 512, imgsz_max- 512, imgsz_test- 512\n","opt.rect - False\n","train_path - data/customdata/train.txt\n","test_path - data/customdata/test.txt\n","init_train - False\n","weights - weights/best.pt\n","midasnet_freeze - True\n","mixed_precision enabled - False\n","Downloading: \"https://github.com/facebookresearch/WSL-Images/archive/master.zip\" to /root/.cache/torch/hub/master.zip\n","Downloading: \"https://download.pytorch.org/models/ig_resnext101_32x8-c38310e5.pth\" to /root/.cache/torch/hub/checkpoints/ig_resnext101_32x8-c38310e5.pth\n","100% 340M/340M [00:09<00:00, 39.4MB/s]\n","Caching labels (2623 found, 114 missing, 30 empty, 0 duplicate, for 2767 images): 100% 2767/2767 [16:15<00:00,  2.84it/s]\n","Caching images (1.5GB): 100% 2767/2767 [1:48:56<00:00,  2.36s/it]\n","Caching labels (657 found, 27 missing, 8 empty, 0 duplicate, for 692 images): 100% 692/692 [04:33<00:00,  2.53it/s]\n","Caching images (0.3GB): 100% 692/692 [21:27<00:00,  1.86s/it]\n","Freezing the midasnet\n","YMP Model Summary\n","----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","            Conv2d-1         [-1, 64, 256, 256]           9,408\n","       BatchNorm2d-2         [-1, 64, 256, 256]             128\n","              ReLU-3         [-1, 64, 256, 256]               0\n","         MaxPool2d-4         [-1, 64, 128, 128]               0\n","            Conv2d-5        [-1, 256, 128, 128]          16,384\n","       BatchNorm2d-6        [-1, 256, 128, 128]             512\n","              ReLU-7        [-1, 256, 128, 128]               0\n","            Conv2d-8        [-1, 256, 128, 128]          18,432\n","       BatchNorm2d-9        [-1, 256, 128, 128]             512\n","             ReLU-10        [-1, 256, 128, 128]               0\n","           Conv2d-11        [-1, 256, 128, 128]          65,536\n","      BatchNorm2d-12        [-1, 256, 128, 128]             512\n","           Conv2d-13        [-1, 256, 128, 128]          16,384\n","      BatchNorm2d-14        [-1, 256, 128, 128]             512\n","             ReLU-15        [-1, 256, 128, 128]               0\n","       Bottleneck-16        [-1, 256, 128, 128]               0\n","           Conv2d-17        [-1, 256, 128, 128]          65,536\n","      BatchNorm2d-18        [-1, 256, 128, 128]             512\n","             ReLU-19        [-1, 256, 128, 128]               0\n","           Conv2d-20        [-1, 256, 128, 128]          18,432\n","      BatchNorm2d-21        [-1, 256, 128, 128]             512\n","             ReLU-22        [-1, 256, 128, 128]               0\n","           Conv2d-23        [-1, 256, 128, 128]          65,536\n","      BatchNorm2d-24        [-1, 256, 128, 128]             512\n","             ReLU-25        [-1, 256, 128, 128]               0\n","       Bottleneck-26        [-1, 256, 128, 128]               0\n","           Conv2d-27        [-1, 256, 128, 128]          65,536\n","      BatchNorm2d-28        [-1, 256, 128, 128]             512\n","             ReLU-29        [-1, 256, 128, 128]               0\n","           Conv2d-30        [-1, 256, 128, 128]          18,432\n","      BatchNorm2d-31        [-1, 256, 128, 128]             512\n","             ReLU-32        [-1, 256, 128, 128]               0\n","           Conv2d-33        [-1, 256, 128, 128]          65,536\n","      BatchNorm2d-34        [-1, 256, 128, 128]             512\n","             ReLU-35        [-1, 256, 128, 128]               0\n","       Bottleneck-36        [-1, 256, 128, 128]               0\n","           Conv2d-37        [-1, 512, 128, 128]         131,072\n","      BatchNorm2d-38        [-1, 512, 128, 128]           1,024\n","             ReLU-39        [-1, 512, 128, 128]               0\n","           Conv2d-40          [-1, 512, 64, 64]          73,728\n","      BatchNorm2d-41          [-1, 512, 64, 64]           1,024\n","             ReLU-42          [-1, 512, 64, 64]               0\n","           Conv2d-43          [-1, 512, 64, 64]         262,144\n","      BatchNorm2d-44          [-1, 512, 64, 64]           1,024\n","           Conv2d-45          [-1, 512, 64, 64]         131,072\n","      BatchNorm2d-46          [-1, 512, 64, 64]           1,024\n","             ReLU-47          [-1, 512, 64, 64]               0\n","       Bottleneck-48          [-1, 512, 64, 64]               0\n","           Conv2d-49          [-1, 512, 64, 64]         262,144\n","      BatchNorm2d-50          [-1, 512, 64, 64]           1,024\n","             ReLU-51          [-1, 512, 64, 64]               0\n","           Conv2d-52          [-1, 512, 64, 64]          73,728\n","      BatchNorm2d-53          [-1, 512, 64, 64]           1,024\n","             ReLU-54          [-1, 512, 64, 64]               0\n","           Conv2d-55          [-1, 512, 64, 64]         262,144\n","      BatchNorm2d-56          [-1, 512, 64, 64]           1,024\n","             ReLU-57          [-1, 512, 64, 64]               0\n","       Bottleneck-58          [-1, 512, 64, 64]               0\n","           Conv2d-59          [-1, 512, 64, 64]         262,144\n","      BatchNorm2d-60          [-1, 512, 64, 64]           1,024\n","             ReLU-61          [-1, 512, 64, 64]               0\n","           Conv2d-62          [-1, 512, 64, 64]          73,728\n","      BatchNorm2d-63          [-1, 512, 64, 64]           1,024\n","             ReLU-64          [-1, 512, 64, 64]               0\n","           Conv2d-65          [-1, 512, 64, 64]         262,144\n","      BatchNorm2d-66          [-1, 512, 64, 64]           1,024\n","             ReLU-67          [-1, 512, 64, 64]               0\n","       Bottleneck-68          [-1, 512, 64, 64]               0\n","           Conv2d-69          [-1, 512, 64, 64]         262,144\n","      BatchNorm2d-70          [-1, 512, 64, 64]           1,024\n","             ReLU-71          [-1, 512, 64, 64]               0\n","           Conv2d-72          [-1, 512, 64, 64]          73,728\n","      BatchNorm2d-73          [-1, 512, 64, 64]           1,024\n","             ReLU-74          [-1, 512, 64, 64]               0\n","           Conv2d-75          [-1, 512, 64, 64]         262,144\n","      BatchNorm2d-76          [-1, 512, 64, 64]           1,024\n","             ReLU-77          [-1, 512, 64, 64]               0\n","       Bottleneck-78          [-1, 512, 64, 64]               0\n","           Conv2d-79         [-1, 1024, 64, 64]         524,288\n","      BatchNorm2d-80         [-1, 1024, 64, 64]           2,048\n","             ReLU-81         [-1, 1024, 64, 64]               0\n","           Conv2d-82         [-1, 1024, 32, 32]         294,912\n","      BatchNorm2d-83         [-1, 1024, 32, 32]           2,048\n","             ReLU-84         [-1, 1024, 32, 32]               0\n","           Conv2d-85         [-1, 1024, 32, 32]       1,048,576\n","      BatchNorm2d-86         [-1, 1024, 32, 32]           2,048\n","           Conv2d-87         [-1, 1024, 32, 32]         524,288\n","      BatchNorm2d-88         [-1, 1024, 32, 32]           2,048\n","             ReLU-89         [-1, 1024, 32, 32]               0\n","       Bottleneck-90         [-1, 1024, 32, 32]               0\n","           Conv2d-91         [-1, 1024, 32, 32]       1,048,576\n","      BatchNorm2d-92         [-1, 1024, 32, 32]           2,048\n","             ReLU-93         [-1, 1024, 32, 32]               0\n","           Conv2d-94         [-1, 1024, 32, 32]         294,912\n","      BatchNorm2d-95         [-1, 1024, 32, 32]           2,048\n","             ReLU-96         [-1, 1024, 32, 32]               0\n","           Conv2d-97         [-1, 1024, 32, 32]       1,048,576\n","      BatchNorm2d-98         [-1, 1024, 32, 32]           2,048\n","             ReLU-99         [-1, 1024, 32, 32]               0\n","      Bottleneck-100         [-1, 1024, 32, 32]               0\n","          Conv2d-101         [-1, 1024, 32, 32]       1,048,576\n","     BatchNorm2d-102         [-1, 1024, 32, 32]           2,048\n","            ReLU-103         [-1, 1024, 32, 32]               0\n","          Conv2d-104         [-1, 1024, 32, 32]         294,912\n","     BatchNorm2d-105         [-1, 1024, 32, 32]           2,048\n","            ReLU-106         [-1, 1024, 32, 32]               0\n","          Conv2d-107         [-1, 1024, 32, 32]       1,048,576\n","     BatchNorm2d-108         [-1, 1024, 32, 32]           2,048\n","            ReLU-109         [-1, 1024, 32, 32]               0\n","      Bottleneck-110         [-1, 1024, 32, 32]               0\n","          Conv2d-111         [-1, 1024, 32, 32]       1,048,576\n","     BatchNorm2d-112         [-1, 1024, 32, 32]           2,048\n","            ReLU-113         [-1, 1024, 32, 32]               0\n","          Conv2d-114         [-1, 1024, 32, 32]         294,912\n","     BatchNorm2d-115         [-1, 1024, 32, 32]           2,048\n","            ReLU-116         [-1, 1024, 32, 32]               0\n","          Conv2d-117         [-1, 1024, 32, 32]       1,048,576\n","     BatchNorm2d-118         [-1, 1024, 32, 32]           2,048\n","            ReLU-119         [-1, 1024, 32, 32]               0\n","      Bottleneck-120         [-1, 1024, 32, 32]               0\n","          Conv2d-121         [-1, 1024, 32, 32]       1,048,576\n","     BatchNorm2d-122         [-1, 1024, 32, 32]           2,048\n","            ReLU-123         [-1, 1024, 32, 32]               0\n","          Conv2d-124         [-1, 1024, 32, 32]         294,912\n","     BatchNorm2d-125         [-1, 1024, 32, 32]           2,048\n","            ReLU-126         [-1, 1024, 32, 32]               0\n","          Conv2d-127         [-1, 1024, 32, 32]       1,048,576\n","     BatchNorm2d-128         [-1, 1024, 32, 32]           2,048\n","            ReLU-129         [-1, 1024, 32, 32]               0\n","      Bottleneck-130         [-1, 1024, 32, 32]               0\n","          Conv2d-131         [-1, 1024, 32, 32]       1,048,576\n","     BatchNorm2d-132         [-1, 1024, 32, 32]           2,048\n","            ReLU-133         [-1, 1024, 32, 32]               0\n","          Conv2d-134         [-1, 1024, 32, 32]         294,912\n","     BatchNorm2d-135         [-1, 1024, 32, 32]           2,048\n","            ReLU-136         [-1, 1024, 32, 32]               0\n","          Conv2d-137         [-1, 1024, 32, 32]       1,048,576\n","     BatchNorm2d-138         [-1, 1024, 32, 32]           2,048\n","            ReLU-139         [-1, 1024, 32, 32]               0\n","      Bottleneck-140         [-1, 1024, 32, 32]               0\n","          Conv2d-141         [-1, 1024, 32, 32]       1,048,576\n","     BatchNorm2d-142         [-1, 1024, 32, 32]           2,048\n","            ReLU-143         [-1, 1024, 32, 32]               0\n","          Conv2d-144         [-1, 1024, 32, 32]         294,912\n","     BatchNorm2d-145         [-1, 1024, 32, 32]           2,048\n","            ReLU-146         [-1, 1024, 32, 32]               0\n","          Conv2d-147         [-1, 1024, 32, 32]       1,048,576\n","     BatchNorm2d-148         [-1, 1024, 32, 32]           2,048\n","            ReLU-149         [-1, 1024, 32, 32]               0\n","      Bottleneck-150         [-1, 1024, 32, 32]               0\n","          Conv2d-151         [-1, 1024, 32, 32]       1,048,576\n","     BatchNorm2d-152         [-1, 1024, 32, 32]           2,048\n","            ReLU-153         [-1, 1024, 32, 32]               0\n","          Conv2d-154         [-1, 1024, 32, 32]         294,912\n","     BatchNorm2d-155         [-1, 1024, 32, 32]           2,048\n","            ReLU-156         [-1, 1024, 32, 32]               0\n","          Conv2d-157         [-1, 1024, 32, 32]       1,048,576\n","     BatchNorm2d-158         [-1, 1024, 32, 32]           2,048\n","            ReLU-159         [-1, 1024, 32, 32]               0\n","      Bottleneck-160         [-1, 1024, 32, 32]               0\n","          Conv2d-161         [-1, 1024, 32, 32]       1,048,576\n","     BatchNorm2d-162         [-1, 1024, 32, 32]           2,048\n","            ReLU-163         [-1, 1024, 32, 32]               0\n","          Conv2d-164         [-1, 1024, 32, 32]         294,912\n","     BatchNorm2d-165         [-1, 1024, 32, 32]           2,048\n","            ReLU-166         [-1, 1024, 32, 32]               0\n","          Conv2d-167         [-1, 1024, 32, 32]       1,048,576\n","     BatchNorm2d-168         [-1, 1024, 32, 32]           2,048\n","            ReLU-169         [-1, 1024, 32, 32]               0\n","      Bottleneck-170         [-1, 1024, 32, 32]               0\n","          Conv2d-171         [-1, 1024, 32, 32]       1,048,576\n","     BatchNorm2d-172         [-1, 1024, 32, 32]           2,048\n","            ReLU-173         [-1, 1024, 32, 32]               0\n","          Conv2d-174         [-1, 1024, 32, 32]         294,912\n","     BatchNorm2d-175         [-1, 1024, 32, 32]           2,048\n","            ReLU-176         [-1, 1024, 32, 32]               0\n","          Conv2d-177         [-1, 1024, 32, 32]       1,048,576\n","     BatchNorm2d-178         [-1, 1024, 32, 32]           2,048\n","            ReLU-179         [-1, 1024, 32, 32]               0\n","      Bottleneck-180         [-1, 1024, 32, 32]               0\n","          Conv2d-181         [-1, 1024, 32, 32]       1,048,576\n","     BatchNorm2d-182         [-1, 1024, 32, 32]           2,048\n","            ReLU-183         [-1, 1024, 32, 32]               0\n","          Conv2d-184         [-1, 1024, 32, 32]         294,912\n","     BatchNorm2d-185         [-1, 1024, 32, 32]           2,048\n","            ReLU-186         [-1, 1024, 32, 32]               0\n","          Conv2d-187         [-1, 1024, 32, 32]       1,048,576\n","     BatchNorm2d-188         [-1, 1024, 32, 32]           2,048\n","            ReLU-189         [-1, 1024, 32, 32]               0\n","      Bottleneck-190         [-1, 1024, 32, 32]               0\n","          Conv2d-191         [-1, 1024, 32, 32]       1,048,576\n","     BatchNorm2d-192         [-1, 1024, 32, 32]           2,048\n","            ReLU-193         [-1, 1024, 32, 32]               0\n","          Conv2d-194         [-1, 1024, 32, 32]         294,912\n","     BatchNorm2d-195         [-1, 1024, 32, 32]           2,048\n","            ReLU-196         [-1, 1024, 32, 32]               0\n","          Conv2d-197         [-1, 1024, 32, 32]       1,048,576\n","     BatchNorm2d-198         [-1, 1024, 32, 32]           2,048\n","            ReLU-199         [-1, 1024, 32, 32]               0\n","      Bottleneck-200         [-1, 1024, 32, 32]               0\n","          Conv2d-201         [-1, 1024, 32, 32]       1,048,576\n","     BatchNorm2d-202         [-1, 1024, 32, 32]           2,048\n","            ReLU-203         [-1, 1024, 32, 32]               0\n","          Conv2d-204         [-1, 1024, 32, 32]         294,912\n","     BatchNorm2d-205         [-1, 1024, 32, 32]           2,048\n","            ReLU-206         [-1, 1024, 32, 32]               0\n","          Conv2d-207         [-1, 1024, 32, 32]       1,048,576\n","     BatchNorm2d-208         [-1, 1024, 32, 32]           2,048\n","            ReLU-209         [-1, 1024, 32, 32]               0\n","      Bottleneck-210         [-1, 1024, 32, 32]               0\n","          Conv2d-211         [-1, 1024, 32, 32]       1,048,576\n","     BatchNorm2d-212         [-1, 1024, 32, 32]           2,048\n","            ReLU-213         [-1, 1024, 32, 32]               0\n","          Conv2d-214         [-1, 1024, 32, 32]         294,912\n","     BatchNorm2d-215         [-1, 1024, 32, 32]           2,048\n","            ReLU-216         [-1, 1024, 32, 32]               0\n","          Conv2d-217         [-1, 1024, 32, 32]       1,048,576\n","     BatchNorm2d-218         [-1, 1024, 32, 32]           2,048\n","            ReLU-219         [-1, 1024, 32, 32]               0\n","      Bottleneck-220         [-1, 1024, 32, 32]               0\n","          Conv2d-221         [-1, 1024, 32, 32]       1,048,576\n","     BatchNorm2d-222         [-1, 1024, 32, 32]           2,048\n","            ReLU-223         [-1, 1024, 32, 32]               0\n","          Conv2d-224         [-1, 1024, 32, 32]         294,912\n","     BatchNorm2d-225         [-1, 1024, 32, 32]           2,048\n","            ReLU-226         [-1, 1024, 32, 32]               0\n","          Conv2d-227         [-1, 1024, 32, 32]       1,048,576\n","     BatchNorm2d-228         [-1, 1024, 32, 32]           2,048\n","            ReLU-229         [-1, 1024, 32, 32]               0\n","      Bottleneck-230         [-1, 1024, 32, 32]               0\n","          Conv2d-231         [-1, 1024, 32, 32]       1,048,576\n","     BatchNorm2d-232         [-1, 1024, 32, 32]           2,048\n","            ReLU-233         [-1, 1024, 32, 32]               0\n","          Conv2d-234         [-1, 1024, 32, 32]         294,912\n","     BatchNorm2d-235         [-1, 1024, 32, 32]           2,048\n","            ReLU-236         [-1, 1024, 32, 32]               0\n","          Conv2d-237         [-1, 1024, 32, 32]       1,048,576\n","     BatchNorm2d-238         [-1, 1024, 32, 32]           2,048\n","            ReLU-239         [-1, 1024, 32, 32]               0\n","      Bottleneck-240         [-1, 1024, 32, 32]               0\n","          Conv2d-241         [-1, 1024, 32, 32]       1,048,576\n","     BatchNorm2d-242         [-1, 1024, 32, 32]           2,048\n","            ReLU-243         [-1, 1024, 32, 32]               0\n","          Conv2d-244         [-1, 1024, 32, 32]         294,912\n","     BatchNorm2d-245         [-1, 1024, 32, 32]           2,048\n","            ReLU-246         [-1, 1024, 32, 32]               0\n","          Conv2d-247         [-1, 1024, 32, 32]       1,048,576\n","     BatchNorm2d-248         [-1, 1024, 32, 32]           2,048\n","            ReLU-249         [-1, 1024, 32, 32]               0\n","      Bottleneck-250         [-1, 1024, 32, 32]               0\n","          Conv2d-251         [-1, 1024, 32, 32]       1,048,576\n","     BatchNorm2d-252         [-1, 1024, 32, 32]           2,048\n","            ReLU-253         [-1, 1024, 32, 32]               0\n","          Conv2d-254         [-1, 1024, 32, 32]         294,912\n","     BatchNorm2d-255         [-1, 1024, 32, 32]           2,048\n","            ReLU-256         [-1, 1024, 32, 32]               0\n","          Conv2d-257         [-1, 1024, 32, 32]       1,048,576\n","     BatchNorm2d-258         [-1, 1024, 32, 32]           2,048\n","            ReLU-259         [-1, 1024, 32, 32]               0\n","      Bottleneck-260         [-1, 1024, 32, 32]               0\n","          Conv2d-261         [-1, 1024, 32, 32]       1,048,576\n","     BatchNorm2d-262         [-1, 1024, 32, 32]           2,048\n","            ReLU-263         [-1, 1024, 32, 32]               0\n","          Conv2d-264         [-1, 1024, 32, 32]         294,912\n","     BatchNorm2d-265         [-1, 1024, 32, 32]           2,048\n","            ReLU-266         [-1, 1024, 32, 32]               0\n","          Conv2d-267         [-1, 1024, 32, 32]       1,048,576\n","     BatchNorm2d-268         [-1, 1024, 32, 32]           2,048\n","            ReLU-269         [-1, 1024, 32, 32]               0\n","      Bottleneck-270         [-1, 1024, 32, 32]               0\n","          Conv2d-271         [-1, 1024, 32, 32]       1,048,576\n","     BatchNorm2d-272         [-1, 1024, 32, 32]           2,048\n","            ReLU-273         [-1, 1024, 32, 32]               0\n","          Conv2d-274         [-1, 1024, 32, 32]         294,912\n","     BatchNorm2d-275         [-1, 1024, 32, 32]           2,048\n","            ReLU-276         [-1, 1024, 32, 32]               0\n","          Conv2d-277         [-1, 1024, 32, 32]       1,048,576\n","     BatchNorm2d-278         [-1, 1024, 32, 32]           2,048\n","            ReLU-279         [-1, 1024, 32, 32]               0\n","      Bottleneck-280         [-1, 1024, 32, 32]               0\n","          Conv2d-281         [-1, 1024, 32, 32]       1,048,576\n","     BatchNorm2d-282         [-1, 1024, 32, 32]           2,048\n","            ReLU-283         [-1, 1024, 32, 32]               0\n","          Conv2d-284         [-1, 1024, 32, 32]         294,912\n","     BatchNorm2d-285         [-1, 1024, 32, 32]           2,048\n","            ReLU-286         [-1, 1024, 32, 32]               0\n","          Conv2d-287         [-1, 1024, 32, 32]       1,048,576\n","     BatchNorm2d-288         [-1, 1024, 32, 32]           2,048\n","            ReLU-289         [-1, 1024, 32, 32]               0\n","      Bottleneck-290         [-1, 1024, 32, 32]               0\n","          Conv2d-291         [-1, 1024, 32, 32]       1,048,576\n","     BatchNorm2d-292         [-1, 1024, 32, 32]           2,048\n","            ReLU-293         [-1, 1024, 32, 32]               0\n","          Conv2d-294         [-1, 1024, 32, 32]         294,912\n","     BatchNorm2d-295         [-1, 1024, 32, 32]           2,048\n","            ReLU-296         [-1, 1024, 32, 32]               0\n","          Conv2d-297         [-1, 1024, 32, 32]       1,048,576\n","     BatchNorm2d-298         [-1, 1024, 32, 32]           2,048\n","            ReLU-299         [-1, 1024, 32, 32]               0\n","      Bottleneck-300         [-1, 1024, 32, 32]               0\n","          Conv2d-301         [-1, 1024, 32, 32]       1,048,576\n","     BatchNorm2d-302         [-1, 1024, 32, 32]           2,048\n","            ReLU-303         [-1, 1024, 32, 32]               0\n","          Conv2d-304         [-1, 1024, 32, 32]         294,912\n","     BatchNorm2d-305         [-1, 1024, 32, 32]           2,048\n","            ReLU-306         [-1, 1024, 32, 32]               0\n","          Conv2d-307         [-1, 1024, 32, 32]       1,048,576\n","     BatchNorm2d-308         [-1, 1024, 32, 32]           2,048\n","            ReLU-309         [-1, 1024, 32, 32]               0\n","      Bottleneck-310         [-1, 1024, 32, 32]               0\n","          Conv2d-311         [-1, 2048, 32, 32]       2,097,152\n","     BatchNorm2d-312         [-1, 2048, 32, 32]           4,096\n","            ReLU-313         [-1, 2048, 32, 32]               0\n","          Conv2d-314         [-1, 2048, 16, 16]       1,179,648\n","     BatchNorm2d-315         [-1, 2048, 16, 16]           4,096\n","            ReLU-316         [-1, 2048, 16, 16]               0\n","          Conv2d-317         [-1, 2048, 16, 16]       4,194,304\n","     BatchNorm2d-318         [-1, 2048, 16, 16]           4,096\n","          Conv2d-319         [-1, 2048, 16, 16]       2,097,152\n","     BatchNorm2d-320         [-1, 2048, 16, 16]           4,096\n","            ReLU-321         [-1, 2048, 16, 16]               0\n","      Bottleneck-322         [-1, 2048, 16, 16]               0\n","          Conv2d-323         [-1, 2048, 16, 16]       4,194,304\n","     BatchNorm2d-324         [-1, 2048, 16, 16]           4,096\n","            ReLU-325         [-1, 2048, 16, 16]               0\n","          Conv2d-326         [-1, 2048, 16, 16]       1,179,648\n","     BatchNorm2d-327         [-1, 2048, 16, 16]           4,096\n","            ReLU-328         [-1, 2048, 16, 16]               0\n","          Conv2d-329         [-1, 2048, 16, 16]       4,194,304\n","     BatchNorm2d-330         [-1, 2048, 16, 16]           4,096\n","            ReLU-331         [-1, 2048, 16, 16]               0\n","      Bottleneck-332         [-1, 2048, 16, 16]               0\n","          Conv2d-333         [-1, 2048, 16, 16]       4,194,304\n","     BatchNorm2d-334         [-1, 2048, 16, 16]           4,096\n","            ReLU-335         [-1, 2048, 16, 16]               0\n","          Conv2d-336         [-1, 2048, 16, 16]       1,179,648\n","     BatchNorm2d-337         [-1, 2048, 16, 16]           4,096\n","            ReLU-338         [-1, 2048, 16, 16]               0\n","          Conv2d-339         [-1, 2048, 16, 16]       4,194,304\n","     BatchNorm2d-340         [-1, 2048, 16, 16]           4,096\n","            ReLU-341         [-1, 2048, 16, 16]               0\n","      Bottleneck-342         [-1, 2048, 16, 16]               0\n","          Conv2d-343        [-1, 256, 128, 128]         589,824\n","          Conv2d-344          [-1, 256, 64, 64]       1,179,648\n","          Conv2d-345          [-1, 256, 32, 32]       2,359,296\n","          Conv2d-346          [-1, 256, 16, 16]       4,718,592\n","            ReLU-347          [-1, 256, 16, 16]               0\n","          Conv2d-348          [-1, 256, 16, 16]         590,080\n","            ReLU-349          [-1, 256, 16, 16]               0\n","          Conv2d-350          [-1, 256, 16, 16]         590,080\n","ResidualConvUnit-351          [-1, 256, 16, 16]               0\n","FeatureFusionBlock-352          [-1, 256, 32, 32]               0\n","            ReLU-353          [-1, 256, 32, 32]               0\n","          Conv2d-354          [-1, 256, 32, 32]         590,080\n","            ReLU-355          [-1, 256, 32, 32]               0\n","          Conv2d-356          [-1, 256, 32, 32]         590,080\n","ResidualConvUnit-357          [-1, 256, 32, 32]               0\n","            ReLU-358          [-1, 256, 32, 32]               0\n","          Conv2d-359          [-1, 256, 32, 32]         590,080\n","            ReLU-360          [-1, 256, 32, 32]               0\n","          Conv2d-361          [-1, 256, 32, 32]         590,080\n","ResidualConvUnit-362          [-1, 256, 32, 32]               0\n","FeatureFusionBlock-363          [-1, 256, 64, 64]               0\n","            ReLU-364          [-1, 256, 64, 64]               0\n","          Conv2d-365          [-1, 256, 64, 64]         590,080\n","            ReLU-366          [-1, 256, 64, 64]               0\n","          Conv2d-367          [-1, 256, 64, 64]         590,080\n","ResidualConvUnit-368          [-1, 256, 64, 64]               0\n","            ReLU-369          [-1, 256, 64, 64]               0\n","          Conv2d-370          [-1, 256, 64, 64]         590,080\n","            ReLU-371          [-1, 256, 64, 64]               0\n","          Conv2d-372          [-1, 256, 64, 64]         590,080\n","ResidualConvUnit-373          [-1, 256, 64, 64]               0\n","FeatureFusionBlock-374        [-1, 256, 128, 128]               0\n","            ReLU-375        [-1, 256, 128, 128]               0\n","          Conv2d-376        [-1, 256, 128, 128]         590,080\n","            ReLU-377        [-1, 256, 128, 128]               0\n","          Conv2d-378        [-1, 256, 128, 128]         590,080\n","ResidualConvUnit-379        [-1, 256, 128, 128]               0\n","            ReLU-380        [-1, 256, 128, 128]               0\n","          Conv2d-381        [-1, 256, 128, 128]         590,080\n","            ReLU-382        [-1, 256, 128, 128]               0\n","          Conv2d-383        [-1, 256, 128, 128]         590,080\n","ResidualConvUnit-384        [-1, 256, 128, 128]               0\n","FeatureFusionBlock-385        [-1, 256, 256, 256]               0\n","          Conv2d-386        [-1, 128, 256, 256]         295,040\n","     Interpolate-387        [-1, 128, 512, 512]               0\n","          Conv2d-388         [-1, 32, 512, 512]          36,896\n","            ReLU-389         [-1, 32, 512, 512]               0\n","          Conv2d-390          [-1, 1, 512, 512]              33\n","            ReLU-391          [-1, 1, 512, 512]               0\n","          Conv2d-392        [-1, 256, 256, 256]           6,912\n","     BatchNorm2d-393        [-1, 256, 256, 256]             512\n","            ReLU-394        [-1, 256, 256, 256]               0\n","          Conv2d-395        [-1, 256, 128, 128]         589,824\n","     BatchNorm2d-396        [-1, 256, 128, 128]             512\n","            ReLU-397        [-1, 256, 128, 128]               0\n","          Conv2d-398          [-1, 256, 64, 64]         589,824\n","     BatchNorm2d-399          [-1, 256, 64, 64]             512\n","            ReLU-400          [-1, 256, 64, 64]               0\n","          Conv2d-401          [-1, 512, 32, 32]       1,179,648\n","     BatchNorm2d-402          [-1, 512, 32, 32]           1,024\n","            ReLU-403          [-1, 512, 32, 32]               0\n","          Conv2d-404         [-1, 1024, 16, 16]       4,718,592\n","     BatchNorm2d-405         [-1, 1024, 16, 16]           2,048\n","            ReLU-406         [-1, 1024, 16, 16]               0\n","          Conv2d-407         [-1, 1024, 16, 16]       2,097,152\n","     BatchNorm2d-408         [-1, 1024, 16, 16]           2,048\n","            ReLU-409         [-1, 1024, 16, 16]               0\n","          Conv2d-410           [-1, 27, 16, 16]          27,675\n","       YOLOLayer-411         [-1, 3, 16, 16, 9]               0\n","     Interpolate-412         [-1, 1024, 32, 32]               0\n","          Conv2d-413          [-1, 256, 32, 32]         262,144\n","     BatchNorm2d-414          [-1, 256, 32, 32]             512\n","            ReLU-415          [-1, 256, 32, 32]               0\n","          Conv2d-416          [-1, 512, 32, 32]         524,288\n","     BatchNorm2d-417          [-1, 512, 32, 32]           1,024\n","            ReLU-418          [-1, 512, 32, 32]               0\n","          Conv2d-419          [-1, 256, 32, 32]         196,608\n","     BatchNorm2d-420          [-1, 256, 32, 32]             512\n","            ReLU-421          [-1, 256, 32, 32]               0\n","          Conv2d-422          [-1, 512, 32, 32]       1,179,648\n","     BatchNorm2d-423          [-1, 512, 32, 32]           1,024\n","            ReLU-424          [-1, 512, 32, 32]               0\n","          Conv2d-425          [-1, 256, 32, 32]         131,072\n","     BatchNorm2d-426          [-1, 256, 32, 32]             512\n","            ReLU-427          [-1, 256, 32, 32]               0\n","          Conv2d-428          [-1, 512, 32, 32]       1,179,648\n","     BatchNorm2d-429          [-1, 512, 32, 32]           1,024\n","            ReLU-430          [-1, 512, 32, 32]               0\n","          Conv2d-431          [-1, 256, 32, 32]         131,072\n","     BatchNorm2d-432          [-1, 256, 32, 32]             512\n","            ReLU-433          [-1, 256, 32, 32]               0\n","          Conv2d-434          [-1, 512, 32, 32]       1,179,648\n","     BatchNorm2d-435          [-1, 512, 32, 32]           1,024\n","            ReLU-436          [-1, 512, 32, 32]               0\n","          Conv2d-437           [-1, 27, 32, 32]          13,851\n","       YOLOLayer-438         [-1, 3, 32, 32, 9]               0\n","          Conv2d-439          [-1, 256, 64, 64]         131,072\n","     BatchNorm2d-440          [-1, 256, 64, 64]             512\n","            ReLU-441          [-1, 256, 64, 64]               0\n","     Interpolate-442          [-1, 512, 64, 64]               0\n","          Conv2d-443          [-1, 128, 64, 64]          65,536\n","     BatchNorm2d-444          [-1, 128, 64, 64]             256\n","            ReLU-445          [-1, 128, 64, 64]               0\n","          Conv2d-446          [-1, 128, 64, 64]          49,152\n","     BatchNorm2d-447          [-1, 128, 64, 64]             256\n","            ReLU-448          [-1, 128, 64, 64]               0\n","          Conv2d-449          [-1, 256, 64, 64]         294,912\n","     BatchNorm2d-450          [-1, 256, 64, 64]             512\n","            ReLU-451          [-1, 256, 64, 64]               0\n","          Conv2d-452          [-1, 128, 64, 64]          32,768\n","     BatchNorm2d-453          [-1, 128, 64, 64]             256\n","            ReLU-454          [-1, 128, 64, 64]               0\n","          Conv2d-455          [-1, 256, 64, 64]         294,912\n","     BatchNorm2d-456          [-1, 256, 64, 64]             512\n","            ReLU-457          [-1, 256, 64, 64]               0\n","          Conv2d-458          [-1, 128, 64, 64]          32,768\n","     BatchNorm2d-459          [-1, 128, 64, 64]             256\n","            ReLU-460          [-1, 128, 64, 64]               0\n","          Conv2d-461          [-1, 256, 64, 64]         294,912\n","     BatchNorm2d-462          [-1, 256, 64, 64]             512\n","            ReLU-463          [-1, 256, 64, 64]               0\n","          Conv2d-464           [-1, 27, 64, 64]           6,939\n","       YOLOLayer-465         [-1, 3, 64, 64, 9]               0\n","================================================================\n","Total params: 119,409,234\n","Trainable params: 15,226,449\n","Non-trainable params: 104,182,785\n","----------------------------------------------------------------\n","Input size (MB): 3.00\n","Forward/backward pass size (MB): 5893.21\n","Params size (MB): 455.51\n","Estimated Total Size (MB): 6351.72\n","----------------------------------------------------------------\n","Image sizes 512 - 512 train, 512 test\n","Using 4 dataloader workers\n","Starting training for 300 epochs...\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","  0% 0/346 [00:00<?, ?it/s]/usr/local/lib/python3.6/dist-packages/torch/cuda/memory.py:346: FutureWarning: torch.cuda.memory_cached has been renamed to torch.cuda.memory_reserved\n","  FutureWarning)\n","   176/299     5.09G      4.15      1.08     0.406      5.64        60       512: 100% 346/346 [04:45<00:00,  1.21it/s]\n","               Class    Images   Targets         P         R   mAP@0.5        F1:   0% 0/87 [00:00<?, ?it/s]/content/drive/My Drive/computer_vision/capstone_project/yolo_v3/utils/utils.py:544: UserWarning: This overload of nonzero is deprecated:\n","\tnonzero()\n","Consider using one of the following signatures instead:\n","\tnonzero(*, bool as_tuple) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:882.)\n","  anchors = anchors.to(device=targets.device)\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 87/87 [00:56<00:00,  1.54it/s]\n","                 all       692  3.06e+03      0.25     0.589     0.359     0.351\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","  0% 0/346 [00:00<?, ?it/s]/usr/local/lib/python3.6/dist-packages/torch/cuda/memory.py:346: FutureWarning: torch.cuda.memory_cached has been renamed to torch.cuda.memory_reserved\n","  FutureWarning)\n","   177/299     5.09G      4.15      1.07     0.385       5.6        50       512: 100% 346/346 [04:45<00:00,  1.21it/s]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 87/87 [00:54<00:00,  1.60it/s]\n","                 all       692  3.06e+03     0.252     0.593     0.358     0.353\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","   178/299     5.09G       4.3      1.08     0.458      5.83        31       512: 100% 346/346 [04:45<00:00,  1.21it/s]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 87/87 [00:54<00:00,  1.60it/s]\n","                 all       692  3.06e+03     0.252     0.591     0.349     0.353\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","   179/299     5.09G       4.3      1.08     0.481      5.86        25       512: 100% 346/346 [04:45<00:00,  1.21it/s]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 87/87 [00:54<00:00,  1.60it/s]\n","                 all       692  3.06e+03     0.257     0.591     0.343     0.357\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","   180/299     5.09G       4.3      1.06     0.477      5.84        42       512: 100% 346/346 [04:45<00:00,  1.21it/s]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 87/87 [00:54<00:00,  1.61it/s]\n","                 all       692  3.06e+03     0.254     0.585     0.344     0.354\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","   181/299     5.09G      4.29       1.1     0.478      5.87        40       512: 100% 346/346 [04:46<00:00,  1.21it/s]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 87/87 [00:54<00:00,  1.61it/s]\n","                 all       692  3.06e+03     0.256     0.589     0.362     0.356\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","   182/299     5.09G       4.3      1.08     0.491      5.87        34       512: 100% 346/346 [04:45<00:00,  1.21it/s]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 87/87 [00:54<00:00,  1.61it/s]\n","                 all       692  3.06e+03     0.243     0.581     0.337     0.342\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","   183/299     5.09G      4.27      1.08     0.488      5.83        48       512:  77% 266/346 [03:39<01:05,  1.22it/s]"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"c2kBemqIxbYA","colab":{"base_uri":"https://localhost:8080/"},"outputId":"a9781105-d08d-433d-fe00-bc1b7716d23c"},"source":["!md5sum weights/best.pt\n","!md5sum weights/last_best_diwali_2am.pt\n","!md5sum weights/last.pt"],"execution_count":null,"outputs":[{"output_type":"stream","text":["4d111871c26592ce86197c2d04fa5087  weights/best.pt\n","4d111871c26592ce86197c2d04fa5087  weights/last_best_diwali_2am.pt\n","741f479c7f18431ba15649b7cf6b8ecc  weights/last.pt\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gbu1Jf2FUBO6","outputId":"7d60a26d-f749-46fa-ec88-0b9c3fbf3914"},"source":["!python train.py --data data/customdata/custom_test.data --batch 8  --cache --cfg cfg/yolov3-custom.cfg --epochs 300 --weights 'weights/best.pt'  --img-size=448 --midasnet_freeze='False'"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Namespace(accumulate=4, adam=False, batch_size=8, bbox_lambda=1, bucket='', cache_images=True, cfg='cfg/yolov3-custom.cfg', data='data/customdata/custom_test.data', depth_lambda=1, device='', epochs=300, evolve=False, img_size=[448], init_train='False', midas_weights='', midasnet_freeze='False', multi_scale=False, name='', nosave=False, notest=False, rect=False, resume=False, single_cls=False, weights='weights/best.pt', yolo_weights='')\n","Using CUDA device0 _CudaDeviceProperties(name='Tesla V100-SXM2-16GB', total_memory=16130MB)\n","\n","2020-11-18 13:48:54.316535: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n","Run 'tensorboard --logdir=runs' to view tensorboard at http://localhost:6006/\n","cfg - cfg/yolov3-custom.cfg\n","data - data/customdata/custom_test.data\n","epochs - 300\n","batch_size - 8\n","accumulate - 4\n","yolo weights - \n","midas weights - \n","imgsz_min- 448, imgsz_max- 448, imgsz_test- 448\n","opt.rect - False\n","train_path - data/customdata/custom_train.txt\n","test_path - data/customdata/custom_test.txt\n","init_train - False\n","weights - weights/best.pt\n","midasnet_freeze - False\n","mixed_precision enabled - False\n","Using cache found in /root/.cache/torch/hub/facebookresearch_WSL-Images_master\n","Caching labels (18 found, 1 missing, 0 empty, 0 duplicate, for 19 images): 100% 19/19 [00:00<00:00, 823.61it/s]\n","Caching images (0.0GB): 100% 19/19 [00:00<00:00, 19.67it/s]\n","Caching labels (13 found, 1 missing, 0 empty, 0 duplicate, for 14 images): 100% 14/14 [00:00<00:00, 645.31it/s]\n","Caching images (0.0GB): 100% 14/14 [00:00<00:00, 19.41it/s]\n","YMP Model Summary\n","----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","            Conv2d-1         [-1, 64, 224, 224]           9,408\n","       BatchNorm2d-2         [-1, 64, 224, 224]             128\n","              ReLU-3         [-1, 64, 224, 224]               0\n","         MaxPool2d-4         [-1, 64, 112, 112]               0\n","            Conv2d-5        [-1, 256, 112, 112]          16,384\n","       BatchNorm2d-6        [-1, 256, 112, 112]             512\n","              ReLU-7        [-1, 256, 112, 112]               0\n","            Conv2d-8        [-1, 256, 112, 112]          18,432\n","       BatchNorm2d-9        [-1, 256, 112, 112]             512\n","             ReLU-10        [-1, 256, 112, 112]               0\n","           Conv2d-11        [-1, 256, 112, 112]          65,536\n","      BatchNorm2d-12        [-1, 256, 112, 112]             512\n","           Conv2d-13        [-1, 256, 112, 112]          16,384\n","      BatchNorm2d-14        [-1, 256, 112, 112]             512\n","             ReLU-15        [-1, 256, 112, 112]               0\n","       Bottleneck-16        [-1, 256, 112, 112]               0\n","           Conv2d-17        [-1, 256, 112, 112]          65,536\n","      BatchNorm2d-18        [-1, 256, 112, 112]             512\n","             ReLU-19        [-1, 256, 112, 112]               0\n","           Conv2d-20        [-1, 256, 112, 112]          18,432\n","      BatchNorm2d-21        [-1, 256, 112, 112]             512\n","             ReLU-22        [-1, 256, 112, 112]               0\n","           Conv2d-23        [-1, 256, 112, 112]          65,536\n","      BatchNorm2d-24        [-1, 256, 112, 112]             512\n","             ReLU-25        [-1, 256, 112, 112]               0\n","       Bottleneck-26        [-1, 256, 112, 112]               0\n","           Conv2d-27        [-1, 256, 112, 112]          65,536\n","      BatchNorm2d-28        [-1, 256, 112, 112]             512\n","             ReLU-29        [-1, 256, 112, 112]               0\n","           Conv2d-30        [-1, 256, 112, 112]          18,432\n","      BatchNorm2d-31        [-1, 256, 112, 112]             512\n","             ReLU-32        [-1, 256, 112, 112]               0\n","           Conv2d-33        [-1, 256, 112, 112]          65,536\n","      BatchNorm2d-34        [-1, 256, 112, 112]             512\n","             ReLU-35        [-1, 256, 112, 112]               0\n","       Bottleneck-36        [-1, 256, 112, 112]               0\n","           Conv2d-37        [-1, 512, 112, 112]         131,072\n","      BatchNorm2d-38        [-1, 512, 112, 112]           1,024\n","             ReLU-39        [-1, 512, 112, 112]               0\n","           Conv2d-40          [-1, 512, 56, 56]          73,728\n","      BatchNorm2d-41          [-1, 512, 56, 56]           1,024\n","             ReLU-42          [-1, 512, 56, 56]               0\n","           Conv2d-43          [-1, 512, 56, 56]         262,144\n","      BatchNorm2d-44          [-1, 512, 56, 56]           1,024\n","           Conv2d-45          [-1, 512, 56, 56]         131,072\n","      BatchNorm2d-46          [-1, 512, 56, 56]           1,024\n","             ReLU-47          [-1, 512, 56, 56]               0\n","       Bottleneck-48          [-1, 512, 56, 56]               0\n","           Conv2d-49          [-1, 512, 56, 56]         262,144\n","      BatchNorm2d-50          [-1, 512, 56, 56]           1,024\n","             ReLU-51          [-1, 512, 56, 56]               0\n","           Conv2d-52          [-1, 512, 56, 56]          73,728\n","      BatchNorm2d-53          [-1, 512, 56, 56]           1,024\n","             ReLU-54          [-1, 512, 56, 56]               0\n","           Conv2d-55          [-1, 512, 56, 56]         262,144\n","      BatchNorm2d-56          [-1, 512, 56, 56]           1,024\n","             ReLU-57          [-1, 512, 56, 56]               0\n","       Bottleneck-58          [-1, 512, 56, 56]               0\n","           Conv2d-59          [-1, 512, 56, 56]         262,144\n","      BatchNorm2d-60          [-1, 512, 56, 56]           1,024\n","             ReLU-61          [-1, 512, 56, 56]               0\n","           Conv2d-62          [-1, 512, 56, 56]          73,728\n","      BatchNorm2d-63          [-1, 512, 56, 56]           1,024\n","             ReLU-64          [-1, 512, 56, 56]               0\n","           Conv2d-65          [-1, 512, 56, 56]         262,144\n","      BatchNorm2d-66          [-1, 512, 56, 56]           1,024\n","             ReLU-67          [-1, 512, 56, 56]               0\n","       Bottleneck-68          [-1, 512, 56, 56]               0\n","           Conv2d-69          [-1, 512, 56, 56]         262,144\n","      BatchNorm2d-70          [-1, 512, 56, 56]           1,024\n","             ReLU-71          [-1, 512, 56, 56]               0\n","           Conv2d-72          [-1, 512, 56, 56]          73,728\n","      BatchNorm2d-73          [-1, 512, 56, 56]           1,024\n","             ReLU-74          [-1, 512, 56, 56]               0\n","           Conv2d-75          [-1, 512, 56, 56]         262,144\n","      BatchNorm2d-76          [-1, 512, 56, 56]           1,024\n","             ReLU-77          [-1, 512, 56, 56]               0\n","       Bottleneck-78          [-1, 512, 56, 56]               0\n","           Conv2d-79         [-1, 1024, 56, 56]         524,288\n","      BatchNorm2d-80         [-1, 1024, 56, 56]           2,048\n","             ReLU-81         [-1, 1024, 56, 56]               0\n","           Conv2d-82         [-1, 1024, 28, 28]         294,912\n","      BatchNorm2d-83         [-1, 1024, 28, 28]           2,048\n","             ReLU-84         [-1, 1024, 28, 28]               0\n","           Conv2d-85         [-1, 1024, 28, 28]       1,048,576\n","      BatchNorm2d-86         [-1, 1024, 28, 28]           2,048\n","           Conv2d-87         [-1, 1024, 28, 28]         524,288\n","      BatchNorm2d-88         [-1, 1024, 28, 28]           2,048\n","             ReLU-89         [-1, 1024, 28, 28]               0\n","       Bottleneck-90         [-1, 1024, 28, 28]               0\n","           Conv2d-91         [-1, 1024, 28, 28]       1,048,576\n","      BatchNorm2d-92         [-1, 1024, 28, 28]           2,048\n","             ReLU-93         [-1, 1024, 28, 28]               0\n","           Conv2d-94         [-1, 1024, 28, 28]         294,912\n","      BatchNorm2d-95         [-1, 1024, 28, 28]           2,048\n","             ReLU-96         [-1, 1024, 28, 28]               0\n","           Conv2d-97         [-1, 1024, 28, 28]       1,048,576\n","      BatchNorm2d-98         [-1, 1024, 28, 28]           2,048\n","             ReLU-99         [-1, 1024, 28, 28]               0\n","      Bottleneck-100         [-1, 1024, 28, 28]               0\n","          Conv2d-101         [-1, 1024, 28, 28]       1,048,576\n","     BatchNorm2d-102         [-1, 1024, 28, 28]           2,048\n","            ReLU-103         [-1, 1024, 28, 28]               0\n","          Conv2d-104         [-1, 1024, 28, 28]         294,912\n","     BatchNorm2d-105         [-1, 1024, 28, 28]           2,048\n","            ReLU-106         [-1, 1024, 28, 28]               0\n","          Conv2d-107         [-1, 1024, 28, 28]       1,048,576\n","     BatchNorm2d-108         [-1, 1024, 28, 28]           2,048\n","            ReLU-109         [-1, 1024, 28, 28]               0\n","      Bottleneck-110         [-1, 1024, 28, 28]               0\n","          Conv2d-111         [-1, 1024, 28, 28]       1,048,576\n","     BatchNorm2d-112         [-1, 1024, 28, 28]           2,048\n","            ReLU-113         [-1, 1024, 28, 28]               0\n","          Conv2d-114         [-1, 1024, 28, 28]         294,912\n","     BatchNorm2d-115         [-1, 1024, 28, 28]           2,048\n","            ReLU-116         [-1, 1024, 28, 28]               0\n","          Conv2d-117         [-1, 1024, 28, 28]       1,048,576\n","     BatchNorm2d-118         [-1, 1024, 28, 28]           2,048\n","            ReLU-119         [-1, 1024, 28, 28]               0\n","      Bottleneck-120         [-1, 1024, 28, 28]               0\n","          Conv2d-121         [-1, 1024, 28, 28]       1,048,576\n","     BatchNorm2d-122         [-1, 1024, 28, 28]           2,048\n","            ReLU-123         [-1, 1024, 28, 28]               0\n","          Conv2d-124         [-1, 1024, 28, 28]         294,912\n","     BatchNorm2d-125         [-1, 1024, 28, 28]           2,048\n","            ReLU-126         [-1, 1024, 28, 28]               0\n","          Conv2d-127         [-1, 1024, 28, 28]       1,048,576\n","     BatchNorm2d-128         [-1, 1024, 28, 28]           2,048\n","            ReLU-129         [-1, 1024, 28, 28]               0\n","      Bottleneck-130         [-1, 1024, 28, 28]               0\n","          Conv2d-131         [-1, 1024, 28, 28]       1,048,576\n","     BatchNorm2d-132         [-1, 1024, 28, 28]           2,048\n","            ReLU-133         [-1, 1024, 28, 28]               0\n","          Conv2d-134         [-1, 1024, 28, 28]         294,912\n","     BatchNorm2d-135         [-1, 1024, 28, 28]           2,048\n","            ReLU-136         [-1, 1024, 28, 28]               0\n","          Conv2d-137         [-1, 1024, 28, 28]       1,048,576\n","     BatchNorm2d-138         [-1, 1024, 28, 28]           2,048\n","            ReLU-139         [-1, 1024, 28, 28]               0\n","      Bottleneck-140         [-1, 1024, 28, 28]               0\n","          Conv2d-141         [-1, 1024, 28, 28]       1,048,576\n","     BatchNorm2d-142         [-1, 1024, 28, 28]           2,048\n","            ReLU-143         [-1, 1024, 28, 28]               0\n","          Conv2d-144         [-1, 1024, 28, 28]         294,912\n","     BatchNorm2d-145         [-1, 1024, 28, 28]           2,048\n","            ReLU-146         [-1, 1024, 28, 28]               0\n","          Conv2d-147         [-1, 1024, 28, 28]       1,048,576\n","     BatchNorm2d-148         [-1, 1024, 28, 28]           2,048\n","            ReLU-149         [-1, 1024, 28, 28]               0\n","      Bottleneck-150         [-1, 1024, 28, 28]               0\n","          Conv2d-151         [-1, 1024, 28, 28]       1,048,576\n","     BatchNorm2d-152         [-1, 1024, 28, 28]           2,048\n","            ReLU-153         [-1, 1024, 28, 28]               0\n","          Conv2d-154         [-1, 1024, 28, 28]         294,912\n","     BatchNorm2d-155         [-1, 1024, 28, 28]           2,048\n","            ReLU-156         [-1, 1024, 28, 28]               0\n","          Conv2d-157         [-1, 1024, 28, 28]       1,048,576\n","     BatchNorm2d-158         [-1, 1024, 28, 28]           2,048\n","            ReLU-159         [-1, 1024, 28, 28]               0\n","      Bottleneck-160         [-1, 1024, 28, 28]               0\n","          Conv2d-161         [-1, 1024, 28, 28]       1,048,576\n","     BatchNorm2d-162         [-1, 1024, 28, 28]           2,048\n","            ReLU-163         [-1, 1024, 28, 28]               0\n","          Conv2d-164         [-1, 1024, 28, 28]         294,912\n","     BatchNorm2d-165         [-1, 1024, 28, 28]           2,048\n","            ReLU-166         [-1, 1024, 28, 28]               0\n","          Conv2d-167         [-1, 1024, 28, 28]       1,048,576\n","     BatchNorm2d-168         [-1, 1024, 28, 28]           2,048\n","            ReLU-169         [-1, 1024, 28, 28]               0\n","      Bottleneck-170         [-1, 1024, 28, 28]               0\n","          Conv2d-171         [-1, 1024, 28, 28]       1,048,576\n","     BatchNorm2d-172         [-1, 1024, 28, 28]           2,048\n","            ReLU-173         [-1, 1024, 28, 28]               0\n","          Conv2d-174         [-1, 1024, 28, 28]         294,912\n","     BatchNorm2d-175         [-1, 1024, 28, 28]           2,048\n","            ReLU-176         [-1, 1024, 28, 28]               0\n","          Conv2d-177         [-1, 1024, 28, 28]       1,048,576\n","     BatchNorm2d-178         [-1, 1024, 28, 28]           2,048\n","            ReLU-179         [-1, 1024, 28, 28]               0\n","      Bottleneck-180         [-1, 1024, 28, 28]               0\n","          Conv2d-181         [-1, 1024, 28, 28]       1,048,576\n","     BatchNorm2d-182         [-1, 1024, 28, 28]           2,048\n","            ReLU-183         [-1, 1024, 28, 28]               0\n","          Conv2d-184         [-1, 1024, 28, 28]         294,912\n","     BatchNorm2d-185         [-1, 1024, 28, 28]           2,048\n","            ReLU-186         [-1, 1024, 28, 28]               0\n","          Conv2d-187         [-1, 1024, 28, 28]       1,048,576\n","     BatchNorm2d-188         [-1, 1024, 28, 28]           2,048\n","            ReLU-189         [-1, 1024, 28, 28]               0\n","      Bottleneck-190         [-1, 1024, 28, 28]               0\n","          Conv2d-191         [-1, 1024, 28, 28]       1,048,576\n","     BatchNorm2d-192         [-1, 1024, 28, 28]           2,048\n","            ReLU-193         [-1, 1024, 28, 28]               0\n","          Conv2d-194         [-1, 1024, 28, 28]         294,912\n","     BatchNorm2d-195         [-1, 1024, 28, 28]           2,048\n","            ReLU-196         [-1, 1024, 28, 28]               0\n","          Conv2d-197         [-1, 1024, 28, 28]       1,048,576\n","     BatchNorm2d-198         [-1, 1024, 28, 28]           2,048\n","            ReLU-199         [-1, 1024, 28, 28]               0\n","      Bottleneck-200         [-1, 1024, 28, 28]               0\n","          Conv2d-201         [-1, 1024, 28, 28]       1,048,576\n","     BatchNorm2d-202         [-1, 1024, 28, 28]           2,048\n","            ReLU-203         [-1, 1024, 28, 28]               0\n","          Conv2d-204         [-1, 1024, 28, 28]         294,912\n","     BatchNorm2d-205         [-1, 1024, 28, 28]           2,048\n","            ReLU-206         [-1, 1024, 28, 28]               0\n","          Conv2d-207         [-1, 1024, 28, 28]       1,048,576\n","     BatchNorm2d-208         [-1, 1024, 28, 28]           2,048\n","            ReLU-209         [-1, 1024, 28, 28]               0\n","      Bottleneck-210         [-1, 1024, 28, 28]               0\n","          Conv2d-211         [-1, 1024, 28, 28]       1,048,576\n","     BatchNorm2d-212         [-1, 1024, 28, 28]           2,048\n","            ReLU-213         [-1, 1024, 28, 28]               0\n","          Conv2d-214         [-1, 1024, 28, 28]         294,912\n","     BatchNorm2d-215         [-1, 1024, 28, 28]           2,048\n","            ReLU-216         [-1, 1024, 28, 28]               0\n","          Conv2d-217         [-1, 1024, 28, 28]       1,048,576\n","     BatchNorm2d-218         [-1, 1024, 28, 28]           2,048\n","            ReLU-219         [-1, 1024, 28, 28]               0\n","      Bottleneck-220         [-1, 1024, 28, 28]               0\n","          Conv2d-221         [-1, 1024, 28, 28]       1,048,576\n","     BatchNorm2d-222         [-1, 1024, 28, 28]           2,048\n","            ReLU-223         [-1, 1024, 28, 28]               0\n","          Conv2d-224         [-1, 1024, 28, 28]         294,912\n","     BatchNorm2d-225         [-1, 1024, 28, 28]           2,048\n","            ReLU-226         [-1, 1024, 28, 28]               0\n","          Conv2d-227         [-1, 1024, 28, 28]       1,048,576\n","     BatchNorm2d-228         [-1, 1024, 28, 28]           2,048\n","            ReLU-229         [-1, 1024, 28, 28]               0\n","      Bottleneck-230         [-1, 1024, 28, 28]               0\n","          Conv2d-231         [-1, 1024, 28, 28]       1,048,576\n","     BatchNorm2d-232         [-1, 1024, 28, 28]           2,048\n","            ReLU-233         [-1, 1024, 28, 28]               0\n","          Conv2d-234         [-1, 1024, 28, 28]         294,912\n","     BatchNorm2d-235         [-1, 1024, 28, 28]           2,048\n","            ReLU-236         [-1, 1024, 28, 28]               0\n","          Conv2d-237         [-1, 1024, 28, 28]       1,048,576\n","     BatchNorm2d-238         [-1, 1024, 28, 28]           2,048\n","            ReLU-239         [-1, 1024, 28, 28]               0\n","      Bottleneck-240         [-1, 1024, 28, 28]               0\n","          Conv2d-241         [-1, 1024, 28, 28]       1,048,576\n","     BatchNorm2d-242         [-1, 1024, 28, 28]           2,048\n","            ReLU-243         [-1, 1024, 28, 28]               0\n","          Conv2d-244         [-1, 1024, 28, 28]         294,912\n","     BatchNorm2d-245         [-1, 1024, 28, 28]           2,048\n","            ReLU-246         [-1, 1024, 28, 28]               0\n","          Conv2d-247         [-1, 1024, 28, 28]       1,048,576\n","     BatchNorm2d-248         [-1, 1024, 28, 28]           2,048\n","            ReLU-249         [-1, 1024, 28, 28]               0\n","      Bottleneck-250         [-1, 1024, 28, 28]               0\n","          Conv2d-251         [-1, 1024, 28, 28]       1,048,576\n","     BatchNorm2d-252         [-1, 1024, 28, 28]           2,048\n","            ReLU-253         [-1, 1024, 28, 28]               0\n","          Conv2d-254         [-1, 1024, 28, 28]         294,912\n","     BatchNorm2d-255         [-1, 1024, 28, 28]           2,048\n","            ReLU-256         [-1, 1024, 28, 28]               0\n","          Conv2d-257         [-1, 1024, 28, 28]       1,048,576\n","     BatchNorm2d-258         [-1, 1024, 28, 28]           2,048\n","            ReLU-259         [-1, 1024, 28, 28]               0\n","      Bottleneck-260         [-1, 1024, 28, 28]               0\n","          Conv2d-261         [-1, 1024, 28, 28]       1,048,576\n","     BatchNorm2d-262         [-1, 1024, 28, 28]           2,048\n","            ReLU-263         [-1, 1024, 28, 28]               0\n","          Conv2d-264         [-1, 1024, 28, 28]         294,912\n","     BatchNorm2d-265         [-1, 1024, 28, 28]           2,048\n","            ReLU-266         [-1, 1024, 28, 28]               0\n","          Conv2d-267         [-1, 1024, 28, 28]       1,048,576\n","     BatchNorm2d-268         [-1, 1024, 28, 28]           2,048\n","            ReLU-269         [-1, 1024, 28, 28]               0\n","      Bottleneck-270         [-1, 1024, 28, 28]               0\n","          Conv2d-271         [-1, 1024, 28, 28]       1,048,576\n","     BatchNorm2d-272         [-1, 1024, 28, 28]           2,048\n","            ReLU-273         [-1, 1024, 28, 28]               0\n","          Conv2d-274         [-1, 1024, 28, 28]         294,912\n","     BatchNorm2d-275         [-1, 1024, 28, 28]           2,048\n","            ReLU-276         [-1, 1024, 28, 28]               0\n","          Conv2d-277         [-1, 1024, 28, 28]       1,048,576\n","     BatchNorm2d-278         [-1, 1024, 28, 28]           2,048\n","            ReLU-279         [-1, 1024, 28, 28]               0\n","      Bottleneck-280         [-1, 1024, 28, 28]               0\n","          Conv2d-281         [-1, 1024, 28, 28]       1,048,576\n","     BatchNorm2d-282         [-1, 1024, 28, 28]           2,048\n","            ReLU-283         [-1, 1024, 28, 28]               0\n","          Conv2d-284         [-1, 1024, 28, 28]         294,912\n","     BatchNorm2d-285         [-1, 1024, 28, 28]           2,048\n","            ReLU-286         [-1, 1024, 28, 28]               0\n","          Conv2d-287         [-1, 1024, 28, 28]       1,048,576\n","     BatchNorm2d-288         [-1, 1024, 28, 28]           2,048\n","            ReLU-289         [-1, 1024, 28, 28]               0\n","      Bottleneck-290         [-1, 1024, 28, 28]               0\n","          Conv2d-291         [-1, 1024, 28, 28]       1,048,576\n","     BatchNorm2d-292         [-1, 1024, 28, 28]           2,048\n","            ReLU-293         [-1, 1024, 28, 28]               0\n","          Conv2d-294         [-1, 1024, 28, 28]         294,912\n","     BatchNorm2d-295         [-1, 1024, 28, 28]           2,048\n","            ReLU-296         [-1, 1024, 28, 28]               0\n","          Conv2d-297         [-1, 1024, 28, 28]       1,048,576\n","     BatchNorm2d-298         [-1, 1024, 28, 28]           2,048\n","            ReLU-299         [-1, 1024, 28, 28]               0\n","      Bottleneck-300         [-1, 1024, 28, 28]               0\n","          Conv2d-301         [-1, 1024, 28, 28]       1,048,576\n","     BatchNorm2d-302         [-1, 1024, 28, 28]           2,048\n","            ReLU-303         [-1, 1024, 28, 28]               0\n","          Conv2d-304         [-1, 1024, 28, 28]         294,912\n","     BatchNorm2d-305         [-1, 1024, 28, 28]           2,048\n","            ReLU-306         [-1, 1024, 28, 28]               0\n","          Conv2d-307         [-1, 1024, 28, 28]       1,048,576\n","     BatchNorm2d-308         [-1, 1024, 28, 28]           2,048\n","            ReLU-309         [-1, 1024, 28, 28]               0\n","      Bottleneck-310         [-1, 1024, 28, 28]               0\n","          Conv2d-311         [-1, 2048, 28, 28]       2,097,152\n","     BatchNorm2d-312         [-1, 2048, 28, 28]           4,096\n","            ReLU-313         [-1, 2048, 28, 28]               0\n","          Conv2d-314         [-1, 2048, 14, 14]       1,179,648\n","     BatchNorm2d-315         [-1, 2048, 14, 14]           4,096\n","            ReLU-316         [-1, 2048, 14, 14]               0\n","          Conv2d-317         [-1, 2048, 14, 14]       4,194,304\n","     BatchNorm2d-318         [-1, 2048, 14, 14]           4,096\n","          Conv2d-319         [-1, 2048, 14, 14]       2,097,152\n","     BatchNorm2d-320         [-1, 2048, 14, 14]           4,096\n","            ReLU-321         [-1, 2048, 14, 14]               0\n","      Bottleneck-322         [-1, 2048, 14, 14]               0\n","          Conv2d-323         [-1, 2048, 14, 14]       4,194,304\n","     BatchNorm2d-324         [-1, 2048, 14, 14]           4,096\n","            ReLU-325         [-1, 2048, 14, 14]               0\n","          Conv2d-326         [-1, 2048, 14, 14]       1,179,648\n","     BatchNorm2d-327         [-1, 2048, 14, 14]           4,096\n","            ReLU-328         [-1, 2048, 14, 14]               0\n","          Conv2d-329         [-1, 2048, 14, 14]       4,194,304\n","     BatchNorm2d-330         [-1, 2048, 14, 14]           4,096\n","            ReLU-331         [-1, 2048, 14, 14]               0\n","      Bottleneck-332         [-1, 2048, 14, 14]               0\n","          Conv2d-333         [-1, 2048, 14, 14]       4,194,304\n","     BatchNorm2d-334         [-1, 2048, 14, 14]           4,096\n","            ReLU-335         [-1, 2048, 14, 14]               0\n","          Conv2d-336         [-1, 2048, 14, 14]       1,179,648\n","     BatchNorm2d-337         [-1, 2048, 14, 14]           4,096\n","            ReLU-338         [-1, 2048, 14, 14]               0\n","          Conv2d-339         [-1, 2048, 14, 14]       4,194,304\n","     BatchNorm2d-340         [-1, 2048, 14, 14]           4,096\n","            ReLU-341         [-1, 2048, 14, 14]               0\n","      Bottleneck-342         [-1, 2048, 14, 14]               0\n","          Conv2d-343        [-1, 256, 112, 112]         589,824\n","          Conv2d-344          [-1, 256, 56, 56]       1,179,648\n","          Conv2d-345          [-1, 256, 28, 28]       2,359,296\n","          Conv2d-346          [-1, 256, 14, 14]       4,718,592\n","            ReLU-347          [-1, 256, 14, 14]               0\n","          Conv2d-348          [-1, 256, 14, 14]         590,080\n","            ReLU-349          [-1, 256, 14, 14]               0\n","          Conv2d-350          [-1, 256, 14, 14]         590,080\n","ResidualConvUnit-351          [-1, 256, 14, 14]               0\n","FeatureFusionBlock-352          [-1, 256, 28, 28]               0\n","            ReLU-353          [-1, 256, 28, 28]               0\n","          Conv2d-354          [-1, 256, 28, 28]         590,080\n","            ReLU-355          [-1, 256, 28, 28]               0\n","          Conv2d-356          [-1, 256, 28, 28]         590,080\n","ResidualConvUnit-357          [-1, 256, 28, 28]               0\n","            ReLU-358          [-1, 256, 28, 28]               0\n","          Conv2d-359          [-1, 256, 28, 28]         590,080\n","            ReLU-360          [-1, 256, 28, 28]               0\n","          Conv2d-361          [-1, 256, 28, 28]         590,080\n","ResidualConvUnit-362          [-1, 256, 28, 28]               0\n","FeatureFusionBlock-363          [-1, 256, 56, 56]               0\n","            ReLU-364          [-1, 256, 56, 56]               0\n","          Conv2d-365          [-1, 256, 56, 56]         590,080\n","            ReLU-366          [-1, 256, 56, 56]               0\n","          Conv2d-367          [-1, 256, 56, 56]         590,080\n","ResidualConvUnit-368          [-1, 256, 56, 56]               0\n","            ReLU-369          [-1, 256, 56, 56]               0\n","          Conv2d-370          [-1, 256, 56, 56]         590,080\n","            ReLU-371          [-1, 256, 56, 56]               0\n","          Conv2d-372          [-1, 256, 56, 56]         590,080\n","ResidualConvUnit-373          [-1, 256, 56, 56]               0\n","FeatureFusionBlock-374        [-1, 256, 112, 112]               0\n","            ReLU-375        [-1, 256, 112, 112]               0\n","          Conv2d-376        [-1, 256, 112, 112]         590,080\n","            ReLU-377        [-1, 256, 112, 112]               0\n","          Conv2d-378        [-1, 256, 112, 112]         590,080\n","ResidualConvUnit-379        [-1, 256, 112, 112]               0\n","            ReLU-380        [-1, 256, 112, 112]               0\n","          Conv2d-381        [-1, 256, 112, 112]         590,080\n","            ReLU-382        [-1, 256, 112, 112]               0\n","          Conv2d-383        [-1, 256, 112, 112]         590,080\n","ResidualConvUnit-384        [-1, 256, 112, 112]               0\n","FeatureFusionBlock-385        [-1, 256, 224, 224]               0\n","          Conv2d-386        [-1, 128, 224, 224]         295,040\n","     Interpolate-387        [-1, 128, 448, 448]               0\n","          Conv2d-388         [-1, 32, 448, 448]          36,896\n","            ReLU-389         [-1, 32, 448, 448]               0\n","          Conv2d-390          [-1, 1, 448, 448]              33\n","            ReLU-391          [-1, 1, 448, 448]               0\n","          Conv2d-392        [-1, 256, 224, 224]           6,912\n","     BatchNorm2d-393        [-1, 256, 224, 224]             512\n","            ReLU-394        [-1, 256, 224, 224]               0\n","          Conv2d-395        [-1, 256, 112, 112]         589,824\n","     BatchNorm2d-396        [-1, 256, 112, 112]             512\n","            ReLU-397        [-1, 256, 112, 112]               0\n","          Conv2d-398          [-1, 256, 56, 56]         589,824\n","     BatchNorm2d-399          [-1, 256, 56, 56]             512\n","            ReLU-400          [-1, 256, 56, 56]               0\n","          Conv2d-401          [-1, 512, 28, 28]       1,179,648\n","     BatchNorm2d-402          [-1, 512, 28, 28]           1,024\n","            ReLU-403          [-1, 512, 28, 28]               0\n","          Conv2d-404         [-1, 1024, 14, 14]       4,718,592\n","     BatchNorm2d-405         [-1, 1024, 14, 14]           2,048\n","            ReLU-406         [-1, 1024, 14, 14]               0\n","          Conv2d-407         [-1, 1024, 14, 14]       2,097,152\n","     BatchNorm2d-408         [-1, 1024, 14, 14]           2,048\n","            ReLU-409         [-1, 1024, 14, 14]               0\n","          Conv2d-410           [-1, 27, 14, 14]          27,675\n","       YOLOLayer-411         [-1, 3, 14, 14, 9]               0\n","     Interpolate-412         [-1, 1024, 28, 28]               0\n","          Conv2d-413          [-1, 256, 28, 28]         262,144\n","     BatchNorm2d-414          [-1, 256, 28, 28]             512\n","            ReLU-415          [-1, 256, 28, 28]               0\n","          Conv2d-416          [-1, 512, 28, 28]         524,288\n","     BatchNorm2d-417          [-1, 512, 28, 28]           1,024\n","            ReLU-418          [-1, 512, 28, 28]               0\n","          Conv2d-419          [-1, 256, 28, 28]         196,608\n","     BatchNorm2d-420          [-1, 256, 28, 28]             512\n","            ReLU-421          [-1, 256, 28, 28]               0\n","          Conv2d-422          [-1, 512, 28, 28]       1,179,648\n","     BatchNorm2d-423          [-1, 512, 28, 28]           1,024\n","            ReLU-424          [-1, 512, 28, 28]               0\n","          Conv2d-425          [-1, 256, 28, 28]         131,072\n","     BatchNorm2d-426          [-1, 256, 28, 28]             512\n","            ReLU-427          [-1, 256, 28, 28]               0\n","          Conv2d-428          [-1, 512, 28, 28]       1,179,648\n","     BatchNorm2d-429          [-1, 512, 28, 28]           1,024\n","            ReLU-430          [-1, 512, 28, 28]               0\n","          Conv2d-431          [-1, 256, 28, 28]         131,072\n","     BatchNorm2d-432          [-1, 256, 28, 28]             512\n","            ReLU-433          [-1, 256, 28, 28]               0\n","          Conv2d-434          [-1, 512, 28, 28]       1,179,648\n","     BatchNorm2d-435          [-1, 512, 28, 28]           1,024\n","            ReLU-436          [-1, 512, 28, 28]               0\n","          Conv2d-437           [-1, 27, 28, 28]          13,851\n","       YOLOLayer-438         [-1, 3, 28, 28, 9]               0\n","          Conv2d-439          [-1, 256, 56, 56]         131,072\n","     BatchNorm2d-440          [-1, 256, 56, 56]             512\n","            ReLU-441          [-1, 256, 56, 56]               0\n","     Interpolate-442          [-1, 512, 56, 56]               0\n","          Conv2d-443          [-1, 128, 56, 56]          65,536\n","     BatchNorm2d-444          [-1, 128, 56, 56]             256\n","            ReLU-445          [-1, 128, 56, 56]               0\n","          Conv2d-446          [-1, 128, 56, 56]          49,152\n","     BatchNorm2d-447          [-1, 128, 56, 56]             256\n","            ReLU-448          [-1, 128, 56, 56]               0\n","          Conv2d-449          [-1, 256, 56, 56]         294,912\n","     BatchNorm2d-450          [-1, 256, 56, 56]             512\n","            ReLU-451          [-1, 256, 56, 56]               0\n","          Conv2d-452          [-1, 128, 56, 56]          32,768\n","     BatchNorm2d-453          [-1, 128, 56, 56]             256\n","            ReLU-454          [-1, 128, 56, 56]               0\n","          Conv2d-455          [-1, 256, 56, 56]         294,912\n","     BatchNorm2d-456          [-1, 256, 56, 56]             512\n","            ReLU-457          [-1, 256, 56, 56]               0\n","          Conv2d-458          [-1, 128, 56, 56]          32,768\n","     BatchNorm2d-459          [-1, 128, 56, 56]             256\n","            ReLU-460          [-1, 128, 56, 56]               0\n","          Conv2d-461          [-1, 256, 56, 56]         294,912\n","     BatchNorm2d-462          [-1, 256, 56, 56]             512\n","            ReLU-463          [-1, 256, 56, 56]               0\n","          Conv2d-464           [-1, 27, 56, 56]           6,939\n","       YOLOLayer-465         [-1, 3, 56, 56, 9]               0\n","================================================================\n","Total params: 119,409,234\n","Trainable params: 119,409,234\n","Non-trainable params: 0\n","----------------------------------------------------------------\n","Input size (MB): 2.30\n","Forward/backward pass size (MB): 4511.99\n","Params size (MB): 455.51\n","Estimated Total Size (MB): 4969.80\n","----------------------------------------------------------------\n","Image sizes 448 - 448 train, 448 test\n","Using 4 dataloader workers\n","Starting training for 300 epochs...\n","\n","            Epoch          gpu_mem             GIoU              obj              cls            total          targets          ImgSize RmseGradMeanLoss    SSIM_meanLoss\n","  0% 0/3 [00:00<?, ?it/s]/content/drive/My Drive/computer_vision/capstone_project/yolo_v3/utils/utils.py:613: UserWarning: This overload of nonzero is deprecated:\n","\tnonzero()\n","Consider using one of the following signatures instead:\n","\tnonzero(*, bool as_tuple) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:882.)\n","  valid = det.nonzero()\n","/usr/local/lib/python3.6/dist-packages/torch/cuda/memory.py:346: FutureWarning: torch.cuda.memory_cached has been renamed to torch.cuda.memory_reserved\n","  FutureWarning)\n","   176/299     15.1G             5.99             5.79             3.44             15.2               14              448                0            0.375: 100% 3/3 [00:04<00:00,  1.34s/it]\n","               Class           Images          Targets                P                R          mAP@0.5               F1 RmseGradientLoss         SSIMLoss            DLoss        TotalLoss:   0% 0/2 [00:00<?, ?it/s]Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","               Class           Images          Targets                P                R          mAP@0.5               F1 RmseGradientLoss         SSIMLoss            DLoss        TotalLoss: 100% 2/2 [00:02<00:00,  1.30s/it]\n","                 all               14               49                0                0                0                0                0             1.74             1.74             40.3\n","\n","            Epoch          gpu_mem             GIoU              obj              cls            total          targets          ImgSize RmseGradMeanLoss    SSIM_meanLoss\n","  0% 0/3 [00:00<?, ?it/s]/usr/local/lib/python3.6/dist-packages/torch/cuda/memory.py:346: FutureWarning: torch.cuda.memory_cached has been renamed to torch.cuda.memory_reserved\n","  FutureWarning)\n","   177/299     15.1G              5.8             6.71             2.68             15.2               20              448                0            0.374: 100% 3/3 [00:03<00:00,  1.28s/it]\n","               Class           Images          Targets                P                R          mAP@0.5               F1 RmseGradientLoss         SSIMLoss            DLoss        TotalLoss: 100% 2/2 [00:01<00:00,  1.60it/s]\n","                 all               14               49                0                0                0                0             67.5             1.75             69.2              111\n","\n","            Epoch          gpu_mem             GIoU              obj              cls            total          targets          ImgSize RmseGradMeanLoss    SSIM_meanLoss\n","   178/299     15.1G             5.52             5.65             1.47             12.6               25              448                0            0.374: 100% 3/3 [00:03<00:00,  1.26s/it]\n","               Class           Images          Targets                P                R          mAP@0.5               F1 RmseGradientLoss         SSIMLoss            DLoss        TotalLoss: 100% 2/2 [00:01<00:00,  1.59it/s]\n","                 all               14               49                0                0                0                0             15.2             1.75             16.9             59.6\n","\n","            Epoch          gpu_mem             GIoU              obj              cls            total          targets          ImgSize RmseGradMeanLoss    SSIM_meanLoss\n","   179/299     15.1G             5.35             5.47             1.41             12.2               19              448                0            0.375: 100% 3/3 [00:03<00:00,  1.26s/it]\n","               Class           Images          Targets                P                R          mAP@0.5               F1 RmseGradientLoss         SSIMLoss            DLoss        TotalLoss: 100% 2/2 [00:01<00:00,  1.51it/s]\n","                 all               14               49                0                0                0                0             15.2             1.75             16.9             59.6\n","\n","            Epoch          gpu_mem             GIoU              obj              cls            total          targets          ImgSize RmseGradMeanLoss    SSIM_meanLoss\n","   180/299     15.1G              5.9             4.93              2.4             13.2               12              448             18.7            0.372: 100% 3/3 [00:04<00:00,  1.34s/it]\n","               Class           Images          Targets                P                R          mAP@0.5               F1 RmseGradientLoss         SSIMLoss            DLoss        TotalLoss: 100% 2/2 [00:01<00:00,  1.55it/s]\n","                 all               14               49                0                0         0.000355                0             8.96             1.75             10.7              125\n","\n","            Epoch          gpu_mem             GIoU              obj              cls            total          targets          ImgSize RmseGradMeanLoss    SSIM_meanLoss\n","   181/299     15.1G             6.18             6.68             3.88             16.7               19              448                0            0.372: 100% 3/3 [00:03<00:00,  1.28s/it]\n","               Class           Images          Targets                P                R          mAP@0.5               F1 RmseGradientLoss         SSIMLoss            DLoss        TotalLoss: 100% 2/2 [00:01<00:00,  1.62it/s]\n","                 all               14               49                0                0                0                0                0             1.75             1.75         8.33e+14\n","\n","            Epoch          gpu_mem             GIoU              obj              cls            total          targets          ImgSize RmseGradMeanLoss    SSIM_meanLoss\n","   182/299     15.1G             6.87             5.33             4.66             16.9               13              448                0            0.375: 100% 3/3 [00:03<00:00,  1.26s/it]\n","               Class           Images          Targets                P                R          mAP@0.5               F1 RmseGradientLoss         SSIMLoss            DLoss        TotalLoss: 100% 2/2 [00:01<00:00,  1.70it/s]\n","                 all               14               49                0                0                0                0                0             1.75             1.75         9.56e+23\n","\n","            Epoch          gpu_mem             GIoU              obj              cls            total          targets          ImgSize RmseGradMeanLoss    SSIM_meanLoss\n","   183/299     15.1G             6.65             6.68              4.2             17.5               15              448                0            0.374: 100% 3/3 [00:04<00:00,  1.47s/it]\n","               Class           Images          Targets                P                R          mAP@0.5               F1 RmseGradientLoss         SSIMLoss            DLoss        TotalLoss: 100% 2/2 [00:01<00:00,  1.65it/s]\n","                 all               14               49                0                0                0                0                0             1.75             1.75         9.55e+23\n","\n","            Epoch          gpu_mem             GIoU              obj              cls            total          targets          ImgSize RmseGradMeanLoss    SSIM_meanLoss\n","   184/299     15.1G             6.66             4.55             4.45             15.7               11              448                0            0.374: 100% 3/3 [00:10<00:00,  3.51s/it]\n","               Class           Images          Targets                P                R          mAP@0.5               F1 RmseGradientLoss         SSIMLoss            DLoss        TotalLoss: 100% 2/2 [00:01<00:00,  1.67it/s]\n","                 all               14               49                0                0                0                0                0             1.75             1.75         3.15e+16\n","\n","            Epoch          gpu_mem             GIoU              obj              cls            total          targets          ImgSize RmseGradMeanLoss    SSIM_meanLoss\n","   185/299     15.1G             6.41             5.12             4.18             15.7               31              448                0            0.374: 100% 3/3 [00:03<00:00,  1.25s/it]\n","               Class           Images          Targets                P                R          mAP@0.5               F1 RmseGradientLoss         SSIMLoss            DLoss        TotalLoss: 100% 2/2 [00:01<00:00,  1.68it/s]\n","                 all               14               49                0                0                0                0                0             1.75             1.75         9.41e+12\n","\n","            Epoch          gpu_mem             GIoU              obj              cls            total          targets          ImgSize RmseGradMeanLoss    SSIM_meanLoss\n","   186/299     15.1G             6.47             5.28             3.74             15.5               24              448                0            0.374: 100% 3/3 [00:05<00:00,  1.68s/it]\n","               Class           Images          Targets                P                R          mAP@0.5               F1 RmseGradientLoss         SSIMLoss            DLoss        TotalLoss: 100% 2/2 [00:01<00:00,  1.66it/s]\n","                 all               14               49                0                0                0                0                0             1.75             1.75          9.5e+10\n","\n","            Epoch          gpu_mem             GIoU              obj              cls            total          targets          ImgSize RmseGradMeanLoss    SSIM_meanLoss\n","   187/299     15.1G              6.4             3.69             3.28             13.4               11              448                0            0.372: 100% 3/3 [00:03<00:00,  1.24s/it]\n","               Class           Images          Targets                P                R          mAP@0.5               F1 RmseGradientLoss         SSIMLoss            DLoss        TotalLoss: 100% 2/2 [00:01<00:00,  1.68it/s]\n","                 all               14               49                0                0                0                0                0             1.75             1.75         9.47e+10\n","\n","            Epoch          gpu_mem             GIoU              obj              cls            total          targets          ImgSize RmseGradMeanLoss    SSIM_meanLoss\n","   188/299     15.1G             6.15              5.1             3.15             14.4               18              448                0            0.375: 100% 3/3 [00:03<00:00,  1.29s/it]\n","               Class           Images          Targets                P                R          mAP@0.5               F1 RmseGradientLoss         SSIMLoss            DLoss        TotalLoss: 100% 2/2 [00:01<00:00,  1.70it/s]\n","                 all               14               49                0                0                0                0                0             1.75             1.75         2.23e+09\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"wcpCWX_sF-tg"},"source":["# !python train.py --data data/customdata/custom_test.data --batch 8 --cache --cfg cfg/yolov3-custom.cfg --epochs 50 --midas_weights='weights/model-f46da743.pt' --yolo_weights='weights/last_ppe.pt' --init_train='True' --img-size=512 --midasnet_freeze='False'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"w3PAeEy1oSMW","outputId":"dd7c597d-e6b3-457d-bf8c-906bf9d4ca1f"},"source":["!md5sum ./weights/last_best_diwali_2am.pt\n","!md5sum ./weights/best.pt\n","!md5sum ./weights/last.pt"],"execution_count":null,"outputs":[{"output_type":"stream","text":["4d111871c26592ce86197c2d04fa5087  ./weights/last_best_diwali_2am.pt\n","4d111871c26592ce86197c2d04fa5087  ./weights/best.pt\n","d0f8da0323a1620f913934168ac0aa79  ./weights/last.pt\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AdYUpRYuoACQ","outputId":"ee4339bc-2747-4479-c58c-1048edd16b5e"},"source":["!python train.py --data data/customdata/custom.data --batch 32  --cache --cfg cfg/yolov3-custom.cfg --epochs 300 --weights 'weights/best.pt'  --img-size=64 --midasnet_freeze='False'"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Namespace(accumulate=4, adam=False, batch_size=32, bbox_lambda=1, bucket='', cache_images=True, cfg='cfg/yolov3-custom.cfg', data='data/customdata/custom.data', depth_lambda=1, device='', epochs=300, evolve=False, img_size=[64], init_train='False', midas_weights='', midasnet_freeze='False', multi_scale=False, name='', nosave=False, notest=False, rect=False, resume=False, single_cls=False, weights='weights/best.pt', yolo_weights='')\n","Using CUDA device0 _CudaDeviceProperties(name='Tesla V100-SXM2-16GB', total_memory=16130MB)\n","\n","2020-11-18 14:00:56.949556: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n","Run 'tensorboard --logdir=runs' to view tensorboard at http://localhost:6006/\n","cfg - cfg/yolov3-custom.cfg\n","data - data/customdata/custom.data\n","epochs - 300\n","batch_size - 32\n","accumulate - 4\n","yolo weights - \n","midas weights - \n","imgsz_min- 64, imgsz_max- 64, imgsz_test- 64\n","opt.rect - False\n","train_path - data/customdata/train.txt\n","test_path - data/customdata/test.txt\n","init_train - False\n","weights - weights/best.pt\n","midasnet_freeze - False\n","mixed_precision enabled - False\n","Init LR - 0.0001\n","Using cache found in /root/.cache/torch/hub/facebookresearch_WSL-Images_master\n","Caching labels (2623 found, 114 missing, 30 empty, 0 duplicate, for 2767 images): 100% 2767/2767 [22:37<00:00,  2.04it/s]\n","Caching images (0.1GB): 100% 2767/2767 [2:04:04<00:00,  2.69s/it]\n","Caching labels (657 found, 27 missing, 8 empty, 0 duplicate, for 692 images): 100% 692/692 [06:00<00:00,  1.92it/s]\n","Caching images (0.0GB): 100% 692/692 [30:23<00:00,  2.64s/it]\n","YMP Model Summary\n","----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","            Conv2d-1           [-1, 64, 32, 32]           9,408\n","       BatchNorm2d-2           [-1, 64, 32, 32]             128\n","              ReLU-3           [-1, 64, 32, 32]               0\n","         MaxPool2d-4           [-1, 64, 16, 16]               0\n","            Conv2d-5          [-1, 256, 16, 16]          16,384\n","       BatchNorm2d-6          [-1, 256, 16, 16]             512\n","              ReLU-7          [-1, 256, 16, 16]               0\n","            Conv2d-8          [-1, 256, 16, 16]          18,432\n","       BatchNorm2d-9          [-1, 256, 16, 16]             512\n","             ReLU-10          [-1, 256, 16, 16]               0\n","           Conv2d-11          [-1, 256, 16, 16]          65,536\n","      BatchNorm2d-12          [-1, 256, 16, 16]             512\n","           Conv2d-13          [-1, 256, 16, 16]          16,384\n","      BatchNorm2d-14          [-1, 256, 16, 16]             512\n","             ReLU-15          [-1, 256, 16, 16]               0\n","       Bottleneck-16          [-1, 256, 16, 16]               0\n","           Conv2d-17          [-1, 256, 16, 16]          65,536\n","      BatchNorm2d-18          [-1, 256, 16, 16]             512\n","             ReLU-19          [-1, 256, 16, 16]               0\n","           Conv2d-20          [-1, 256, 16, 16]          18,432\n","      BatchNorm2d-21          [-1, 256, 16, 16]             512\n","             ReLU-22          [-1, 256, 16, 16]               0\n","           Conv2d-23          [-1, 256, 16, 16]          65,536\n","      BatchNorm2d-24          [-1, 256, 16, 16]             512\n","             ReLU-25          [-1, 256, 16, 16]               0\n","       Bottleneck-26          [-1, 256, 16, 16]               0\n","           Conv2d-27          [-1, 256, 16, 16]          65,536\n","      BatchNorm2d-28          [-1, 256, 16, 16]             512\n","             ReLU-29          [-1, 256, 16, 16]               0\n","           Conv2d-30          [-1, 256, 16, 16]          18,432\n","      BatchNorm2d-31          [-1, 256, 16, 16]             512\n","             ReLU-32          [-1, 256, 16, 16]               0\n","           Conv2d-33          [-1, 256, 16, 16]          65,536\n","      BatchNorm2d-34          [-1, 256, 16, 16]             512\n","             ReLU-35          [-1, 256, 16, 16]               0\n","       Bottleneck-36          [-1, 256, 16, 16]               0\n","           Conv2d-37          [-1, 512, 16, 16]         131,072\n","      BatchNorm2d-38          [-1, 512, 16, 16]           1,024\n","             ReLU-39          [-1, 512, 16, 16]               0\n","           Conv2d-40            [-1, 512, 8, 8]          73,728\n","      BatchNorm2d-41            [-1, 512, 8, 8]           1,024\n","             ReLU-42            [-1, 512, 8, 8]               0\n","           Conv2d-43            [-1, 512, 8, 8]         262,144\n","      BatchNorm2d-44            [-1, 512, 8, 8]           1,024\n","           Conv2d-45            [-1, 512, 8, 8]         131,072\n","      BatchNorm2d-46            [-1, 512, 8, 8]           1,024\n","             ReLU-47            [-1, 512, 8, 8]               0\n","       Bottleneck-48            [-1, 512, 8, 8]               0\n","           Conv2d-49            [-1, 512, 8, 8]         262,144\n","      BatchNorm2d-50            [-1, 512, 8, 8]           1,024\n","             ReLU-51            [-1, 512, 8, 8]               0\n","           Conv2d-52            [-1, 512, 8, 8]          73,728\n","      BatchNorm2d-53            [-1, 512, 8, 8]           1,024\n","             ReLU-54            [-1, 512, 8, 8]               0\n","           Conv2d-55            [-1, 512, 8, 8]         262,144\n","      BatchNorm2d-56            [-1, 512, 8, 8]           1,024\n","             ReLU-57            [-1, 512, 8, 8]               0\n","       Bottleneck-58            [-1, 512, 8, 8]               0\n","           Conv2d-59            [-1, 512, 8, 8]         262,144\n","      BatchNorm2d-60            [-1, 512, 8, 8]           1,024\n","             ReLU-61            [-1, 512, 8, 8]               0\n","           Conv2d-62            [-1, 512, 8, 8]          73,728\n","      BatchNorm2d-63            [-1, 512, 8, 8]           1,024\n","             ReLU-64            [-1, 512, 8, 8]               0\n","           Conv2d-65            [-1, 512, 8, 8]         262,144\n","      BatchNorm2d-66            [-1, 512, 8, 8]           1,024\n","             ReLU-67            [-1, 512, 8, 8]               0\n","       Bottleneck-68            [-1, 512, 8, 8]               0\n","           Conv2d-69            [-1, 512, 8, 8]         262,144\n","      BatchNorm2d-70            [-1, 512, 8, 8]           1,024\n","             ReLU-71            [-1, 512, 8, 8]               0\n","           Conv2d-72            [-1, 512, 8, 8]          73,728\n","      BatchNorm2d-73            [-1, 512, 8, 8]           1,024\n","             ReLU-74            [-1, 512, 8, 8]               0\n","           Conv2d-75            [-1, 512, 8, 8]         262,144\n","      BatchNorm2d-76            [-1, 512, 8, 8]           1,024\n","             ReLU-77            [-1, 512, 8, 8]               0\n","       Bottleneck-78            [-1, 512, 8, 8]               0\n","           Conv2d-79           [-1, 1024, 8, 8]         524,288\n","      BatchNorm2d-80           [-1, 1024, 8, 8]           2,048\n","             ReLU-81           [-1, 1024, 8, 8]               0\n","           Conv2d-82           [-1, 1024, 4, 4]         294,912\n","      BatchNorm2d-83           [-1, 1024, 4, 4]           2,048\n","             ReLU-84           [-1, 1024, 4, 4]               0\n","           Conv2d-85           [-1, 1024, 4, 4]       1,048,576\n","      BatchNorm2d-86           [-1, 1024, 4, 4]           2,048\n","           Conv2d-87           [-1, 1024, 4, 4]         524,288\n","      BatchNorm2d-88           [-1, 1024, 4, 4]           2,048\n","             ReLU-89           [-1, 1024, 4, 4]               0\n","       Bottleneck-90           [-1, 1024, 4, 4]               0\n","           Conv2d-91           [-1, 1024, 4, 4]       1,048,576\n","      BatchNorm2d-92           [-1, 1024, 4, 4]           2,048\n","             ReLU-93           [-1, 1024, 4, 4]               0\n","           Conv2d-94           [-1, 1024, 4, 4]         294,912\n","      BatchNorm2d-95           [-1, 1024, 4, 4]           2,048\n","             ReLU-96           [-1, 1024, 4, 4]               0\n","           Conv2d-97           [-1, 1024, 4, 4]       1,048,576\n","      BatchNorm2d-98           [-1, 1024, 4, 4]           2,048\n","             ReLU-99           [-1, 1024, 4, 4]               0\n","      Bottleneck-100           [-1, 1024, 4, 4]               0\n","          Conv2d-101           [-1, 1024, 4, 4]       1,048,576\n","     BatchNorm2d-102           [-1, 1024, 4, 4]           2,048\n","            ReLU-103           [-1, 1024, 4, 4]               0\n","          Conv2d-104           [-1, 1024, 4, 4]         294,912\n","     BatchNorm2d-105           [-1, 1024, 4, 4]           2,048\n","            ReLU-106           [-1, 1024, 4, 4]               0\n","          Conv2d-107           [-1, 1024, 4, 4]       1,048,576\n","     BatchNorm2d-108           [-1, 1024, 4, 4]           2,048\n","            ReLU-109           [-1, 1024, 4, 4]               0\n","      Bottleneck-110           [-1, 1024, 4, 4]               0\n","          Conv2d-111           [-1, 1024, 4, 4]       1,048,576\n","     BatchNorm2d-112           [-1, 1024, 4, 4]           2,048\n","            ReLU-113           [-1, 1024, 4, 4]               0\n","          Conv2d-114           [-1, 1024, 4, 4]         294,912\n","     BatchNorm2d-115           [-1, 1024, 4, 4]           2,048\n","            ReLU-116           [-1, 1024, 4, 4]               0\n","          Conv2d-117           [-1, 1024, 4, 4]       1,048,576\n","     BatchNorm2d-118           [-1, 1024, 4, 4]           2,048\n","            ReLU-119           [-1, 1024, 4, 4]               0\n","      Bottleneck-120           [-1, 1024, 4, 4]               0\n","          Conv2d-121           [-1, 1024, 4, 4]       1,048,576\n","     BatchNorm2d-122           [-1, 1024, 4, 4]           2,048\n","            ReLU-123           [-1, 1024, 4, 4]               0\n","          Conv2d-124           [-1, 1024, 4, 4]         294,912\n","     BatchNorm2d-125           [-1, 1024, 4, 4]           2,048\n","            ReLU-126           [-1, 1024, 4, 4]               0\n","          Conv2d-127           [-1, 1024, 4, 4]       1,048,576\n","     BatchNorm2d-128           [-1, 1024, 4, 4]           2,048\n","            ReLU-129           [-1, 1024, 4, 4]               0\n","      Bottleneck-130           [-1, 1024, 4, 4]               0\n","          Conv2d-131           [-1, 1024, 4, 4]       1,048,576\n","     BatchNorm2d-132           [-1, 1024, 4, 4]           2,048\n","            ReLU-133           [-1, 1024, 4, 4]               0\n","          Conv2d-134           [-1, 1024, 4, 4]         294,912\n","     BatchNorm2d-135           [-1, 1024, 4, 4]           2,048\n","            ReLU-136           [-1, 1024, 4, 4]               0\n","          Conv2d-137           [-1, 1024, 4, 4]       1,048,576\n","     BatchNorm2d-138           [-1, 1024, 4, 4]           2,048\n","            ReLU-139           [-1, 1024, 4, 4]               0\n","      Bottleneck-140           [-1, 1024, 4, 4]               0\n","          Conv2d-141           [-1, 1024, 4, 4]       1,048,576\n","     BatchNorm2d-142           [-1, 1024, 4, 4]           2,048\n","            ReLU-143           [-1, 1024, 4, 4]               0\n","          Conv2d-144           [-1, 1024, 4, 4]         294,912\n","     BatchNorm2d-145           [-1, 1024, 4, 4]           2,048\n","            ReLU-146           [-1, 1024, 4, 4]               0\n","          Conv2d-147           [-1, 1024, 4, 4]       1,048,576\n","     BatchNorm2d-148           [-1, 1024, 4, 4]           2,048\n","            ReLU-149           [-1, 1024, 4, 4]               0\n","      Bottleneck-150           [-1, 1024, 4, 4]               0\n","          Conv2d-151           [-1, 1024, 4, 4]       1,048,576\n","     BatchNorm2d-152           [-1, 1024, 4, 4]           2,048\n","            ReLU-153           [-1, 1024, 4, 4]               0\n","          Conv2d-154           [-1, 1024, 4, 4]         294,912\n","     BatchNorm2d-155           [-1, 1024, 4, 4]           2,048\n","            ReLU-156           [-1, 1024, 4, 4]               0\n","          Conv2d-157           [-1, 1024, 4, 4]       1,048,576\n","     BatchNorm2d-158           [-1, 1024, 4, 4]           2,048\n","            ReLU-159           [-1, 1024, 4, 4]               0\n","      Bottleneck-160           [-1, 1024, 4, 4]               0\n","          Conv2d-161           [-1, 1024, 4, 4]       1,048,576\n","     BatchNorm2d-162           [-1, 1024, 4, 4]           2,048\n","            ReLU-163           [-1, 1024, 4, 4]               0\n","          Conv2d-164           [-1, 1024, 4, 4]         294,912\n","     BatchNorm2d-165           [-1, 1024, 4, 4]           2,048\n","            ReLU-166           [-1, 1024, 4, 4]               0\n","          Conv2d-167           [-1, 1024, 4, 4]       1,048,576\n","     BatchNorm2d-168           [-1, 1024, 4, 4]           2,048\n","            ReLU-169           [-1, 1024, 4, 4]               0\n","      Bottleneck-170           [-1, 1024, 4, 4]               0\n","          Conv2d-171           [-1, 1024, 4, 4]       1,048,576\n","     BatchNorm2d-172           [-1, 1024, 4, 4]           2,048\n","            ReLU-173           [-1, 1024, 4, 4]               0\n","          Conv2d-174           [-1, 1024, 4, 4]         294,912\n","     BatchNorm2d-175           [-1, 1024, 4, 4]           2,048\n","            ReLU-176           [-1, 1024, 4, 4]               0\n","          Conv2d-177           [-1, 1024, 4, 4]       1,048,576\n","     BatchNorm2d-178           [-1, 1024, 4, 4]           2,048\n","            ReLU-179           [-1, 1024, 4, 4]               0\n","      Bottleneck-180           [-1, 1024, 4, 4]               0\n","          Conv2d-181           [-1, 1024, 4, 4]       1,048,576\n","     BatchNorm2d-182           [-1, 1024, 4, 4]           2,048\n","            ReLU-183           [-1, 1024, 4, 4]               0\n","          Conv2d-184           [-1, 1024, 4, 4]         294,912\n","     BatchNorm2d-185           [-1, 1024, 4, 4]           2,048\n","            ReLU-186           [-1, 1024, 4, 4]               0\n","          Conv2d-187           [-1, 1024, 4, 4]       1,048,576\n","     BatchNorm2d-188           [-1, 1024, 4, 4]           2,048\n","            ReLU-189           [-1, 1024, 4, 4]               0\n","      Bottleneck-190           [-1, 1024, 4, 4]               0\n","          Conv2d-191           [-1, 1024, 4, 4]       1,048,576\n","     BatchNorm2d-192           [-1, 1024, 4, 4]           2,048\n","            ReLU-193           [-1, 1024, 4, 4]               0\n","          Conv2d-194           [-1, 1024, 4, 4]         294,912\n","     BatchNorm2d-195           [-1, 1024, 4, 4]           2,048\n","            ReLU-196           [-1, 1024, 4, 4]               0\n","          Conv2d-197           [-1, 1024, 4, 4]       1,048,576\n","     BatchNorm2d-198           [-1, 1024, 4, 4]           2,048\n","            ReLU-199           [-1, 1024, 4, 4]               0\n","      Bottleneck-200           [-1, 1024, 4, 4]               0\n","          Conv2d-201           [-1, 1024, 4, 4]       1,048,576\n","     BatchNorm2d-202           [-1, 1024, 4, 4]           2,048\n","            ReLU-203           [-1, 1024, 4, 4]               0\n","          Conv2d-204           [-1, 1024, 4, 4]         294,912\n","     BatchNorm2d-205           [-1, 1024, 4, 4]           2,048\n","            ReLU-206           [-1, 1024, 4, 4]               0\n","          Conv2d-207           [-1, 1024, 4, 4]       1,048,576\n","     BatchNorm2d-208           [-1, 1024, 4, 4]           2,048\n","            ReLU-209           [-1, 1024, 4, 4]               0\n","      Bottleneck-210           [-1, 1024, 4, 4]               0\n","          Conv2d-211           [-1, 1024, 4, 4]       1,048,576\n","     BatchNorm2d-212           [-1, 1024, 4, 4]           2,048\n","            ReLU-213           [-1, 1024, 4, 4]               0\n","          Conv2d-214           [-1, 1024, 4, 4]         294,912\n","     BatchNorm2d-215           [-1, 1024, 4, 4]           2,048\n","            ReLU-216           [-1, 1024, 4, 4]               0\n","          Conv2d-217           [-1, 1024, 4, 4]       1,048,576\n","     BatchNorm2d-218           [-1, 1024, 4, 4]           2,048\n","            ReLU-219           [-1, 1024, 4, 4]               0\n","      Bottleneck-220           [-1, 1024, 4, 4]               0\n","          Conv2d-221           [-1, 1024, 4, 4]       1,048,576\n","     BatchNorm2d-222           [-1, 1024, 4, 4]           2,048\n","            ReLU-223           [-1, 1024, 4, 4]               0\n","          Conv2d-224           [-1, 1024, 4, 4]         294,912\n","     BatchNorm2d-225           [-1, 1024, 4, 4]           2,048\n","            ReLU-226           [-1, 1024, 4, 4]               0\n","          Conv2d-227           [-1, 1024, 4, 4]       1,048,576\n","     BatchNorm2d-228           [-1, 1024, 4, 4]           2,048\n","            ReLU-229           [-1, 1024, 4, 4]               0\n","      Bottleneck-230           [-1, 1024, 4, 4]               0\n","          Conv2d-231           [-1, 1024, 4, 4]       1,048,576\n","     BatchNorm2d-232           [-1, 1024, 4, 4]           2,048\n","            ReLU-233           [-1, 1024, 4, 4]               0\n","          Conv2d-234           [-1, 1024, 4, 4]         294,912\n","     BatchNorm2d-235           [-1, 1024, 4, 4]           2,048\n","            ReLU-236           [-1, 1024, 4, 4]               0\n","          Conv2d-237           [-1, 1024, 4, 4]       1,048,576\n","     BatchNorm2d-238           [-1, 1024, 4, 4]           2,048\n","            ReLU-239           [-1, 1024, 4, 4]               0\n","      Bottleneck-240           [-1, 1024, 4, 4]               0\n","          Conv2d-241           [-1, 1024, 4, 4]       1,048,576\n","     BatchNorm2d-242           [-1, 1024, 4, 4]           2,048\n","            ReLU-243           [-1, 1024, 4, 4]               0\n","          Conv2d-244           [-1, 1024, 4, 4]         294,912\n","     BatchNorm2d-245           [-1, 1024, 4, 4]           2,048\n","            ReLU-246           [-1, 1024, 4, 4]               0\n","          Conv2d-247           [-1, 1024, 4, 4]       1,048,576\n","     BatchNorm2d-248           [-1, 1024, 4, 4]           2,048\n","            ReLU-249           [-1, 1024, 4, 4]               0\n","      Bottleneck-250           [-1, 1024, 4, 4]               0\n","          Conv2d-251           [-1, 1024, 4, 4]       1,048,576\n","     BatchNorm2d-252           [-1, 1024, 4, 4]           2,048\n","            ReLU-253           [-1, 1024, 4, 4]               0\n","          Conv2d-254           [-1, 1024, 4, 4]         294,912\n","     BatchNorm2d-255           [-1, 1024, 4, 4]           2,048\n","            ReLU-256           [-1, 1024, 4, 4]               0\n","          Conv2d-257           [-1, 1024, 4, 4]       1,048,576\n","     BatchNorm2d-258           [-1, 1024, 4, 4]           2,048\n","            ReLU-259           [-1, 1024, 4, 4]               0\n","      Bottleneck-260           [-1, 1024, 4, 4]               0\n","          Conv2d-261           [-1, 1024, 4, 4]       1,048,576\n","     BatchNorm2d-262           [-1, 1024, 4, 4]           2,048\n","            ReLU-263           [-1, 1024, 4, 4]               0\n","          Conv2d-264           [-1, 1024, 4, 4]         294,912\n","     BatchNorm2d-265           [-1, 1024, 4, 4]           2,048\n","            ReLU-266           [-1, 1024, 4, 4]               0\n","          Conv2d-267           [-1, 1024, 4, 4]       1,048,576\n","     BatchNorm2d-268           [-1, 1024, 4, 4]           2,048\n","            ReLU-269           [-1, 1024, 4, 4]               0\n","      Bottleneck-270           [-1, 1024, 4, 4]               0\n","          Conv2d-271           [-1, 1024, 4, 4]       1,048,576\n","     BatchNorm2d-272           [-1, 1024, 4, 4]           2,048\n","            ReLU-273           [-1, 1024, 4, 4]               0\n","          Conv2d-274           [-1, 1024, 4, 4]         294,912\n","     BatchNorm2d-275           [-1, 1024, 4, 4]           2,048\n","            ReLU-276           [-1, 1024, 4, 4]               0\n","          Conv2d-277           [-1, 1024, 4, 4]       1,048,576\n","     BatchNorm2d-278           [-1, 1024, 4, 4]           2,048\n","            ReLU-279           [-1, 1024, 4, 4]               0\n","      Bottleneck-280           [-1, 1024, 4, 4]               0\n","          Conv2d-281           [-1, 1024, 4, 4]       1,048,576\n","     BatchNorm2d-282           [-1, 1024, 4, 4]           2,048\n","            ReLU-283           [-1, 1024, 4, 4]               0\n","          Conv2d-284           [-1, 1024, 4, 4]         294,912\n","     BatchNorm2d-285           [-1, 1024, 4, 4]           2,048\n","            ReLU-286           [-1, 1024, 4, 4]               0\n","          Conv2d-287           [-1, 1024, 4, 4]       1,048,576\n","     BatchNorm2d-288           [-1, 1024, 4, 4]           2,048\n","            ReLU-289           [-1, 1024, 4, 4]               0\n","      Bottleneck-290           [-1, 1024, 4, 4]               0\n","          Conv2d-291           [-1, 1024, 4, 4]       1,048,576\n","     BatchNorm2d-292           [-1, 1024, 4, 4]           2,048\n","            ReLU-293           [-1, 1024, 4, 4]               0\n","          Conv2d-294           [-1, 1024, 4, 4]         294,912\n","     BatchNorm2d-295           [-1, 1024, 4, 4]           2,048\n","            ReLU-296           [-1, 1024, 4, 4]               0\n","          Conv2d-297           [-1, 1024, 4, 4]       1,048,576\n","     BatchNorm2d-298           [-1, 1024, 4, 4]           2,048\n","            ReLU-299           [-1, 1024, 4, 4]               0\n","      Bottleneck-300           [-1, 1024, 4, 4]               0\n","          Conv2d-301           [-1, 1024, 4, 4]       1,048,576\n","     BatchNorm2d-302           [-1, 1024, 4, 4]           2,048\n","            ReLU-303           [-1, 1024, 4, 4]               0\n","          Conv2d-304           [-1, 1024, 4, 4]         294,912\n","     BatchNorm2d-305           [-1, 1024, 4, 4]           2,048\n","            ReLU-306           [-1, 1024, 4, 4]               0\n","          Conv2d-307           [-1, 1024, 4, 4]       1,048,576\n","     BatchNorm2d-308           [-1, 1024, 4, 4]           2,048\n","            ReLU-309           [-1, 1024, 4, 4]               0\n","      Bottleneck-310           [-1, 1024, 4, 4]               0\n","          Conv2d-311           [-1, 2048, 4, 4]       2,097,152\n","     BatchNorm2d-312           [-1, 2048, 4, 4]           4,096\n","            ReLU-313           [-1, 2048, 4, 4]               0\n","          Conv2d-314           [-1, 2048, 2, 2]       1,179,648\n","     BatchNorm2d-315           [-1, 2048, 2, 2]           4,096\n","            ReLU-316           [-1, 2048, 2, 2]               0\n","          Conv2d-317           [-1, 2048, 2, 2]       4,194,304\n","     BatchNorm2d-318           [-1, 2048, 2, 2]           4,096\n","          Conv2d-319           [-1, 2048, 2, 2]       2,097,152\n","     BatchNorm2d-320           [-1, 2048, 2, 2]           4,096\n","            ReLU-321           [-1, 2048, 2, 2]               0\n","      Bottleneck-322           [-1, 2048, 2, 2]               0\n","          Conv2d-323           [-1, 2048, 2, 2]       4,194,304\n","     BatchNorm2d-324           [-1, 2048, 2, 2]           4,096\n","            ReLU-325           [-1, 2048, 2, 2]               0\n","          Conv2d-326           [-1, 2048, 2, 2]       1,179,648\n","     BatchNorm2d-327           [-1, 2048, 2, 2]           4,096\n","            ReLU-328           [-1, 2048, 2, 2]               0\n","          Conv2d-329           [-1, 2048, 2, 2]       4,194,304\n","     BatchNorm2d-330           [-1, 2048, 2, 2]           4,096\n","            ReLU-331           [-1, 2048, 2, 2]               0\n","      Bottleneck-332           [-1, 2048, 2, 2]               0\n","          Conv2d-333           [-1, 2048, 2, 2]       4,194,304\n","     BatchNorm2d-334           [-1, 2048, 2, 2]           4,096\n","            ReLU-335           [-1, 2048, 2, 2]               0\n","          Conv2d-336           [-1, 2048, 2, 2]       1,179,648\n","     BatchNorm2d-337           [-1, 2048, 2, 2]           4,096\n","            ReLU-338           [-1, 2048, 2, 2]               0\n","          Conv2d-339           [-1, 2048, 2, 2]       4,194,304\n","     BatchNorm2d-340           [-1, 2048, 2, 2]           4,096\n","            ReLU-341           [-1, 2048, 2, 2]               0\n","      Bottleneck-342           [-1, 2048, 2, 2]               0\n","          Conv2d-343          [-1, 256, 16, 16]         589,824\n","          Conv2d-344            [-1, 256, 8, 8]       1,179,648\n","          Conv2d-345            [-1, 256, 4, 4]       2,359,296\n","          Conv2d-346            [-1, 256, 2, 2]       4,718,592\n","            ReLU-347            [-1, 256, 2, 2]               0\n","          Conv2d-348            [-1, 256, 2, 2]         590,080\n","            ReLU-349            [-1, 256, 2, 2]               0\n","          Conv2d-350            [-1, 256, 2, 2]         590,080\n","ResidualConvUnit-351            [-1, 256, 2, 2]               0\n","FeatureFusionBlock-352            [-1, 256, 4, 4]               0\n","            ReLU-353            [-1, 256, 4, 4]               0\n","          Conv2d-354            [-1, 256, 4, 4]         590,080\n","            ReLU-355            [-1, 256, 4, 4]               0\n","          Conv2d-356            [-1, 256, 4, 4]         590,080\n","ResidualConvUnit-357            [-1, 256, 4, 4]               0\n","            ReLU-358            [-1, 256, 4, 4]               0\n","          Conv2d-359            [-1, 256, 4, 4]         590,080\n","            ReLU-360            [-1, 256, 4, 4]               0\n","          Conv2d-361            [-1, 256, 4, 4]         590,080\n","ResidualConvUnit-362            [-1, 256, 4, 4]               0\n","FeatureFusionBlock-363            [-1, 256, 8, 8]               0\n","            ReLU-364            [-1, 256, 8, 8]               0\n","          Conv2d-365            [-1, 256, 8, 8]         590,080\n","            ReLU-366            [-1, 256, 8, 8]               0\n","          Conv2d-367            [-1, 256, 8, 8]         590,080\n","ResidualConvUnit-368            [-1, 256, 8, 8]               0\n","            ReLU-369            [-1, 256, 8, 8]               0\n","          Conv2d-370            [-1, 256, 8, 8]         590,080\n","            ReLU-371            [-1, 256, 8, 8]               0\n","          Conv2d-372            [-1, 256, 8, 8]         590,080\n","ResidualConvUnit-373            [-1, 256, 8, 8]               0\n","FeatureFusionBlock-374          [-1, 256, 16, 16]               0\n","            ReLU-375          [-1, 256, 16, 16]               0\n","          Conv2d-376          [-1, 256, 16, 16]         590,080\n","            ReLU-377          [-1, 256, 16, 16]               0\n","          Conv2d-378          [-1, 256, 16, 16]         590,080\n","ResidualConvUnit-379          [-1, 256, 16, 16]               0\n","            ReLU-380          [-1, 256, 16, 16]               0\n","          Conv2d-381          [-1, 256, 16, 16]         590,080\n","            ReLU-382          [-1, 256, 16, 16]               0\n","          Conv2d-383          [-1, 256, 16, 16]         590,080\n","ResidualConvUnit-384          [-1, 256, 16, 16]               0\n","FeatureFusionBlock-385          [-1, 256, 32, 32]               0\n","          Conv2d-386          [-1, 128, 32, 32]         295,040\n","     Interpolate-387          [-1, 128, 64, 64]               0\n","          Conv2d-388           [-1, 32, 64, 64]          36,896\n","            ReLU-389           [-1, 32, 64, 64]               0\n","          Conv2d-390            [-1, 1, 64, 64]              33\n","            ReLU-391            [-1, 1, 64, 64]               0\n","          Conv2d-392          [-1, 256, 32, 32]           6,912\n","     BatchNorm2d-393          [-1, 256, 32, 32]             512\n","            ReLU-394          [-1, 256, 32, 32]               0\n","          Conv2d-395          [-1, 256, 16, 16]         589,824\n","     BatchNorm2d-396          [-1, 256, 16, 16]             512\n","            ReLU-397          [-1, 256, 16, 16]               0\n","          Conv2d-398            [-1, 256, 8, 8]         589,824\n","     BatchNorm2d-399            [-1, 256, 8, 8]             512\n","            ReLU-400            [-1, 256, 8, 8]               0\n","          Conv2d-401            [-1, 512, 4, 4]       1,179,648\n","     BatchNorm2d-402            [-1, 512, 4, 4]           1,024\n","            ReLU-403            [-1, 512, 4, 4]               0\n","          Conv2d-404           [-1, 1024, 2, 2]       4,718,592\n","     BatchNorm2d-405           [-1, 1024, 2, 2]           2,048\n","            ReLU-406           [-1, 1024, 2, 2]               0\n","          Conv2d-407           [-1, 1024, 2, 2]       2,097,152\n","     BatchNorm2d-408           [-1, 1024, 2, 2]           2,048\n","            ReLU-409           [-1, 1024, 2, 2]               0\n","          Conv2d-410             [-1, 27, 2, 2]          27,675\n","       YOLOLayer-411           [-1, 3, 2, 2, 9]               0\n","     Interpolate-412           [-1, 1024, 4, 4]               0\n","          Conv2d-413            [-1, 256, 4, 4]         262,144\n","     BatchNorm2d-414            [-1, 256, 4, 4]             512\n","            ReLU-415            [-1, 256, 4, 4]               0\n","          Conv2d-416            [-1, 512, 4, 4]         524,288\n","     BatchNorm2d-417            [-1, 512, 4, 4]           1,024\n","            ReLU-418            [-1, 512, 4, 4]               0\n","          Conv2d-419            [-1, 256, 4, 4]         196,608\n","     BatchNorm2d-420            [-1, 256, 4, 4]             512\n","            ReLU-421            [-1, 256, 4, 4]               0\n","          Conv2d-422            [-1, 512, 4, 4]       1,179,648\n","     BatchNorm2d-423            [-1, 512, 4, 4]           1,024\n","            ReLU-424            [-1, 512, 4, 4]               0\n","          Conv2d-425            [-1, 256, 4, 4]         131,072\n","     BatchNorm2d-426            [-1, 256, 4, 4]             512\n","            ReLU-427            [-1, 256, 4, 4]               0\n","          Conv2d-428            [-1, 512, 4, 4]       1,179,648\n","     BatchNorm2d-429            [-1, 512, 4, 4]           1,024\n","            ReLU-430            [-1, 512, 4, 4]               0\n","          Conv2d-431            [-1, 256, 4, 4]         131,072\n","     BatchNorm2d-432            [-1, 256, 4, 4]             512\n","            ReLU-433            [-1, 256, 4, 4]               0\n","          Conv2d-434            [-1, 512, 4, 4]       1,179,648\n","     BatchNorm2d-435            [-1, 512, 4, 4]           1,024\n","            ReLU-436            [-1, 512, 4, 4]               0\n","          Conv2d-437             [-1, 27, 4, 4]          13,851\n","       YOLOLayer-438           [-1, 3, 4, 4, 9]               0\n","          Conv2d-439            [-1, 256, 8, 8]         131,072\n","     BatchNorm2d-440            [-1, 256, 8, 8]             512\n","            ReLU-441            [-1, 256, 8, 8]               0\n","     Interpolate-442            [-1, 512, 8, 8]               0\n","          Conv2d-443            [-1, 128, 8, 8]          65,536\n","     BatchNorm2d-444            [-1, 128, 8, 8]             256\n","            ReLU-445            [-1, 128, 8, 8]               0\n","          Conv2d-446            [-1, 128, 8, 8]          49,152\n","     BatchNorm2d-447            [-1, 128, 8, 8]             256\n","            ReLU-448            [-1, 128, 8, 8]               0\n","          Conv2d-449            [-1, 256, 8, 8]         294,912\n","     BatchNorm2d-450            [-1, 256, 8, 8]             512\n","            ReLU-451            [-1, 256, 8, 8]               0\n","          Conv2d-452            [-1, 128, 8, 8]          32,768\n","     BatchNorm2d-453            [-1, 128, 8, 8]             256\n","            ReLU-454            [-1, 128, 8, 8]               0\n","          Conv2d-455            [-1, 256, 8, 8]         294,912\n","     BatchNorm2d-456            [-1, 256, 8, 8]             512\n","            ReLU-457            [-1, 256, 8, 8]               0\n","          Conv2d-458            [-1, 128, 8, 8]          32,768\n","     BatchNorm2d-459            [-1, 128, 8, 8]             256\n","            ReLU-460            [-1, 128, 8, 8]               0\n","          Conv2d-461            [-1, 256, 8, 8]         294,912\n","     BatchNorm2d-462            [-1, 256, 8, 8]             512\n","            ReLU-463            [-1, 256, 8, 8]               0\n","          Conv2d-464             [-1, 27, 8, 8]           6,939\n","       YOLOLayer-465           [-1, 3, 8, 8, 9]               0\n","================================================================\n","Total params: 119,409,234\n","Trainable params: 119,409,234\n","Non-trainable params: 0\n","----------------------------------------------------------------\n","Input size (MB): 0.05\n","Forward/backward pass size (MB): 92.08\n","Params size (MB): 455.51\n","Estimated Total Size (MB): 547.64\n","----------------------------------------------------------------\n","Image sizes 64 - 64 train, 64 test\n","Using 4 dataloader workers\n","Starting training for 300 epochs...\n","\n","            Epoch          gpu_mem             GIoU              obj              cls            total          targets          ImgSize RmseGradMeanLoss    SSIM_meanLoss\n","  0% 0/87 [00:00<?, ?it/s]/content/drive/My Drive/computer_vision/capstone_project/yolo_v3/utils/utils.py:613: UserWarning: This overload of nonzero is deprecated:\n","\tnonzero()\n","Consider using one of the following signatures instead:\n","\tnonzero(*, bool as_tuple) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:882.)\n","  valid = det.nonzero()\n","/usr/local/lib/python3.6/dist-packages/torch/cuda/memory.py:346: FutureWarning: torch.cuda.memory_cached has been renamed to torch.cuda.memory_reserved\n","  FutureWarning)\n","   176/299     3.24G             3.79                7             2.05             12.8               52               64             7.23            0.372: 100% 87/87 [02:11<00:00,  1.51s/it]\n","               Class           Images          Targets                P                R          mAP@0.5               F1 RmseGradientLoss         SSIMLoss            DLoss        TotalLoss:   0% 0/22 [00:00<?, ?it/s]Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","               Class           Images          Targets                P                R          mAP@0.5               F1 RmseGradientLoss         SSIMLoss            DLoss        TotalLoss: 100% 22/22 [00:14<00:00,  1.53it/s]\n","                 all              692         3.06e+03                0                0         0.000592                0               96             17.7              114              553\n","\n","            Epoch          gpu_mem             GIoU              obj              cls            total          targets          ImgSize RmseGradMeanLoss    SSIM_meanLoss\n","  0% 0/87 [00:00<?, ?it/s]/usr/local/lib/python3.6/dist-packages/torch/cuda/memory.py:346: FutureWarning: torch.cuda.memory_cached has been renamed to torch.cuda.memory_reserved\n","  FutureWarning)\n","   177/299     3.24G             3.75             6.55             1.91             12.2               47               64                0            0.469: 100% 87/87 [02:13<00:00,  1.53s/it]\n","               Class           Images          Targets                P                R          mAP@0.5               F1 RmseGradientLoss         SSIMLoss            DLoss        TotalLoss: 100% 22/22 [00:12<00:00,  1.74it/s]\n","                 all              692         3.06e+03          0.00236         0.000326         0.000353         0.000572                0             21.6             21.6         1.22e+03\n","\n","            Epoch          gpu_mem             GIoU              obj              cls            total          targets          ImgSize RmseGradMeanLoss    SSIM_meanLoss\n","   178/299     3.24G              3.6             6.32             2.05               12               68               64                0            0.469: 100% 87/87 [02:12<00:00,  1.52s/it]\n","               Class           Images          Targets                P                R          mAP@0.5               F1 RmseGradientLoss         SSIMLoss            DLoss        TotalLoss: 100% 22/22 [00:12<00:00,  1.73it/s]\n","                 all              692         3.06e+03         0.000668         0.000326         0.000156         0.000438                0             21.6             21.6         2.62e+03\n","\n","            Epoch          gpu_mem             GIoU              obj              cls            total          targets          ImgSize RmseGradMeanLoss    SSIM_meanLoss\n","   179/299     3.24G             3.73             6.27             1.92             11.9               48               64                0            0.469: 100% 87/87 [02:10<00:00,  1.50s/it]\n","               Class           Images          Targets                P                R          mAP@0.5               F1 RmseGradientLoss         SSIMLoss            DLoss        TotalLoss: 100% 22/22 [00:12<00:00,  1.74it/s]\n","                 all              692         3.06e+03                0                0          0.00157                0                0             21.6             21.6              434\n","\n","            Epoch          gpu_mem             GIoU              obj              cls            total          targets          ImgSize RmseGradMeanLoss    SSIM_meanLoss\n","   180/299     3.24G             3.43             6.32             1.68             11.4               71               64                0            0.469: 100% 87/87 [02:12<00:00,  1.52s/it]\n","               Class           Images          Targets                P                R          mAP@0.5               F1 RmseGradientLoss         SSIMLoss            DLoss        TotalLoss: 100% 22/22 [00:12<00:00,  1.70it/s]\n","                 all              692         3.06e+03                0                0            0.002                0                0             21.6             21.6              353\n","\n","            Epoch          gpu_mem             GIoU              obj              cls            total          targets          ImgSize RmseGradMeanLoss    SSIM_meanLoss\n","   181/299     3.24G             3.44              6.1             1.69             11.2               71               64                0            0.469: 100% 87/87 [02:10<00:00,  1.51s/it]\n","               Class           Images          Targets                P                R          mAP@0.5               F1 RmseGradientLoss         SSIMLoss            DLoss        TotalLoss: 100% 22/22 [00:12<00:00,  1.78it/s]\n","                 all              692         3.06e+03                0                0          0.00206                0                0             21.6             21.6              514\n","\n","            Epoch          gpu_mem             GIoU              obj              cls            total          targets          ImgSize RmseGradMeanLoss    SSIM_meanLoss\n","   182/299     3.24G             3.46             6.24             1.82             11.5               68               64                0            0.469: 100% 87/87 [02:08<00:00,  1.48s/it]\n","               Class           Images          Targets                P                R          mAP@0.5               F1 RmseGradientLoss         SSIMLoss            DLoss        TotalLoss: 100% 22/22 [00:12<00:00,  1.77it/s]\n","                 all              692         3.06e+03                0                0          0.00178                0                0             21.6             21.6              564\n","\n","            Epoch          gpu_mem             GIoU              obj              cls            total          targets          ImgSize RmseGradMeanLoss    SSIM_meanLoss\n","   183/299     3.24G             3.37             6.06             1.51             10.9               65               64                0            0.469: 100% 87/87 [02:08<00:00,  1.48s/it]\n","               Class           Images          Targets                P                R          mAP@0.5               F1 RmseGradientLoss         SSIMLoss            DLoss        TotalLoss: 100% 22/22 [00:12<00:00,  1.81it/s]\n","                 all              692         3.06e+03                0                0          0.00127                0                0             21.6             21.6              488\n","\n","            Epoch          gpu_mem             GIoU              obj              cls            total          targets          ImgSize RmseGradMeanLoss    SSIM_meanLoss\n","   184/299     3.24G             3.47             6.25             1.69             11.4               53               64                0            0.469: 100% 87/87 [02:07<00:00,  1.46s/it]\n","               Class           Images          Targets                P                R          mAP@0.5               F1 RmseGradientLoss         SSIMLoss            DLoss        TotalLoss: 100% 22/22 [00:12<00:00,  1.74it/s]\n","                 all              692         3.06e+03                0                0          0.00158                0                0             21.6             21.6              357\n","\n","            Epoch          gpu_mem             GIoU              obj              cls            total          targets          ImgSize RmseGradMeanLoss    SSIM_meanLoss\n","   185/299     3.24G             3.33             5.99             1.43             10.8               64               64                0            0.469: 100% 87/87 [02:09<00:00,  1.48s/it]\n","               Class           Images          Targets                P                R          mAP@0.5               F1 RmseGradientLoss         SSIMLoss            DLoss        TotalLoss: 100% 22/22 [00:12<00:00,  1.76it/s]\n","                 all              692         3.06e+03                0                0          0.00246                0                0             21.6             21.6              336\n","\n","            Epoch          gpu_mem             GIoU              obj              cls            total          targets          ImgSize RmseGradMeanLoss    SSIM_meanLoss\n","   186/299     3.24G             3.38             6.09             1.51               11               63               64                0            0.469: 100% 87/87 [02:09<00:00,  1.49s/it]\n","               Class           Images          Targets                P                R          mAP@0.5               F1 RmseGradientLoss         SSIMLoss            DLoss        TotalLoss: 100% 22/22 [00:12<00:00,  1.74it/s]\n","                 all              692         3.06e+03                0                0          0.00111                0                0             21.6             21.6              297\n","\n","            Epoch          gpu_mem             GIoU              obj              cls            total          targets          ImgSize RmseGradMeanLoss    SSIM_meanLoss\n","   187/299     3.24G             3.26             6.09             1.58             10.9               56               64                0            0.469: 100% 87/87 [02:10<00:00,  1.50s/it]\n","               Class           Images          Targets                P                R          mAP@0.5               F1 RmseGradientLoss         SSIMLoss            DLoss        TotalLoss: 100% 22/22 [00:12<00:00,  1.70it/s]\n","                 all              692         3.06e+03                0                0          0.00172                0                0             21.6             21.6              280\n","\n","            Epoch          gpu_mem             GIoU              obj              cls            total          targets          ImgSize RmseGradMeanLoss    SSIM_meanLoss\n","   188/299     3.24G             3.17             6.17             1.44             10.8              157               64                0                1:  83% 72/87 [01:48<00:17,  1.16s/it]"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qPaxO9FgbkJN","outputId":"18b498f1-8efc-4d8d-f1cc-f7121054d177"},"source":["!python train.py --data data/customdata/custom.data --batch 32  --cache --cfg cfg/yolov3-custom.cfg --epochs 300 --weights 'weights/last.pt'  --img-size=64 --midasnet_freeze='False'"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Namespace(accumulate=4, adam=False, batch_size=32, bbox_lambda=1, bucket='', cache_images=True, cfg='cfg/yolov3-custom.cfg', data='data/customdata/custom.data', depth_lambda=1, device='', epochs=300, evolve=False, img_size=[64], init_train='False', midas_weights='', midasnet_freeze='False', multi_scale=False, name='', nosave=False, notest=False, rect=False, resume=False, single_cls=False, weights='weights/last.pt', yolo_weights='')\n","Using CUDA device0 _CudaDeviceProperties(name='Tesla V100-SXM2-16GB', total_memory=16130MB)\n","\n","2020-11-18 20:55:59.590448: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n","Run 'tensorboard --logdir=runs' to view tensorboard at http://localhost:6006/\n","cfg - cfg/yolov3-custom.cfg\n","data - data/customdata/custom.data\n","epochs - 300\n","batch_size - 32\n","accumulate - 4\n","yolo weights - \n","midas weights - \n","imgsz_min- 64, imgsz_max- 64, imgsz_test- 64\n","opt.rect - False\n","train_path - data/customdata/train.txt\n","test_path - data/customdata/test.txt\n","init_train - False\n","weights - weights/last.pt\n","midasnet_freeze - False\n","mixed_precision enabled - False\n","Init LR - 0.0001\n","Using cache found in /root/.cache/torch/hub/facebookresearch_WSL-Images_master\n","Caching labels (2623 found, 114 missing, 30 empty, 0 duplicate, for 2767 images): 100% 2767/2767 [00:03<00:00, 767.70it/s]\n","Caching images (0.1GB): 100% 2767/2767 [02:42<00:00, 17.02it/s]\n","Caching labels (657 found, 27 missing, 8 empty, 0 duplicate, for 692 images): 100% 692/692 [00:00<00:00, 734.43it/s]\n","Caching images (0.0GB): 100% 692/692 [00:41<00:00, 16.50it/s]\n","YMP Model Summary\n","----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","            Conv2d-1           [-1, 64, 32, 32]           9,408\n","       BatchNorm2d-2           [-1, 64, 32, 32]             128\n","              ReLU-3           [-1, 64, 32, 32]               0\n","         MaxPool2d-4           [-1, 64, 16, 16]               0\n","            Conv2d-5          [-1, 256, 16, 16]          16,384\n","       BatchNorm2d-6          [-1, 256, 16, 16]             512\n","              ReLU-7          [-1, 256, 16, 16]               0\n","            Conv2d-8          [-1, 256, 16, 16]          18,432\n","       BatchNorm2d-9          [-1, 256, 16, 16]             512\n","             ReLU-10          [-1, 256, 16, 16]               0\n","           Conv2d-11          [-1, 256, 16, 16]          65,536\n","      BatchNorm2d-12          [-1, 256, 16, 16]             512\n","           Conv2d-13          [-1, 256, 16, 16]          16,384\n","      BatchNorm2d-14          [-1, 256, 16, 16]             512\n","             ReLU-15          [-1, 256, 16, 16]               0\n","       Bottleneck-16          [-1, 256, 16, 16]               0\n","           Conv2d-17          [-1, 256, 16, 16]          65,536\n","      BatchNorm2d-18          [-1, 256, 16, 16]             512\n","             ReLU-19          [-1, 256, 16, 16]               0\n","           Conv2d-20          [-1, 256, 16, 16]          18,432\n","      BatchNorm2d-21          [-1, 256, 16, 16]             512\n","             ReLU-22          [-1, 256, 16, 16]               0\n","           Conv2d-23          [-1, 256, 16, 16]          65,536\n","      BatchNorm2d-24          [-1, 256, 16, 16]             512\n","             ReLU-25          [-1, 256, 16, 16]               0\n","       Bottleneck-26          [-1, 256, 16, 16]               0\n","           Conv2d-27          [-1, 256, 16, 16]          65,536\n","      BatchNorm2d-28          [-1, 256, 16, 16]             512\n","             ReLU-29          [-1, 256, 16, 16]               0\n","           Conv2d-30          [-1, 256, 16, 16]          18,432\n","      BatchNorm2d-31          [-1, 256, 16, 16]             512\n","             ReLU-32          [-1, 256, 16, 16]               0\n","           Conv2d-33          [-1, 256, 16, 16]          65,536\n","      BatchNorm2d-34          [-1, 256, 16, 16]             512\n","             ReLU-35          [-1, 256, 16, 16]               0\n","       Bottleneck-36          [-1, 256, 16, 16]               0\n","           Conv2d-37          [-1, 512, 16, 16]         131,072\n","      BatchNorm2d-38          [-1, 512, 16, 16]           1,024\n","             ReLU-39          [-1, 512, 16, 16]               0\n","           Conv2d-40            [-1, 512, 8, 8]          73,728\n","      BatchNorm2d-41            [-1, 512, 8, 8]           1,024\n","             ReLU-42            [-1, 512, 8, 8]               0\n","           Conv2d-43            [-1, 512, 8, 8]         262,144\n","      BatchNorm2d-44            [-1, 512, 8, 8]           1,024\n","           Conv2d-45            [-1, 512, 8, 8]         131,072\n","      BatchNorm2d-46            [-1, 512, 8, 8]           1,024\n","             ReLU-47            [-1, 512, 8, 8]               0\n","       Bottleneck-48            [-1, 512, 8, 8]               0\n","           Conv2d-49            [-1, 512, 8, 8]         262,144\n","      BatchNorm2d-50            [-1, 512, 8, 8]           1,024\n","             ReLU-51            [-1, 512, 8, 8]               0\n","           Conv2d-52            [-1, 512, 8, 8]          73,728\n","      BatchNorm2d-53            [-1, 512, 8, 8]           1,024\n","             ReLU-54            [-1, 512, 8, 8]               0\n","           Conv2d-55            [-1, 512, 8, 8]         262,144\n","      BatchNorm2d-56            [-1, 512, 8, 8]           1,024\n","             ReLU-57            [-1, 512, 8, 8]               0\n","       Bottleneck-58            [-1, 512, 8, 8]               0\n","           Conv2d-59            [-1, 512, 8, 8]         262,144\n","      BatchNorm2d-60            [-1, 512, 8, 8]           1,024\n","             ReLU-61            [-1, 512, 8, 8]               0\n","           Conv2d-62            [-1, 512, 8, 8]          73,728\n","      BatchNorm2d-63            [-1, 512, 8, 8]           1,024\n","             ReLU-64            [-1, 512, 8, 8]               0\n","           Conv2d-65            [-1, 512, 8, 8]         262,144\n","      BatchNorm2d-66            [-1, 512, 8, 8]           1,024\n","             ReLU-67            [-1, 512, 8, 8]               0\n","       Bottleneck-68            [-1, 512, 8, 8]               0\n","           Conv2d-69            [-1, 512, 8, 8]         262,144\n","      BatchNorm2d-70            [-1, 512, 8, 8]           1,024\n","             ReLU-71            [-1, 512, 8, 8]               0\n","           Conv2d-72            [-1, 512, 8, 8]          73,728\n","      BatchNorm2d-73            [-1, 512, 8, 8]           1,024\n","             ReLU-74            [-1, 512, 8, 8]               0\n","           Conv2d-75            [-1, 512, 8, 8]         262,144\n","      BatchNorm2d-76            [-1, 512, 8, 8]           1,024\n","             ReLU-77            [-1, 512, 8, 8]               0\n","       Bottleneck-78            [-1, 512, 8, 8]               0\n","           Conv2d-79           [-1, 1024, 8, 8]         524,288\n","      BatchNorm2d-80           [-1, 1024, 8, 8]           2,048\n","             ReLU-81           [-1, 1024, 8, 8]               0\n","           Conv2d-82           [-1, 1024, 4, 4]         294,912\n","      BatchNorm2d-83           [-1, 1024, 4, 4]           2,048\n","             ReLU-84           [-1, 1024, 4, 4]               0\n","           Conv2d-85           [-1, 1024, 4, 4]       1,048,576\n","      BatchNorm2d-86           [-1, 1024, 4, 4]           2,048\n","           Conv2d-87           [-1, 1024, 4, 4]         524,288\n","      BatchNorm2d-88           [-1, 1024, 4, 4]           2,048\n","             ReLU-89           [-1, 1024, 4, 4]               0\n","       Bottleneck-90           [-1, 1024, 4, 4]               0\n","           Conv2d-91           [-1, 1024, 4, 4]       1,048,576\n","      BatchNorm2d-92           [-1, 1024, 4, 4]           2,048\n","             ReLU-93           [-1, 1024, 4, 4]               0\n","           Conv2d-94           [-1, 1024, 4, 4]         294,912\n","      BatchNorm2d-95           [-1, 1024, 4, 4]           2,048\n","             ReLU-96           [-1, 1024, 4, 4]               0\n","           Conv2d-97           [-1, 1024, 4, 4]       1,048,576\n","      BatchNorm2d-98           [-1, 1024, 4, 4]           2,048\n","             ReLU-99           [-1, 1024, 4, 4]               0\n","      Bottleneck-100           [-1, 1024, 4, 4]               0\n","          Conv2d-101           [-1, 1024, 4, 4]       1,048,576\n","     BatchNorm2d-102           [-1, 1024, 4, 4]           2,048\n","            ReLU-103           [-1, 1024, 4, 4]               0\n","          Conv2d-104           [-1, 1024, 4, 4]         294,912\n","     BatchNorm2d-105           [-1, 1024, 4, 4]           2,048\n","            ReLU-106           [-1, 1024, 4, 4]               0\n","          Conv2d-107           [-1, 1024, 4, 4]       1,048,576\n","     BatchNorm2d-108           [-1, 1024, 4, 4]           2,048\n","            ReLU-109           [-1, 1024, 4, 4]               0\n","      Bottleneck-110           [-1, 1024, 4, 4]               0\n","          Conv2d-111           [-1, 1024, 4, 4]       1,048,576\n","     BatchNorm2d-112           [-1, 1024, 4, 4]           2,048\n","            ReLU-113           [-1, 1024, 4, 4]               0\n","          Conv2d-114           [-1, 1024, 4, 4]         294,912\n","     BatchNorm2d-115           [-1, 1024, 4, 4]           2,048\n","            ReLU-116           [-1, 1024, 4, 4]               0\n","          Conv2d-117           [-1, 1024, 4, 4]       1,048,576\n","     BatchNorm2d-118           [-1, 1024, 4, 4]           2,048\n","            ReLU-119           [-1, 1024, 4, 4]               0\n","      Bottleneck-120           [-1, 1024, 4, 4]               0\n","          Conv2d-121           [-1, 1024, 4, 4]       1,048,576\n","     BatchNorm2d-122           [-1, 1024, 4, 4]           2,048\n","            ReLU-123           [-1, 1024, 4, 4]               0\n","          Conv2d-124           [-1, 1024, 4, 4]         294,912\n","     BatchNorm2d-125           [-1, 1024, 4, 4]           2,048\n","            ReLU-126           [-1, 1024, 4, 4]               0\n","          Conv2d-127           [-1, 1024, 4, 4]       1,048,576\n","     BatchNorm2d-128           [-1, 1024, 4, 4]           2,048\n","            ReLU-129           [-1, 1024, 4, 4]               0\n","      Bottleneck-130           [-1, 1024, 4, 4]               0\n","          Conv2d-131           [-1, 1024, 4, 4]       1,048,576\n","     BatchNorm2d-132           [-1, 1024, 4, 4]           2,048\n","            ReLU-133           [-1, 1024, 4, 4]               0\n","          Conv2d-134           [-1, 1024, 4, 4]         294,912\n","     BatchNorm2d-135           [-1, 1024, 4, 4]           2,048\n","            ReLU-136           [-1, 1024, 4, 4]               0\n","          Conv2d-137           [-1, 1024, 4, 4]       1,048,576\n","     BatchNorm2d-138           [-1, 1024, 4, 4]           2,048\n","            ReLU-139           [-1, 1024, 4, 4]               0\n","      Bottleneck-140           [-1, 1024, 4, 4]               0\n","          Conv2d-141           [-1, 1024, 4, 4]       1,048,576\n","     BatchNorm2d-142           [-1, 1024, 4, 4]           2,048\n","            ReLU-143           [-1, 1024, 4, 4]               0\n","          Conv2d-144           [-1, 1024, 4, 4]         294,912\n","     BatchNorm2d-145           [-1, 1024, 4, 4]           2,048\n","            ReLU-146           [-1, 1024, 4, 4]               0\n","          Conv2d-147           [-1, 1024, 4, 4]       1,048,576\n","     BatchNorm2d-148           [-1, 1024, 4, 4]           2,048\n","            ReLU-149           [-1, 1024, 4, 4]               0\n","      Bottleneck-150           [-1, 1024, 4, 4]               0\n","          Conv2d-151           [-1, 1024, 4, 4]       1,048,576\n","     BatchNorm2d-152           [-1, 1024, 4, 4]           2,048\n","            ReLU-153           [-1, 1024, 4, 4]               0\n","          Conv2d-154           [-1, 1024, 4, 4]         294,912\n","     BatchNorm2d-155           [-1, 1024, 4, 4]           2,048\n","            ReLU-156           [-1, 1024, 4, 4]               0\n","          Conv2d-157           [-1, 1024, 4, 4]       1,048,576\n","     BatchNorm2d-158           [-1, 1024, 4, 4]           2,048\n","            ReLU-159           [-1, 1024, 4, 4]               0\n","      Bottleneck-160           [-1, 1024, 4, 4]               0\n","          Conv2d-161           [-1, 1024, 4, 4]       1,048,576\n","     BatchNorm2d-162           [-1, 1024, 4, 4]           2,048\n","            ReLU-163           [-1, 1024, 4, 4]               0\n","          Conv2d-164           [-1, 1024, 4, 4]         294,912\n","     BatchNorm2d-165           [-1, 1024, 4, 4]           2,048\n","            ReLU-166           [-1, 1024, 4, 4]               0\n","          Conv2d-167           [-1, 1024, 4, 4]       1,048,576\n","     BatchNorm2d-168           [-1, 1024, 4, 4]           2,048\n","            ReLU-169           [-1, 1024, 4, 4]               0\n","      Bottleneck-170           [-1, 1024, 4, 4]               0\n","          Conv2d-171           [-1, 1024, 4, 4]       1,048,576\n","     BatchNorm2d-172           [-1, 1024, 4, 4]           2,048\n","            ReLU-173           [-1, 1024, 4, 4]               0\n","          Conv2d-174           [-1, 1024, 4, 4]         294,912\n","     BatchNorm2d-175           [-1, 1024, 4, 4]           2,048\n","            ReLU-176           [-1, 1024, 4, 4]               0\n","          Conv2d-177           [-1, 1024, 4, 4]       1,048,576\n","     BatchNorm2d-178           [-1, 1024, 4, 4]           2,048\n","            ReLU-179           [-1, 1024, 4, 4]               0\n","      Bottleneck-180           [-1, 1024, 4, 4]               0\n","          Conv2d-181           [-1, 1024, 4, 4]       1,048,576\n","     BatchNorm2d-182           [-1, 1024, 4, 4]           2,048\n","            ReLU-183           [-1, 1024, 4, 4]               0\n","          Conv2d-184           [-1, 1024, 4, 4]         294,912\n","     BatchNorm2d-185           [-1, 1024, 4, 4]           2,048\n","            ReLU-186           [-1, 1024, 4, 4]               0\n","          Conv2d-187           [-1, 1024, 4, 4]       1,048,576\n","     BatchNorm2d-188           [-1, 1024, 4, 4]           2,048\n","            ReLU-189           [-1, 1024, 4, 4]               0\n","      Bottleneck-190           [-1, 1024, 4, 4]               0\n","          Conv2d-191           [-1, 1024, 4, 4]       1,048,576\n","     BatchNorm2d-192           [-1, 1024, 4, 4]           2,048\n","            ReLU-193           [-1, 1024, 4, 4]               0\n","          Conv2d-194           [-1, 1024, 4, 4]         294,912\n","     BatchNorm2d-195           [-1, 1024, 4, 4]           2,048\n","            ReLU-196           [-1, 1024, 4, 4]               0\n","          Conv2d-197           [-1, 1024, 4, 4]       1,048,576\n","     BatchNorm2d-198           [-1, 1024, 4, 4]           2,048\n","            ReLU-199           [-1, 1024, 4, 4]               0\n","      Bottleneck-200           [-1, 1024, 4, 4]               0\n","          Conv2d-201           [-1, 1024, 4, 4]       1,048,576\n","     BatchNorm2d-202           [-1, 1024, 4, 4]           2,048\n","            ReLU-203           [-1, 1024, 4, 4]               0\n","          Conv2d-204           [-1, 1024, 4, 4]         294,912\n","     BatchNorm2d-205           [-1, 1024, 4, 4]           2,048\n","            ReLU-206           [-1, 1024, 4, 4]               0\n","          Conv2d-207           [-1, 1024, 4, 4]       1,048,576\n","     BatchNorm2d-208           [-1, 1024, 4, 4]           2,048\n","            ReLU-209           [-1, 1024, 4, 4]               0\n","      Bottleneck-210           [-1, 1024, 4, 4]               0\n","          Conv2d-211           [-1, 1024, 4, 4]       1,048,576\n","     BatchNorm2d-212           [-1, 1024, 4, 4]           2,048\n","            ReLU-213           [-1, 1024, 4, 4]               0\n","          Conv2d-214           [-1, 1024, 4, 4]         294,912\n","     BatchNorm2d-215           [-1, 1024, 4, 4]           2,048\n","            ReLU-216           [-1, 1024, 4, 4]               0\n","          Conv2d-217           [-1, 1024, 4, 4]       1,048,576\n","     BatchNorm2d-218           [-1, 1024, 4, 4]           2,048\n","            ReLU-219           [-1, 1024, 4, 4]               0\n","      Bottleneck-220           [-1, 1024, 4, 4]               0\n","          Conv2d-221           [-1, 1024, 4, 4]       1,048,576\n","     BatchNorm2d-222           [-1, 1024, 4, 4]           2,048\n","            ReLU-223           [-1, 1024, 4, 4]               0\n","          Conv2d-224           [-1, 1024, 4, 4]         294,912\n","     BatchNorm2d-225           [-1, 1024, 4, 4]           2,048\n","            ReLU-226           [-1, 1024, 4, 4]               0\n","          Conv2d-227           [-1, 1024, 4, 4]       1,048,576\n","     BatchNorm2d-228           [-1, 1024, 4, 4]           2,048\n","            ReLU-229           [-1, 1024, 4, 4]               0\n","      Bottleneck-230           [-1, 1024, 4, 4]               0\n","          Conv2d-231           [-1, 1024, 4, 4]       1,048,576\n","     BatchNorm2d-232           [-1, 1024, 4, 4]           2,048\n","            ReLU-233           [-1, 1024, 4, 4]               0\n","          Conv2d-234           [-1, 1024, 4, 4]         294,912\n","     BatchNorm2d-235           [-1, 1024, 4, 4]           2,048\n","            ReLU-236           [-1, 1024, 4, 4]               0\n","          Conv2d-237           [-1, 1024, 4, 4]       1,048,576\n","     BatchNorm2d-238           [-1, 1024, 4, 4]           2,048\n","            ReLU-239           [-1, 1024, 4, 4]               0\n","      Bottleneck-240           [-1, 1024, 4, 4]               0\n","          Conv2d-241           [-1, 1024, 4, 4]       1,048,576\n","     BatchNorm2d-242           [-1, 1024, 4, 4]           2,048\n","            ReLU-243           [-1, 1024, 4, 4]               0\n","          Conv2d-244           [-1, 1024, 4, 4]         294,912\n","     BatchNorm2d-245           [-1, 1024, 4, 4]           2,048\n","            ReLU-246           [-1, 1024, 4, 4]               0\n","          Conv2d-247           [-1, 1024, 4, 4]       1,048,576\n","     BatchNorm2d-248           [-1, 1024, 4, 4]           2,048\n","            ReLU-249           [-1, 1024, 4, 4]               0\n","      Bottleneck-250           [-1, 1024, 4, 4]               0\n","          Conv2d-251           [-1, 1024, 4, 4]       1,048,576\n","     BatchNorm2d-252           [-1, 1024, 4, 4]           2,048\n","            ReLU-253           [-1, 1024, 4, 4]               0\n","          Conv2d-254           [-1, 1024, 4, 4]         294,912\n","     BatchNorm2d-255           [-1, 1024, 4, 4]           2,048\n","            ReLU-256           [-1, 1024, 4, 4]               0\n","          Conv2d-257           [-1, 1024, 4, 4]       1,048,576\n","     BatchNorm2d-258           [-1, 1024, 4, 4]           2,048\n","            ReLU-259           [-1, 1024, 4, 4]               0\n","      Bottleneck-260           [-1, 1024, 4, 4]               0\n","          Conv2d-261           [-1, 1024, 4, 4]       1,048,576\n","     BatchNorm2d-262           [-1, 1024, 4, 4]           2,048\n","            ReLU-263           [-1, 1024, 4, 4]               0\n","          Conv2d-264           [-1, 1024, 4, 4]         294,912\n","     BatchNorm2d-265           [-1, 1024, 4, 4]           2,048\n","            ReLU-266           [-1, 1024, 4, 4]               0\n","          Conv2d-267           [-1, 1024, 4, 4]       1,048,576\n","     BatchNorm2d-268           [-1, 1024, 4, 4]           2,048\n","            ReLU-269           [-1, 1024, 4, 4]               0\n","      Bottleneck-270           [-1, 1024, 4, 4]               0\n","          Conv2d-271           [-1, 1024, 4, 4]       1,048,576\n","     BatchNorm2d-272           [-1, 1024, 4, 4]           2,048\n","            ReLU-273           [-1, 1024, 4, 4]               0\n","          Conv2d-274           [-1, 1024, 4, 4]         294,912\n","     BatchNorm2d-275           [-1, 1024, 4, 4]           2,048\n","            ReLU-276           [-1, 1024, 4, 4]               0\n","          Conv2d-277           [-1, 1024, 4, 4]       1,048,576\n","     BatchNorm2d-278           [-1, 1024, 4, 4]           2,048\n","            ReLU-279           [-1, 1024, 4, 4]               0\n","      Bottleneck-280           [-1, 1024, 4, 4]               0\n","          Conv2d-281           [-1, 1024, 4, 4]       1,048,576\n","     BatchNorm2d-282           [-1, 1024, 4, 4]           2,048\n","            ReLU-283           [-1, 1024, 4, 4]               0\n","          Conv2d-284           [-1, 1024, 4, 4]         294,912\n","     BatchNorm2d-285           [-1, 1024, 4, 4]           2,048\n","            ReLU-286           [-1, 1024, 4, 4]               0\n","          Conv2d-287           [-1, 1024, 4, 4]       1,048,576\n","     BatchNorm2d-288           [-1, 1024, 4, 4]           2,048\n","            ReLU-289           [-1, 1024, 4, 4]               0\n","      Bottleneck-290           [-1, 1024, 4, 4]               0\n","          Conv2d-291           [-1, 1024, 4, 4]       1,048,576\n","     BatchNorm2d-292           [-1, 1024, 4, 4]           2,048\n","            ReLU-293           [-1, 1024, 4, 4]               0\n","          Conv2d-294           [-1, 1024, 4, 4]         294,912\n","     BatchNorm2d-295           [-1, 1024, 4, 4]           2,048\n","            ReLU-296           [-1, 1024, 4, 4]               0\n","          Conv2d-297           [-1, 1024, 4, 4]       1,048,576\n","     BatchNorm2d-298           [-1, 1024, 4, 4]           2,048\n","            ReLU-299           [-1, 1024, 4, 4]               0\n","      Bottleneck-300           [-1, 1024, 4, 4]               0\n","          Conv2d-301           [-1, 1024, 4, 4]       1,048,576\n","     BatchNorm2d-302           [-1, 1024, 4, 4]           2,048\n","            ReLU-303           [-1, 1024, 4, 4]               0\n","          Conv2d-304           [-1, 1024, 4, 4]         294,912\n","     BatchNorm2d-305           [-1, 1024, 4, 4]           2,048\n","            ReLU-306           [-1, 1024, 4, 4]               0\n","          Conv2d-307           [-1, 1024, 4, 4]       1,048,576\n","     BatchNorm2d-308           [-1, 1024, 4, 4]           2,048\n","            ReLU-309           [-1, 1024, 4, 4]               0\n","      Bottleneck-310           [-1, 1024, 4, 4]               0\n","          Conv2d-311           [-1, 2048, 4, 4]       2,097,152\n","     BatchNorm2d-312           [-1, 2048, 4, 4]           4,096\n","            ReLU-313           [-1, 2048, 4, 4]               0\n","          Conv2d-314           [-1, 2048, 2, 2]       1,179,648\n","     BatchNorm2d-315           [-1, 2048, 2, 2]           4,096\n","            ReLU-316           [-1, 2048, 2, 2]               0\n","          Conv2d-317           [-1, 2048, 2, 2]       4,194,304\n","     BatchNorm2d-318           [-1, 2048, 2, 2]           4,096\n","          Conv2d-319           [-1, 2048, 2, 2]       2,097,152\n","     BatchNorm2d-320           [-1, 2048, 2, 2]           4,096\n","            ReLU-321           [-1, 2048, 2, 2]               0\n","      Bottleneck-322           [-1, 2048, 2, 2]               0\n","          Conv2d-323           [-1, 2048, 2, 2]       4,194,304\n","     BatchNorm2d-324           [-1, 2048, 2, 2]           4,096\n","            ReLU-325           [-1, 2048, 2, 2]               0\n","          Conv2d-326           [-1, 2048, 2, 2]       1,179,648\n","     BatchNorm2d-327           [-1, 2048, 2, 2]           4,096\n","            ReLU-328           [-1, 2048, 2, 2]               0\n","          Conv2d-329           [-1, 2048, 2, 2]       4,194,304\n","     BatchNorm2d-330           [-1, 2048, 2, 2]           4,096\n","            ReLU-331           [-1, 2048, 2, 2]               0\n","      Bottleneck-332           [-1, 2048, 2, 2]               0\n","          Conv2d-333           [-1, 2048, 2, 2]       4,194,304\n","     BatchNorm2d-334           [-1, 2048, 2, 2]           4,096\n","            ReLU-335           [-1, 2048, 2, 2]               0\n","          Conv2d-336           [-1, 2048, 2, 2]       1,179,648\n","     BatchNorm2d-337           [-1, 2048, 2, 2]           4,096\n","            ReLU-338           [-1, 2048, 2, 2]               0\n","          Conv2d-339           [-1, 2048, 2, 2]       4,194,304\n","     BatchNorm2d-340           [-1, 2048, 2, 2]           4,096\n","            ReLU-341           [-1, 2048, 2, 2]               0\n","      Bottleneck-342           [-1, 2048, 2, 2]               0\n","          Conv2d-343          [-1, 256, 16, 16]         589,824\n","          Conv2d-344            [-1, 256, 8, 8]       1,179,648\n","          Conv2d-345            [-1, 256, 4, 4]       2,359,296\n","          Conv2d-346            [-1, 256, 2, 2]       4,718,592\n","            ReLU-347            [-1, 256, 2, 2]               0\n","          Conv2d-348            [-1, 256, 2, 2]         590,080\n","            ReLU-349            [-1, 256, 2, 2]               0\n","          Conv2d-350            [-1, 256, 2, 2]         590,080\n","ResidualConvUnit-351            [-1, 256, 2, 2]               0\n","FeatureFusionBlock-352            [-1, 256, 4, 4]               0\n","            ReLU-353            [-1, 256, 4, 4]               0\n","          Conv2d-354            [-1, 256, 4, 4]         590,080\n","            ReLU-355            [-1, 256, 4, 4]               0\n","          Conv2d-356            [-1, 256, 4, 4]         590,080\n","ResidualConvUnit-357            [-1, 256, 4, 4]               0\n","            ReLU-358            [-1, 256, 4, 4]               0\n","          Conv2d-359            [-1, 256, 4, 4]         590,080\n","            ReLU-360            [-1, 256, 4, 4]               0\n","          Conv2d-361            [-1, 256, 4, 4]         590,080\n","ResidualConvUnit-362            [-1, 256, 4, 4]               0\n","FeatureFusionBlock-363            [-1, 256, 8, 8]               0\n","            ReLU-364            [-1, 256, 8, 8]               0\n","          Conv2d-365            [-1, 256, 8, 8]         590,080\n","            ReLU-366            [-1, 256, 8, 8]               0\n","          Conv2d-367            [-1, 256, 8, 8]         590,080\n","ResidualConvUnit-368            [-1, 256, 8, 8]               0\n","            ReLU-369            [-1, 256, 8, 8]               0\n","          Conv2d-370            [-1, 256, 8, 8]         590,080\n","            ReLU-371            [-1, 256, 8, 8]               0\n","          Conv2d-372            [-1, 256, 8, 8]         590,080\n","ResidualConvUnit-373            [-1, 256, 8, 8]               0\n","FeatureFusionBlock-374          [-1, 256, 16, 16]               0\n","            ReLU-375          [-1, 256, 16, 16]               0\n","          Conv2d-376          [-1, 256, 16, 16]         590,080\n","            ReLU-377          [-1, 256, 16, 16]               0\n","          Conv2d-378          [-1, 256, 16, 16]         590,080\n","ResidualConvUnit-379          [-1, 256, 16, 16]               0\n","            ReLU-380          [-1, 256, 16, 16]               0\n","          Conv2d-381          [-1, 256, 16, 16]         590,080\n","            ReLU-382          [-1, 256, 16, 16]               0\n","          Conv2d-383          [-1, 256, 16, 16]         590,080\n","ResidualConvUnit-384          [-1, 256, 16, 16]               0\n","FeatureFusionBlock-385          [-1, 256, 32, 32]               0\n","          Conv2d-386          [-1, 128, 32, 32]         295,040\n","     Interpolate-387          [-1, 128, 64, 64]               0\n","          Conv2d-388           [-1, 32, 64, 64]          36,896\n","            ReLU-389           [-1, 32, 64, 64]               0\n","          Conv2d-390            [-1, 1, 64, 64]              33\n","            ReLU-391            [-1, 1, 64, 64]               0\n","          Conv2d-392          [-1, 256, 32, 32]           6,912\n","     BatchNorm2d-393          [-1, 256, 32, 32]             512\n","            ReLU-394          [-1, 256, 32, 32]               0\n","          Conv2d-395          [-1, 256, 16, 16]         589,824\n","     BatchNorm2d-396          [-1, 256, 16, 16]             512\n","            ReLU-397          [-1, 256, 16, 16]               0\n","          Conv2d-398            [-1, 256, 8, 8]         589,824\n","     BatchNorm2d-399            [-1, 256, 8, 8]             512\n","            ReLU-400            [-1, 256, 8, 8]               0\n","          Conv2d-401            [-1, 512, 4, 4]       1,179,648\n","     BatchNorm2d-402            [-1, 512, 4, 4]           1,024\n","            ReLU-403            [-1, 512, 4, 4]               0\n","          Conv2d-404           [-1, 1024, 2, 2]       4,718,592\n","     BatchNorm2d-405           [-1, 1024, 2, 2]           2,048\n","            ReLU-406           [-1, 1024, 2, 2]               0\n","          Conv2d-407           [-1, 1024, 2, 2]       2,097,152\n","     BatchNorm2d-408           [-1, 1024, 2, 2]           2,048\n","            ReLU-409           [-1, 1024, 2, 2]               0\n","          Conv2d-410             [-1, 27, 2, 2]          27,675\n","       YOLOLayer-411           [-1, 3, 2, 2, 9]               0\n","     Interpolate-412           [-1, 1024, 4, 4]               0\n","          Conv2d-413            [-1, 256, 4, 4]         262,144\n","     BatchNorm2d-414            [-1, 256, 4, 4]             512\n","            ReLU-415            [-1, 256, 4, 4]               0\n","          Conv2d-416            [-1, 512, 4, 4]         524,288\n","     BatchNorm2d-417            [-1, 512, 4, 4]           1,024\n","            ReLU-418            [-1, 512, 4, 4]               0\n","          Conv2d-419            [-1, 256, 4, 4]         196,608\n","     BatchNorm2d-420            [-1, 256, 4, 4]             512\n","            ReLU-421            [-1, 256, 4, 4]               0\n","          Conv2d-422            [-1, 512, 4, 4]       1,179,648\n","     BatchNorm2d-423            [-1, 512, 4, 4]           1,024\n","            ReLU-424            [-1, 512, 4, 4]               0\n","          Conv2d-425            [-1, 256, 4, 4]         131,072\n","     BatchNorm2d-426            [-1, 256, 4, 4]             512\n","            ReLU-427            [-1, 256, 4, 4]               0\n","          Conv2d-428            [-1, 512, 4, 4]       1,179,648\n","     BatchNorm2d-429            [-1, 512, 4, 4]           1,024\n","            ReLU-430            [-1, 512, 4, 4]               0\n","          Conv2d-431            [-1, 256, 4, 4]         131,072\n","     BatchNorm2d-432            [-1, 256, 4, 4]             512\n","            ReLU-433            [-1, 256, 4, 4]               0\n","          Conv2d-434            [-1, 512, 4, 4]       1,179,648\n","     BatchNorm2d-435            [-1, 512, 4, 4]           1,024\n","            ReLU-436            [-1, 512, 4, 4]               0\n","          Conv2d-437             [-1, 27, 4, 4]          13,851\n","       YOLOLayer-438           [-1, 3, 4, 4, 9]               0\n","          Conv2d-439            [-1, 256, 8, 8]         131,072\n","     BatchNorm2d-440            [-1, 256, 8, 8]             512\n","            ReLU-441            [-1, 256, 8, 8]               0\n","     Interpolate-442            [-1, 512, 8, 8]               0\n","          Conv2d-443            [-1, 128, 8, 8]          65,536\n","     BatchNorm2d-444            [-1, 128, 8, 8]             256\n","            ReLU-445            [-1, 128, 8, 8]               0\n","          Conv2d-446            [-1, 128, 8, 8]          49,152\n","     BatchNorm2d-447            [-1, 128, 8, 8]             256\n","            ReLU-448            [-1, 128, 8, 8]               0\n","          Conv2d-449            [-1, 256, 8, 8]         294,912\n","     BatchNorm2d-450            [-1, 256, 8, 8]             512\n","            ReLU-451            [-1, 256, 8, 8]               0\n","          Conv2d-452            [-1, 128, 8, 8]          32,768\n","     BatchNorm2d-453            [-1, 128, 8, 8]             256\n","            ReLU-454            [-1, 128, 8, 8]               0\n","          Conv2d-455            [-1, 256, 8, 8]         294,912\n","     BatchNorm2d-456            [-1, 256, 8, 8]             512\n","            ReLU-457            [-1, 256, 8, 8]               0\n","          Conv2d-458            [-1, 128, 8, 8]          32,768\n","     BatchNorm2d-459            [-1, 128, 8, 8]             256\n","            ReLU-460            [-1, 128, 8, 8]               0\n","          Conv2d-461            [-1, 256, 8, 8]         294,912\n","     BatchNorm2d-462            [-1, 256, 8, 8]             512\n","            ReLU-463            [-1, 256, 8, 8]               0\n","          Conv2d-464             [-1, 27, 8, 8]           6,939\n","       YOLOLayer-465           [-1, 3, 8, 8, 9]               0\n","================================================================\n","Total params: 119,409,234\n","Trainable params: 119,409,234\n","Non-trainable params: 0\n","----------------------------------------------------------------\n","Input size (MB): 0.05\n","Forward/backward pass size (MB): 92.08\n","Params size (MB): 455.51\n","Estimated Total Size (MB): 547.64\n","----------------------------------------------------------------\n","Image sizes 64 - 64 train, 64 test\n","Using 4 dataloader workers\n","Starting training for 300 epochs...\n","\n","            Epoch          gpu_mem             GIoU              obj              cls            total          targets          ImgSize RmseGradMeanLoss    SSIM_meanLoss\n","  0% 0/87 [00:00<?, ?it/s]/content/drive/My Drive/computer_vision/capstone_project/yolo_v3/utils/utils.py:613: UserWarning: This overload of nonzero is deprecated:\n","\tnonzero()\n","Consider using one of the following signatures instead:\n","\tnonzero(*, bool as_tuple) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:882.)\n","  valid = det.nonzero()\n","/usr/local/lib/python3.6/dist-packages/torch/cuda/memory.py:346: FutureWarning: torch.cuda.memory_cached has been renamed to torch.cuda.memory_reserved\n","  FutureWarning)\n","   189/299        3G             3.19              5.9              1.3             10.4               52               64                0            0.467: 100% 87/87 [02:12<00:00,  1.53s/it]\n","               Class           Images          Targets                P                R          mAP@0.5               F1 RmseGradientLoss         SSIMLoss            DLoss        TotalLoss:   0% 0/22 [00:00<?, ?it/s]Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","               Class           Images          Targets                P                R          mAP@0.5               F1 RmseGradientLoss         SSIMLoss            DLoss        TotalLoss: 100% 22/22 [00:14<00:00,  1.56it/s]\n","                 all              692         3.06e+03                0                0          0.00174                0                0             21.6             21.6              291\n","\n","            Epoch          gpu_mem             GIoU              obj              cls            total          targets          ImgSize RmseGradMeanLoss    SSIM_meanLoss\n","  0% 0/87 [00:00<?, ?it/s]/usr/local/lib/python3.6/dist-packages/torch/cuda/memory.py:346: FutureWarning: torch.cuda.memory_cached has been renamed to torch.cuda.memory_reserved\n","  FutureWarning)\n","   190/299        3G             3.24             6.28              1.4             10.9               47               64                0            0.469: 100% 87/87 [02:12<00:00,  1.52s/it]\n","               Class           Images          Targets                P                R          mAP@0.5               F1 RmseGradientLoss         SSIMLoss            DLoss        TotalLoss: 100% 22/22 [00:12<00:00,  1.70it/s]\n","                 all              692         3.06e+03                0                0          0.00137                0                0             21.6             21.6              295\n","\n","            Epoch          gpu_mem             GIoU              obj              cls            total          targets          ImgSize RmseGradMeanLoss    SSIM_meanLoss\n","   191/299        3G             3.16             6.06             1.39             10.6               68               64                0            0.469: 100% 87/87 [02:13<00:00,  1.53s/it]\n","               Class           Images          Targets                P                R          mAP@0.5               F1 RmseGradientLoss         SSIMLoss            DLoss        TotalLoss: 100% 22/22 [00:12<00:00,  1.72it/s]\n","                 all              692         3.06e+03                0                0          0.00121                0                0             21.6             21.6              290\n","\n","            Epoch          gpu_mem             GIoU              obj              cls            total          targets          ImgSize RmseGradMeanLoss    SSIM_meanLoss\n","   192/299        3G             3.37             6.05              1.6               11               48               64                0            0.469: 100% 87/87 [02:10<00:00,  1.50s/it]\n","               Class           Images          Targets                P                R          mAP@0.5               F1 RmseGradientLoss         SSIMLoss            DLoss        TotalLoss: 100% 22/22 [00:12<00:00,  1.72it/s]\n","                 all              692         3.06e+03                0                0          0.00167                0                0             21.6             21.6              344\n","\n","            Epoch          gpu_mem             GIoU              obj              cls            total          targets          ImgSize RmseGradMeanLoss    SSIM_meanLoss\n","   193/299        3G             3.13             6.13             1.38             10.6               71               64                0            0.469: 100% 87/87 [02:11<00:00,  1.51s/it]\n","               Class           Images          Targets                P                R          mAP@0.5               F1 RmseGradientLoss         SSIMLoss            DLoss        TotalLoss: 100% 22/22 [00:12<00:00,  1.75it/s]\n","                 all              692         3.06e+03                0                0          0.00185                0                0             21.6             21.6              363\n","\n","            Epoch          gpu_mem             GIoU              obj              cls            total          targets          ImgSize RmseGradMeanLoss    SSIM_meanLoss\n","   194/299        3G             3.12             5.91             1.34             10.4               71               64                0            0.469: 100% 87/87 [02:09<00:00,  1.49s/it]\n","               Class           Images          Targets                P                R          mAP@0.5               F1 RmseGradientLoss         SSIMLoss            DLoss        TotalLoss: 100% 22/22 [00:12<00:00,  1.75it/s]\n","                 all              692         3.06e+03                0                0          0.00234                0                0             21.6             21.6              357\n","\n","            Epoch          gpu_mem             GIoU              obj              cls            total          targets          ImgSize RmseGradMeanLoss    SSIM_meanLoss\n","   195/299        3G             3.15             6.08             1.32             10.6               68               64                0            0.469: 100% 87/87 [02:08<00:00,  1.48s/it]\n","               Class           Images          Targets                P                R          mAP@0.5               F1 RmseGradientLoss         SSIMLoss            DLoss        TotalLoss: 100% 22/22 [00:12<00:00,  1.75it/s]\n","                 all              692         3.06e+03                0                0          0.00116                0                0             21.6             21.6              354\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"_qi3UxeY-1I7"},"source":["## Training MidasNet only with low learning rate 0.0001 on 64x64 resolution input image"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZeYe8YAZOzHE","outputId":"29166343-afa1-4742-e5c0-4adf48b6950f"},"source":["!python train.py --data data/customdata/custom.data --batch 32  --cache --cfg cfg/yolov3-custom.cfg --epochs 300 --weights 'weights/best.pt'  --img-size=64 --midasnet_freeze='False' --yolo_freeze='True'"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Namespace(accumulate=4, adam=False, batch_size=32, bbox_lambda=1, bucket='', cache_images=True, cfg='cfg/yolov3-custom.cfg', data='data/customdata/custom.data', depth_lambda=1, device='', epochs=300, evolve=False, img_size=[64], init_train='False', midas_weights='', midasnet_freeze='False', multi_scale=False, name='', nosave=False, notest=False, rect=False, resume=False, single_cls=False, weights='weights/best.pt', yolo_freeze='True', yolo_weights='')\n","Using CUDA device0 _CudaDeviceProperties(name='Tesla V100-SXM2-16GB', total_memory=16130MB)\n","\n","2020-11-18 21:29:27.030204: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n","Run 'tensorboard --logdir=runs' to view tensorboard at http://localhost:6006/\n","cfg - cfg/yolov3-custom.cfg\n","data - data/customdata/custom.data\n","epochs - 300\n","batch_size - 32\n","accumulate - 4\n","yolo weights - \n","midas weights - \n","imgsz_min- 64, imgsz_max- 64, imgsz_test- 64\n","opt.rect - False\n","train_path - data/customdata/train.txt\n","test_path - data/customdata/test.txt\n","init_train - False\n","weights - weights/best.pt\n","midasnet_freeze - False\n","yolo_freeze - True\n","mixed_precision enabled - False\n","Init LR - 0.0001\n","Using cache found in /root/.cache/torch/hub/facebookresearch_WSL-Images_master\n","Caching labels (2623 found, 114 missing, 30 empty, 0 duplicate, for 2767 images): 100% 2767/2767 [00:03<00:00, 735.79it/s]\n","Caching images (0.1GB): 100% 2767/2767 [02:45<00:00, 16.70it/s]\n","Caching labels (657 found, 27 missing, 8 empty, 0 duplicate, for 692 images): 100% 692/692 [00:00<00:00, 719.21it/s]\n","Caching images (0.0GB): 100% 692/692 [00:42<00:00, 16.43it/s]\n","Freezing the yolo branch\n","YMP Model Summary\n","----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","            Conv2d-1           [-1, 64, 32, 32]           9,408\n","       BatchNorm2d-2           [-1, 64, 32, 32]             128\n","              ReLU-3           [-1, 64, 32, 32]               0\n","         MaxPool2d-4           [-1, 64, 16, 16]               0\n","            Conv2d-5          [-1, 256, 16, 16]          16,384\n","       BatchNorm2d-6          [-1, 256, 16, 16]             512\n","              ReLU-7          [-1, 256, 16, 16]               0\n","            Conv2d-8          [-1, 256, 16, 16]          18,432\n","       BatchNorm2d-9          [-1, 256, 16, 16]             512\n","             ReLU-10          [-1, 256, 16, 16]               0\n","           Conv2d-11          [-1, 256, 16, 16]          65,536\n","      BatchNorm2d-12          [-1, 256, 16, 16]             512\n","           Conv2d-13          [-1, 256, 16, 16]          16,384\n","      BatchNorm2d-14          [-1, 256, 16, 16]             512\n","             ReLU-15          [-1, 256, 16, 16]               0\n","       Bottleneck-16          [-1, 256, 16, 16]               0\n","           Conv2d-17          [-1, 256, 16, 16]          65,536\n","      BatchNorm2d-18          [-1, 256, 16, 16]             512\n","             ReLU-19          [-1, 256, 16, 16]               0\n","           Conv2d-20          [-1, 256, 16, 16]          18,432\n","      BatchNorm2d-21          [-1, 256, 16, 16]             512\n","             ReLU-22          [-1, 256, 16, 16]               0\n","           Conv2d-23          [-1, 256, 16, 16]          65,536\n","      BatchNorm2d-24          [-1, 256, 16, 16]             512\n","             ReLU-25          [-1, 256, 16, 16]               0\n","       Bottleneck-26          [-1, 256, 16, 16]               0\n","           Conv2d-27          [-1, 256, 16, 16]          65,536\n","      BatchNorm2d-28          [-1, 256, 16, 16]             512\n","             ReLU-29          [-1, 256, 16, 16]               0\n","           Conv2d-30          [-1, 256, 16, 16]          18,432\n","      BatchNorm2d-31          [-1, 256, 16, 16]             512\n","             ReLU-32          [-1, 256, 16, 16]               0\n","           Conv2d-33          [-1, 256, 16, 16]          65,536\n","      BatchNorm2d-34          [-1, 256, 16, 16]             512\n","             ReLU-35          [-1, 256, 16, 16]               0\n","       Bottleneck-36          [-1, 256, 16, 16]               0\n","           Conv2d-37          [-1, 512, 16, 16]         131,072\n","      BatchNorm2d-38          [-1, 512, 16, 16]           1,024\n","             ReLU-39          [-1, 512, 16, 16]               0\n","           Conv2d-40            [-1, 512, 8, 8]          73,728\n","      BatchNorm2d-41            [-1, 512, 8, 8]           1,024\n","             ReLU-42            [-1, 512, 8, 8]               0\n","           Conv2d-43            [-1, 512, 8, 8]         262,144\n","      BatchNorm2d-44            [-1, 512, 8, 8]           1,024\n","           Conv2d-45            [-1, 512, 8, 8]         131,072\n","      BatchNorm2d-46            [-1, 512, 8, 8]           1,024\n","             ReLU-47            [-1, 512, 8, 8]               0\n","       Bottleneck-48            [-1, 512, 8, 8]               0\n","           Conv2d-49            [-1, 512, 8, 8]         262,144\n","      BatchNorm2d-50            [-1, 512, 8, 8]           1,024\n","             ReLU-51            [-1, 512, 8, 8]               0\n","           Conv2d-52            [-1, 512, 8, 8]          73,728\n","      BatchNorm2d-53            [-1, 512, 8, 8]           1,024\n","             ReLU-54            [-1, 512, 8, 8]               0\n","           Conv2d-55            [-1, 512, 8, 8]         262,144\n","      BatchNorm2d-56            [-1, 512, 8, 8]           1,024\n","             ReLU-57            [-1, 512, 8, 8]               0\n","       Bottleneck-58            [-1, 512, 8, 8]               0\n","           Conv2d-59            [-1, 512, 8, 8]         262,144\n","      BatchNorm2d-60            [-1, 512, 8, 8]           1,024\n","             ReLU-61            [-1, 512, 8, 8]               0\n","           Conv2d-62            [-1, 512, 8, 8]          73,728\n","      BatchNorm2d-63            [-1, 512, 8, 8]           1,024\n","             ReLU-64            [-1, 512, 8, 8]               0\n","           Conv2d-65            [-1, 512, 8, 8]         262,144\n","      BatchNorm2d-66            [-1, 512, 8, 8]           1,024\n","             ReLU-67            [-1, 512, 8, 8]               0\n","       Bottleneck-68            [-1, 512, 8, 8]               0\n","           Conv2d-69            [-1, 512, 8, 8]         262,144\n","      BatchNorm2d-70            [-1, 512, 8, 8]           1,024\n","             ReLU-71            [-1, 512, 8, 8]               0\n","           Conv2d-72            [-1, 512, 8, 8]          73,728\n","      BatchNorm2d-73            [-1, 512, 8, 8]           1,024\n","             ReLU-74            [-1, 512, 8, 8]               0\n","           Conv2d-75            [-1, 512, 8, 8]         262,144\n","      BatchNorm2d-76            [-1, 512, 8, 8]           1,024\n","             ReLU-77            [-1, 512, 8, 8]               0\n","       Bottleneck-78            [-1, 512, 8, 8]               0\n","           Conv2d-79           [-1, 1024, 8, 8]         524,288\n","      BatchNorm2d-80           [-1, 1024, 8, 8]           2,048\n","             ReLU-81           [-1, 1024, 8, 8]               0\n","           Conv2d-82           [-1, 1024, 4, 4]         294,912\n","      BatchNorm2d-83           [-1, 1024, 4, 4]           2,048\n","             ReLU-84           [-1, 1024, 4, 4]               0\n","           Conv2d-85           [-1, 1024, 4, 4]       1,048,576\n","      BatchNorm2d-86           [-1, 1024, 4, 4]           2,048\n","           Conv2d-87           [-1, 1024, 4, 4]         524,288\n","      BatchNorm2d-88           [-1, 1024, 4, 4]           2,048\n","             ReLU-89           [-1, 1024, 4, 4]               0\n","       Bottleneck-90           [-1, 1024, 4, 4]               0\n","           Conv2d-91           [-1, 1024, 4, 4]       1,048,576\n","      BatchNorm2d-92           [-1, 1024, 4, 4]           2,048\n","             ReLU-93           [-1, 1024, 4, 4]               0\n","           Conv2d-94           [-1, 1024, 4, 4]         294,912\n","      BatchNorm2d-95           [-1, 1024, 4, 4]           2,048\n","             ReLU-96           [-1, 1024, 4, 4]               0\n","           Conv2d-97           [-1, 1024, 4, 4]       1,048,576\n","      BatchNorm2d-98           [-1, 1024, 4, 4]           2,048\n","             ReLU-99           [-1, 1024, 4, 4]               0\n","      Bottleneck-100           [-1, 1024, 4, 4]               0\n","          Conv2d-101           [-1, 1024, 4, 4]       1,048,576\n","     BatchNorm2d-102           [-1, 1024, 4, 4]           2,048\n","            ReLU-103           [-1, 1024, 4, 4]               0\n","          Conv2d-104           [-1, 1024, 4, 4]         294,912\n","     BatchNorm2d-105           [-1, 1024, 4, 4]           2,048\n","            ReLU-106           [-1, 1024, 4, 4]               0\n","          Conv2d-107           [-1, 1024, 4, 4]       1,048,576\n","     BatchNorm2d-108           [-1, 1024, 4, 4]           2,048\n","            ReLU-109           [-1, 1024, 4, 4]               0\n","      Bottleneck-110           [-1, 1024, 4, 4]               0\n","          Conv2d-111           [-1, 1024, 4, 4]       1,048,576\n","     BatchNorm2d-112           [-1, 1024, 4, 4]           2,048\n","            ReLU-113           [-1, 1024, 4, 4]               0\n","          Conv2d-114           [-1, 1024, 4, 4]         294,912\n","     BatchNorm2d-115           [-1, 1024, 4, 4]           2,048\n","            ReLU-116           [-1, 1024, 4, 4]               0\n","          Conv2d-117           [-1, 1024, 4, 4]       1,048,576\n","     BatchNorm2d-118           [-1, 1024, 4, 4]           2,048\n","            ReLU-119           [-1, 1024, 4, 4]               0\n","      Bottleneck-120           [-1, 1024, 4, 4]               0\n","          Conv2d-121           [-1, 1024, 4, 4]       1,048,576\n","     BatchNorm2d-122           [-1, 1024, 4, 4]           2,048\n","            ReLU-123           [-1, 1024, 4, 4]               0\n","          Conv2d-124           [-1, 1024, 4, 4]         294,912\n","     BatchNorm2d-125           [-1, 1024, 4, 4]           2,048\n","            ReLU-126           [-1, 1024, 4, 4]               0\n","          Conv2d-127           [-1, 1024, 4, 4]       1,048,576\n","     BatchNorm2d-128           [-1, 1024, 4, 4]           2,048\n","            ReLU-129           [-1, 1024, 4, 4]               0\n","      Bottleneck-130           [-1, 1024, 4, 4]               0\n","          Conv2d-131           [-1, 1024, 4, 4]       1,048,576\n","     BatchNorm2d-132           [-1, 1024, 4, 4]           2,048\n","            ReLU-133           [-1, 1024, 4, 4]               0\n","          Conv2d-134           [-1, 1024, 4, 4]         294,912\n","     BatchNorm2d-135           [-1, 1024, 4, 4]           2,048\n","            ReLU-136           [-1, 1024, 4, 4]               0\n","          Conv2d-137           [-1, 1024, 4, 4]       1,048,576\n","     BatchNorm2d-138           [-1, 1024, 4, 4]           2,048\n","            ReLU-139           [-1, 1024, 4, 4]               0\n","      Bottleneck-140           [-1, 1024, 4, 4]               0\n","          Conv2d-141           [-1, 1024, 4, 4]       1,048,576\n","     BatchNorm2d-142           [-1, 1024, 4, 4]           2,048\n","            ReLU-143           [-1, 1024, 4, 4]               0\n","          Conv2d-144           [-1, 1024, 4, 4]         294,912\n","     BatchNorm2d-145           [-1, 1024, 4, 4]           2,048\n","            ReLU-146           [-1, 1024, 4, 4]               0\n","          Conv2d-147           [-1, 1024, 4, 4]       1,048,576\n","     BatchNorm2d-148           [-1, 1024, 4, 4]           2,048\n","            ReLU-149           [-1, 1024, 4, 4]               0\n","      Bottleneck-150           [-1, 1024, 4, 4]               0\n","          Conv2d-151           [-1, 1024, 4, 4]       1,048,576\n","     BatchNorm2d-152           [-1, 1024, 4, 4]           2,048\n","            ReLU-153           [-1, 1024, 4, 4]               0\n","          Conv2d-154           [-1, 1024, 4, 4]         294,912\n","     BatchNorm2d-155           [-1, 1024, 4, 4]           2,048\n","            ReLU-156           [-1, 1024, 4, 4]               0\n","          Conv2d-157           [-1, 1024, 4, 4]       1,048,576\n","     BatchNorm2d-158           [-1, 1024, 4, 4]           2,048\n","            ReLU-159           [-1, 1024, 4, 4]               0\n","      Bottleneck-160           [-1, 1024, 4, 4]               0\n","          Conv2d-161           [-1, 1024, 4, 4]       1,048,576\n","     BatchNorm2d-162           [-1, 1024, 4, 4]           2,048\n","            ReLU-163           [-1, 1024, 4, 4]               0\n","          Conv2d-164           [-1, 1024, 4, 4]         294,912\n","     BatchNorm2d-165           [-1, 1024, 4, 4]           2,048\n","            ReLU-166           [-1, 1024, 4, 4]               0\n","          Conv2d-167           [-1, 1024, 4, 4]       1,048,576\n","     BatchNorm2d-168           [-1, 1024, 4, 4]           2,048\n","            ReLU-169           [-1, 1024, 4, 4]               0\n","      Bottleneck-170           [-1, 1024, 4, 4]               0\n","          Conv2d-171           [-1, 1024, 4, 4]       1,048,576\n","     BatchNorm2d-172           [-1, 1024, 4, 4]           2,048\n","            ReLU-173           [-1, 1024, 4, 4]               0\n","          Conv2d-174           [-1, 1024, 4, 4]         294,912\n","     BatchNorm2d-175           [-1, 1024, 4, 4]           2,048\n","            ReLU-176           [-1, 1024, 4, 4]               0\n","          Conv2d-177           [-1, 1024, 4, 4]       1,048,576\n","     BatchNorm2d-178           [-1, 1024, 4, 4]           2,048\n","            ReLU-179           [-1, 1024, 4, 4]               0\n","      Bottleneck-180           [-1, 1024, 4, 4]               0\n","          Conv2d-181           [-1, 1024, 4, 4]       1,048,576\n","     BatchNorm2d-182           [-1, 1024, 4, 4]           2,048\n","            ReLU-183           [-1, 1024, 4, 4]               0\n","          Conv2d-184           [-1, 1024, 4, 4]         294,912\n","     BatchNorm2d-185           [-1, 1024, 4, 4]           2,048\n","            ReLU-186           [-1, 1024, 4, 4]               0\n","          Conv2d-187           [-1, 1024, 4, 4]       1,048,576\n","     BatchNorm2d-188           [-1, 1024, 4, 4]           2,048\n","            ReLU-189           [-1, 1024, 4, 4]               0\n","      Bottleneck-190           [-1, 1024, 4, 4]               0\n","          Conv2d-191           [-1, 1024, 4, 4]       1,048,576\n","     BatchNorm2d-192           [-1, 1024, 4, 4]           2,048\n","            ReLU-193           [-1, 1024, 4, 4]               0\n","          Conv2d-194           [-1, 1024, 4, 4]         294,912\n","     BatchNorm2d-195           [-1, 1024, 4, 4]           2,048\n","            ReLU-196           [-1, 1024, 4, 4]               0\n","          Conv2d-197           [-1, 1024, 4, 4]       1,048,576\n","     BatchNorm2d-198           [-1, 1024, 4, 4]           2,048\n","            ReLU-199           [-1, 1024, 4, 4]               0\n","      Bottleneck-200           [-1, 1024, 4, 4]               0\n","          Conv2d-201           [-1, 1024, 4, 4]       1,048,576\n","     BatchNorm2d-202           [-1, 1024, 4, 4]           2,048\n","            ReLU-203           [-1, 1024, 4, 4]               0\n","          Conv2d-204           [-1, 1024, 4, 4]         294,912\n","     BatchNorm2d-205           [-1, 1024, 4, 4]           2,048\n","            ReLU-206           [-1, 1024, 4, 4]               0\n","          Conv2d-207           [-1, 1024, 4, 4]       1,048,576\n","     BatchNorm2d-208           [-1, 1024, 4, 4]           2,048\n","            ReLU-209           [-1, 1024, 4, 4]               0\n","      Bottleneck-210           [-1, 1024, 4, 4]               0\n","          Conv2d-211           [-1, 1024, 4, 4]       1,048,576\n","     BatchNorm2d-212           [-1, 1024, 4, 4]           2,048\n","            ReLU-213           [-1, 1024, 4, 4]               0\n","          Conv2d-214           [-1, 1024, 4, 4]         294,912\n","     BatchNorm2d-215           [-1, 1024, 4, 4]           2,048\n","            ReLU-216           [-1, 1024, 4, 4]               0\n","          Conv2d-217           [-1, 1024, 4, 4]       1,048,576\n","     BatchNorm2d-218           [-1, 1024, 4, 4]           2,048\n","            ReLU-219           [-1, 1024, 4, 4]               0\n","      Bottleneck-220           [-1, 1024, 4, 4]               0\n","          Conv2d-221           [-1, 1024, 4, 4]       1,048,576\n","     BatchNorm2d-222           [-1, 1024, 4, 4]           2,048\n","            ReLU-223           [-1, 1024, 4, 4]               0\n","          Conv2d-224           [-1, 1024, 4, 4]         294,912\n","     BatchNorm2d-225           [-1, 1024, 4, 4]           2,048\n","            ReLU-226           [-1, 1024, 4, 4]               0\n","          Conv2d-227           [-1, 1024, 4, 4]       1,048,576\n","     BatchNorm2d-228           [-1, 1024, 4, 4]           2,048\n","            ReLU-229           [-1, 1024, 4, 4]               0\n","      Bottleneck-230           [-1, 1024, 4, 4]               0\n","          Conv2d-231           [-1, 1024, 4, 4]       1,048,576\n","     BatchNorm2d-232           [-1, 1024, 4, 4]           2,048\n","            ReLU-233           [-1, 1024, 4, 4]               0\n","          Conv2d-234           [-1, 1024, 4, 4]         294,912\n","     BatchNorm2d-235           [-1, 1024, 4, 4]           2,048\n","            ReLU-236           [-1, 1024, 4, 4]               0\n","          Conv2d-237           [-1, 1024, 4, 4]       1,048,576\n","     BatchNorm2d-238           [-1, 1024, 4, 4]           2,048\n","            ReLU-239           [-1, 1024, 4, 4]               0\n","      Bottleneck-240           [-1, 1024, 4, 4]               0\n","          Conv2d-241           [-1, 1024, 4, 4]       1,048,576\n","     BatchNorm2d-242           [-1, 1024, 4, 4]           2,048\n","            ReLU-243           [-1, 1024, 4, 4]               0\n","          Conv2d-244           [-1, 1024, 4, 4]         294,912\n","     BatchNorm2d-245           [-1, 1024, 4, 4]           2,048\n","            ReLU-246           [-1, 1024, 4, 4]               0\n","          Conv2d-247           [-1, 1024, 4, 4]       1,048,576\n","     BatchNorm2d-248           [-1, 1024, 4, 4]           2,048\n","            ReLU-249           [-1, 1024, 4, 4]               0\n","      Bottleneck-250           [-1, 1024, 4, 4]               0\n","          Conv2d-251           [-1, 1024, 4, 4]       1,048,576\n","     BatchNorm2d-252           [-1, 1024, 4, 4]           2,048\n","            ReLU-253           [-1, 1024, 4, 4]               0\n","          Conv2d-254           [-1, 1024, 4, 4]         294,912\n","     BatchNorm2d-255           [-1, 1024, 4, 4]           2,048\n","            ReLU-256           [-1, 1024, 4, 4]               0\n","          Conv2d-257           [-1, 1024, 4, 4]       1,048,576\n","     BatchNorm2d-258           [-1, 1024, 4, 4]           2,048\n","            ReLU-259           [-1, 1024, 4, 4]               0\n","      Bottleneck-260           [-1, 1024, 4, 4]               0\n","          Conv2d-261           [-1, 1024, 4, 4]       1,048,576\n","     BatchNorm2d-262           [-1, 1024, 4, 4]           2,048\n","            ReLU-263           [-1, 1024, 4, 4]               0\n","          Conv2d-264           [-1, 1024, 4, 4]         294,912\n","     BatchNorm2d-265           [-1, 1024, 4, 4]           2,048\n","            ReLU-266           [-1, 1024, 4, 4]               0\n","          Conv2d-267           [-1, 1024, 4, 4]       1,048,576\n","     BatchNorm2d-268           [-1, 1024, 4, 4]           2,048\n","            ReLU-269           [-1, 1024, 4, 4]               0\n","      Bottleneck-270           [-1, 1024, 4, 4]               0\n","          Conv2d-271           [-1, 1024, 4, 4]       1,048,576\n","     BatchNorm2d-272           [-1, 1024, 4, 4]           2,048\n","            ReLU-273           [-1, 1024, 4, 4]               0\n","          Conv2d-274           [-1, 1024, 4, 4]         294,912\n","     BatchNorm2d-275           [-1, 1024, 4, 4]           2,048\n","            ReLU-276           [-1, 1024, 4, 4]               0\n","          Conv2d-277           [-1, 1024, 4, 4]       1,048,576\n","     BatchNorm2d-278           [-1, 1024, 4, 4]           2,048\n","            ReLU-279           [-1, 1024, 4, 4]               0\n","      Bottleneck-280           [-1, 1024, 4, 4]               0\n","          Conv2d-281           [-1, 1024, 4, 4]       1,048,576\n","     BatchNorm2d-282           [-1, 1024, 4, 4]           2,048\n","            ReLU-283           [-1, 1024, 4, 4]               0\n","          Conv2d-284           [-1, 1024, 4, 4]         294,912\n","     BatchNorm2d-285           [-1, 1024, 4, 4]           2,048\n","            ReLU-286           [-1, 1024, 4, 4]               0\n","          Conv2d-287           [-1, 1024, 4, 4]       1,048,576\n","     BatchNorm2d-288           [-1, 1024, 4, 4]           2,048\n","            ReLU-289           [-1, 1024, 4, 4]               0\n","      Bottleneck-290           [-1, 1024, 4, 4]               0\n","          Conv2d-291           [-1, 1024, 4, 4]       1,048,576\n","     BatchNorm2d-292           [-1, 1024, 4, 4]           2,048\n","            ReLU-293           [-1, 1024, 4, 4]               0\n","          Conv2d-294           [-1, 1024, 4, 4]         294,912\n","     BatchNorm2d-295           [-1, 1024, 4, 4]           2,048\n","            ReLU-296           [-1, 1024, 4, 4]               0\n","          Conv2d-297           [-1, 1024, 4, 4]       1,048,576\n","     BatchNorm2d-298           [-1, 1024, 4, 4]           2,048\n","            ReLU-299           [-1, 1024, 4, 4]               0\n","      Bottleneck-300           [-1, 1024, 4, 4]               0\n","          Conv2d-301           [-1, 1024, 4, 4]       1,048,576\n","     BatchNorm2d-302           [-1, 1024, 4, 4]           2,048\n","            ReLU-303           [-1, 1024, 4, 4]               0\n","          Conv2d-304           [-1, 1024, 4, 4]         294,912\n","     BatchNorm2d-305           [-1, 1024, 4, 4]           2,048\n","            ReLU-306           [-1, 1024, 4, 4]               0\n","          Conv2d-307           [-1, 1024, 4, 4]       1,048,576\n","     BatchNorm2d-308           [-1, 1024, 4, 4]           2,048\n","            ReLU-309           [-1, 1024, 4, 4]               0\n","      Bottleneck-310           [-1, 1024, 4, 4]               0\n","          Conv2d-311           [-1, 2048, 4, 4]       2,097,152\n","     BatchNorm2d-312           [-1, 2048, 4, 4]           4,096\n","            ReLU-313           [-1, 2048, 4, 4]               0\n","          Conv2d-314           [-1, 2048, 2, 2]       1,179,648\n","     BatchNorm2d-315           [-1, 2048, 2, 2]           4,096\n","            ReLU-316           [-1, 2048, 2, 2]               0\n","          Conv2d-317           [-1, 2048, 2, 2]       4,194,304\n","     BatchNorm2d-318           [-1, 2048, 2, 2]           4,096\n","          Conv2d-319           [-1, 2048, 2, 2]       2,097,152\n","     BatchNorm2d-320           [-1, 2048, 2, 2]           4,096\n","            ReLU-321           [-1, 2048, 2, 2]               0\n","      Bottleneck-322           [-1, 2048, 2, 2]               0\n","          Conv2d-323           [-1, 2048, 2, 2]       4,194,304\n","     BatchNorm2d-324           [-1, 2048, 2, 2]           4,096\n","            ReLU-325           [-1, 2048, 2, 2]               0\n","          Conv2d-326           [-1, 2048, 2, 2]       1,179,648\n","     BatchNorm2d-327           [-1, 2048, 2, 2]           4,096\n","            ReLU-328           [-1, 2048, 2, 2]               0\n","          Conv2d-329           [-1, 2048, 2, 2]       4,194,304\n","     BatchNorm2d-330           [-1, 2048, 2, 2]           4,096\n","            ReLU-331           [-1, 2048, 2, 2]               0\n","      Bottleneck-332           [-1, 2048, 2, 2]               0\n","          Conv2d-333           [-1, 2048, 2, 2]       4,194,304\n","     BatchNorm2d-334           [-1, 2048, 2, 2]           4,096\n","            ReLU-335           [-1, 2048, 2, 2]               0\n","          Conv2d-336           [-1, 2048, 2, 2]       1,179,648\n","     BatchNorm2d-337           [-1, 2048, 2, 2]           4,096\n","            ReLU-338           [-1, 2048, 2, 2]               0\n","          Conv2d-339           [-1, 2048, 2, 2]       4,194,304\n","     BatchNorm2d-340           [-1, 2048, 2, 2]           4,096\n","            ReLU-341           [-1, 2048, 2, 2]               0\n","      Bottleneck-342           [-1, 2048, 2, 2]               0\n","          Conv2d-343          [-1, 256, 16, 16]         589,824\n","          Conv2d-344            [-1, 256, 8, 8]       1,179,648\n","          Conv2d-345            [-1, 256, 4, 4]       2,359,296\n","          Conv2d-346            [-1, 256, 2, 2]       4,718,592\n","            ReLU-347            [-1, 256, 2, 2]               0\n","          Conv2d-348            [-1, 256, 2, 2]         590,080\n","            ReLU-349            [-1, 256, 2, 2]               0\n","          Conv2d-350            [-1, 256, 2, 2]         590,080\n","ResidualConvUnit-351            [-1, 256, 2, 2]               0\n","FeatureFusionBlock-352            [-1, 256, 4, 4]               0\n","            ReLU-353            [-1, 256, 4, 4]               0\n","          Conv2d-354            [-1, 256, 4, 4]         590,080\n","            ReLU-355            [-1, 256, 4, 4]               0\n","          Conv2d-356            [-1, 256, 4, 4]         590,080\n","ResidualConvUnit-357            [-1, 256, 4, 4]               0\n","            ReLU-358            [-1, 256, 4, 4]               0\n","          Conv2d-359            [-1, 256, 4, 4]         590,080\n","            ReLU-360            [-1, 256, 4, 4]               0\n","          Conv2d-361            [-1, 256, 4, 4]         590,080\n","ResidualConvUnit-362            [-1, 256, 4, 4]               0\n","FeatureFusionBlock-363            [-1, 256, 8, 8]               0\n","            ReLU-364            [-1, 256, 8, 8]               0\n","          Conv2d-365            [-1, 256, 8, 8]         590,080\n","            ReLU-366            [-1, 256, 8, 8]               0\n","          Conv2d-367            [-1, 256, 8, 8]         590,080\n","ResidualConvUnit-368            [-1, 256, 8, 8]               0\n","            ReLU-369            [-1, 256, 8, 8]               0\n","          Conv2d-370            [-1, 256, 8, 8]         590,080\n","            ReLU-371            [-1, 256, 8, 8]               0\n","          Conv2d-372            [-1, 256, 8, 8]         590,080\n","ResidualConvUnit-373            [-1, 256, 8, 8]               0\n","FeatureFusionBlock-374          [-1, 256, 16, 16]               0\n","            ReLU-375          [-1, 256, 16, 16]               0\n","          Conv2d-376          [-1, 256, 16, 16]         590,080\n","            ReLU-377          [-1, 256, 16, 16]               0\n","          Conv2d-378          [-1, 256, 16, 16]         590,080\n","ResidualConvUnit-379          [-1, 256, 16, 16]               0\n","            ReLU-380          [-1, 256, 16, 16]               0\n","          Conv2d-381          [-1, 256, 16, 16]         590,080\n","            ReLU-382          [-1, 256, 16, 16]               0\n","          Conv2d-383          [-1, 256, 16, 16]         590,080\n","ResidualConvUnit-384          [-1, 256, 16, 16]               0\n","FeatureFusionBlock-385          [-1, 256, 32, 32]               0\n","          Conv2d-386          [-1, 128, 32, 32]         295,040\n","     Interpolate-387          [-1, 128, 64, 64]               0\n","          Conv2d-388           [-1, 32, 64, 64]          36,896\n","            ReLU-389           [-1, 32, 64, 64]               0\n","          Conv2d-390            [-1, 1, 64, 64]              33\n","            ReLU-391            [-1, 1, 64, 64]               0\n","          Conv2d-392          [-1, 256, 32, 32]           6,912\n","     BatchNorm2d-393          [-1, 256, 32, 32]             512\n","            ReLU-394          [-1, 256, 32, 32]               0\n","          Conv2d-395          [-1, 256, 16, 16]         589,824\n","     BatchNorm2d-396          [-1, 256, 16, 16]             512\n","            ReLU-397          [-1, 256, 16, 16]               0\n","          Conv2d-398            [-1, 256, 8, 8]         589,824\n","     BatchNorm2d-399            [-1, 256, 8, 8]             512\n","            ReLU-400            [-1, 256, 8, 8]               0\n","          Conv2d-401            [-1, 512, 4, 4]       1,179,648\n","     BatchNorm2d-402            [-1, 512, 4, 4]           1,024\n","            ReLU-403            [-1, 512, 4, 4]               0\n","          Conv2d-404           [-1, 1024, 2, 2]       4,718,592\n","     BatchNorm2d-405           [-1, 1024, 2, 2]           2,048\n","            ReLU-406           [-1, 1024, 2, 2]               0\n","          Conv2d-407           [-1, 1024, 2, 2]       2,097,152\n","     BatchNorm2d-408           [-1, 1024, 2, 2]           2,048\n","            ReLU-409           [-1, 1024, 2, 2]               0\n","          Conv2d-410             [-1, 27, 2, 2]          27,675\n","       YOLOLayer-411           [-1, 3, 2, 2, 9]               0\n","     Interpolate-412           [-1, 1024, 4, 4]               0\n","          Conv2d-413            [-1, 256, 4, 4]         262,144\n","     BatchNorm2d-414            [-1, 256, 4, 4]             512\n","            ReLU-415            [-1, 256, 4, 4]               0\n","          Conv2d-416            [-1, 512, 4, 4]         524,288\n","     BatchNorm2d-417            [-1, 512, 4, 4]           1,024\n","            ReLU-418            [-1, 512, 4, 4]               0\n","          Conv2d-419            [-1, 256, 4, 4]         196,608\n","     BatchNorm2d-420            [-1, 256, 4, 4]             512\n","            ReLU-421            [-1, 256, 4, 4]               0\n","          Conv2d-422            [-1, 512, 4, 4]       1,179,648\n","     BatchNorm2d-423            [-1, 512, 4, 4]           1,024\n","            ReLU-424            [-1, 512, 4, 4]               0\n","          Conv2d-425            [-1, 256, 4, 4]         131,072\n","     BatchNorm2d-426            [-1, 256, 4, 4]             512\n","            ReLU-427            [-1, 256, 4, 4]               0\n","          Conv2d-428            [-1, 512, 4, 4]       1,179,648\n","     BatchNorm2d-429            [-1, 512, 4, 4]           1,024\n","            ReLU-430            [-1, 512, 4, 4]               0\n","          Conv2d-431            [-1, 256, 4, 4]         131,072\n","     BatchNorm2d-432            [-1, 256, 4, 4]             512\n","            ReLU-433            [-1, 256, 4, 4]               0\n","          Conv2d-434            [-1, 512, 4, 4]       1,179,648\n","     BatchNorm2d-435            [-1, 512, 4, 4]           1,024\n","            ReLU-436            [-1, 512, 4, 4]               0\n","          Conv2d-437             [-1, 27, 4, 4]          13,851\n","       YOLOLayer-438           [-1, 3, 4, 4, 9]               0\n","          Conv2d-439            [-1, 256, 8, 8]         131,072\n","     BatchNorm2d-440            [-1, 256, 8, 8]             512\n","            ReLU-441            [-1, 256, 8, 8]               0\n","     Interpolate-442            [-1, 512, 8, 8]               0\n","          Conv2d-443            [-1, 128, 8, 8]          65,536\n","     BatchNorm2d-444            [-1, 128, 8, 8]             256\n","            ReLU-445            [-1, 128, 8, 8]               0\n","          Conv2d-446            [-1, 128, 8, 8]          49,152\n","     BatchNorm2d-447            [-1, 128, 8, 8]             256\n","            ReLU-448            [-1, 128, 8, 8]               0\n","          Conv2d-449            [-1, 256, 8, 8]         294,912\n","     BatchNorm2d-450            [-1, 256, 8, 8]             512\n","            ReLU-451            [-1, 256, 8, 8]               0\n","          Conv2d-452            [-1, 128, 8, 8]          32,768\n","     BatchNorm2d-453            [-1, 128, 8, 8]             256\n","            ReLU-454            [-1, 128, 8, 8]               0\n","          Conv2d-455            [-1, 256, 8, 8]         294,912\n","     BatchNorm2d-456            [-1, 256, 8, 8]             512\n","            ReLU-457            [-1, 256, 8, 8]               0\n","          Conv2d-458            [-1, 128, 8, 8]          32,768\n","     BatchNorm2d-459            [-1, 128, 8, 8]             256\n","            ReLU-460            [-1, 128, 8, 8]               0\n","          Conv2d-461            [-1, 256, 8, 8]         294,912\n","     BatchNorm2d-462            [-1, 256, 8, 8]             512\n","            ReLU-463            [-1, 256, 8, 8]               0\n","          Conv2d-464             [-1, 27, 8, 8]           6,939\n","       YOLOLayer-465           [-1, 3, 8, 8, 9]               0\n","================================================================\n","Total params: 119,409,234\n","Trainable params: 104,182,785\n","Non-trainable params: 15,226,449\n","----------------------------------------------------------------\n","Input size (MB): 0.05\n","Forward/backward pass size (MB): 92.08\n","Params size (MB): 455.51\n","Estimated Total Size (MB): 547.64\n","----------------------------------------------------------------\n","Image sizes 64 - 64 train, 64 test\n","Using 4 dataloader workers\n","Starting training for 300 epochs...\n","\n","            Epoch          gpu_mem             GIoU              obj              cls            total          targets          ImgSize RmseGradMeanLoss    SSIM_meanLoss\n","  0% 0/87 [00:00<?, ?it/s]/content/drive/My Drive/computer_vision/capstone_project/yolo_v3/utils/utils.py:613: UserWarning: This overload of nonzero is deprecated:\n","\tnonzero()\n","Consider using one of the following signatures instead:\n","\tnonzero(*, bool as_tuple) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:882.)\n","  valid = det.nonzero()\n","/usr/local/lib/python3.6/dist-packages/torch/cuda/memory.py:346: FutureWarning: torch.cuda.memory_cached has been renamed to torch.cuda.memory_reserved\n","  FutureWarning)\n","   176/299     3.05G             4.94             9.57             3.53               18               52               64                0.042            0.169: 100% 87/87 [02:14<00:00,  1.54s/it]\n","               Class           Images          Targets                P                R          mAP@0.5               F1 RmseGradientLoss         SSIMLoss            DLoss        TotalLoss:   0% 0/22 [00:00<?, ?it/s]Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","               Class           Images          Targets                P                R          mAP@0.5               F1 RmseGradientLoss         SSIMLoss            DLoss        TotalLoss: 100% 22/22 [00:11<00:00,  1.85it/s]\n","                 all              692         3.06e+03                0                0         0.000625                0                0.704             4.4             5.104             5.104\n","\n","            Epoch          gpu_mem             GIoU              obj              cls            total          targets          ImgSize RmseGradMeanLoss    SSIM_meanLoss\n","  0% 0/87 [00:00<?, ?it/s]/usr/local/lib/python3.6/dist-packages/torch/cuda/memory.py:346: FutureWarning: torch.cuda.memory_cached has been renamed to torch.cuda.memory_reserved\n","  FutureWarning)\n","   177/299     3.05G             4.85             10.2              3.5             18.5               47               64                0.041            0.153: 100% 87/87 [02:15<00:00,  1.56s/it]\n","               Class           Images          Targets                P                R          mAP@0.5               F1 RmseGradientLoss         SSIMLoss            DLoss        TotalLoss: 100% 22/22 [00:10<00:00,  2.03it/s]\n","                 all              692         3.06e+03                0                0                0                0             0.682             4.18             4.862             4.862\n","\n","            Epoch          gpu_mem             GIoU              obj              cls            total          targets          ImgSize RmseGradMeanLoss    SSIM_meanLoss\n","   178/299     3.05G             5.08             10.2             3.91             19.2               68               64               0.0402            0.152: 100% 87/87 [02:16<00:00,  1.57s/it]\n","               Class           Images          Targets                P                R          mAP@0.5               F1 RmseGradientLoss         SSIMLoss            DLoss        TotalLoss: 100% 22/22 [00:12<00:00,  1.81it/s]\n","                 all              692         3.06e+03                0                0                0                0.638                           3.74              4.378              4.378\n","\n","            Epoch          gpu_mem             GIoU              obj              cls            total          targets          ImgSize RmseGradMeanLoss    SSIM_meanLoss\n","   179/299     3.05G             5.34             10.4             4.13             19.8               48               64             0.035            0.143: 100% 87/87 [02:15<00:00,  1.56s/it]\n","               Class           Images          Targets                P                R          mAP@0.5               F1 RmseGradientLoss         SSIMLoss            DLoss        TotalLoss: 100% 22/22 [00:12<00:00,  1.79it/s]\n","                 all              692         3.06e+03                0                0         1.66e-05                0             0.55             3.52              4.07              4.07\n","\n","            Epoch          gpu_mem             GIoU              obj              cls            total          targets          ImgSize RmseGradMeanLoss    SSIM_meanLoss\n","   180/299     3.05G             5.17             10.5             3.91             19.5               71               64             0.035            0.144: 100% 87/87 [02:15<00:00,  1.55s/it]\n","               Class           Images          Targets                P                R          mAP@0.5               F1 RmseGradientLoss         SSIMLoss            DLoss        TotalLoss: 100% 22/22 [00:11<00:00,  1.84it/s]\n","                 all              692         3.06e+03                0                0         1.01e-05                0              0.506             3.52              4.026              4.026\n","\n","            Epoch          gpu_mem             GIoU              obj              cls            total          targets          ImgSize RmseGradMeanLoss    SSIM_meanLoss\n","   181/299     3.05G              5.2             10.2             3.88             19.2               71               64             0.032            0.139: 100% 87/87 [02:13<00:00,  1.54s/it]\n","               Class           Images          Targets                P                R          mAP@0.5               F1 RmseGradientLoss         SSIMLoss            DLoss        TotalLoss: 100% 22/22 [00:11<00:00,  1.89it/s]\n","                 all              692         3.06e+03                0                0         8.79e-06                0              0.462             3.3              3.762              3.762\n","\n","            Epoch          gpu_mem             GIoU              obj              cls            total          targets          ImgSize RmseGradMeanLoss    SSIM_meanLoss\n","   182/299     3.05G             5.23             10.3             4.03             19.6               68               64             0.029            0.14: 100% 87/87 [02:12<00:00,  1.53s/it]\n","               Class           Images          Targets                P                R          mAP@0.5               F1 RmseGradientLoss         SSIMLoss            DLoss        TotalLoss: 100% 22/22 [00:11<00:00,  1.88it/s]\n","                 all              692         3.06e+03                0                0         1.62e-05                0             0.418             3.08               3.498               3.498\n","\n","            Epoch          gpu_mem             GIoU              obj              cls            total          targets          ImgSize RmseGradMeanLoss    SSIM_meanLoss\n","   183/299     3.05G             5.16             10.3             3.93             19.4               65               64               0.0296            0.145: 100% 87/87 [02:13<00:00,  1.54s/it]\n","               Class           Images          Targets                P                R          mAP@0.5               F1 RmseGradientLoss         SSIMLoss            DLoss        TotalLoss: 100% 22/22 [00:11<00:00,  1.87it/s]\n","                 all              692         3.06e+03                0                0         8.83e-06                0              0.374             2.86              3.234              3.234\n","\n","            Epoch          gpu_mem             GIoU              obj              cls            total          targets          ImgSize RmseGradMeanLoss    SSIM_meanLoss\n","   184/299     3.05G              5.3             10.6                4             19.9               53               64             0.028            0.139: 100% 87/87 [02:14<00:00,  1.54s/it]\n","               Class           Images          Targets                P                R          mAP@0.5               F1 RmseGradientLoss         SSIMLoss            DLoss        TotalLoss: 100% 22/22 [00:12<00:00,  1.77it/s]\n","                 all              692         3.06e+03                0                0         1.45e-06                0             0.33             2.641             2.971             2.971\n","\n","            Epoch          gpu_mem             GIoU              obj              cls            total          targets          ImgSize RmseGradMeanLoss    SSIM_meanLoss\n","   185/299     3.05G             5.25              9.9             4.03             19.2               64               64             0.0273            0.135: 100% 87/87 [02:13<00:00,  1.54s/it]\n","               Class           Images          Targets                P                R          mAP@0.5               F1 RmseGradientLoss         SSIMLoss            DLoss        TotalLoss: 100% 22/22 [00:11<00:00,  1.86it/s]\n","                 all              692         3.06e+03                0                0         8.98e-06                0              0.2926             2.4486              2.7412              2.7412\n","\n","            Epoch          gpu_mem             GIoU              obj              cls            total          targets          ImgSize RmseGradMeanLoss    SSIM_meanLoss\n","   186/299     3.05G             5.37             10.1             4.17             19.6               63               64             0.0269            0.132: 100% 87/87 [02:13<00:00,  1.54s/it]\n","               Class           Images          Targets                P                R          mAP@0.5               F1 RmseGradientLoss         SSIMLoss            DLoss        TotalLoss: 100% 22/22 [00:11<00:00,  1.87it/s]\n","                 all              692         3.06e+03                0                0          8.7e-06                0         0.264             2.2         2.464         2.464\n","\n","            Epoch          gpu_mem             GIoU              obj              cls            total          targets          ImgSize RmseGradMeanLoss    SSIM_meanLoss\n","   187/299     3.05G             5.19             10.4             4.14             19.7               56               64             0.0253             0.127: 100% 87/87 [02:14<00:00,  1.55s/it]\n","               Class           Images          Targets                P                R          mAP@0.5               F1 RmseGradientLoss         SSIMLoss            DLoss        TotalLoss: 100% 22/22 [00:12<00:00,  1.81it/s]\n","                 all              692         3.06e+03                0                0         8.67e-06                0         0.2486             1.32         1.5686         1.5686\n","\n","            Epoch          gpu_mem             GIoU              obj              cls            total          targets          ImgSize RmseGradMeanLoss    SSIM_meanLoss\n","   188/299     3.05G             5.14             10.6             4.01             19.7              139               64             0.0234            0.129:  78% 68/87 [01:47<00:24,  1.26s/it]"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"4PdlBe1o_CBK"},"source":["## Training MidasNet only on 448x448 resolution input image"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8fscwlkbOzUK","outputId":"074b7681-8182-42fd-f91d-655a407877ac"},"source":["!python train.py --data data/customdata/custom.data --batch 8  --cache --cfg cfg/yolov3-custom.cfg --epochs 300 --weights 'weights/best.pt'  --img-size=448 --midasnet_freeze='False' --yolo_freeze='True'"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Namespace(accumulate=4, adam=False, batch_size=8, bbox_lambda=1, bucket='', cache_images=True, cfg='cfg/yolov3-custom.cfg', data='data/customdata/custom.data', depth_lambda=1, device='', epochs=300, evolve=False, img_size=[448], init_train='False', midas_weights='', midasnet_freeze='False', multi_scale=False, name='', nosave=False, notest=False, rect=False, resume=False, single_cls=False, weights='weights/best.pt', yolo_freeze='True', yolo_weights='')\n","Using CUDA device0 _CudaDeviceProperties(name='Tesla V100-SXM2-16GB', total_memory=16130MB)\n","\n","2020-11-18 22:07:20.385192: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n","Run 'tensorboard --logdir=runs' to view tensorboard at http://localhost:6006/\n","cfg - cfg/yolov3-custom.cfg\n","data - data/customdata/custom.data\n","epochs - 300\n","batch_size - 8\n","accumulate - 4\n","yolo weights - \n","midas weights - \n","imgsz_min- 448, imgsz_max- 448, imgsz_test- 448\n","opt.rect - False\n","train_path - data/customdata/train.txt\n","test_path - data/customdata/test.txt\n","init_train - False\n","weights - weights/best.pt\n","midasnet_freeze - False\n","yolo_freeze - True\n","mixed_precision enabled - False\n","Init LR - 0.01\n","Using cache found in /root/.cache/torch/hub/facebookresearch_WSL-Images_master\n","Caching labels (2623 found, 114 missing, 30 empty, 0 duplicate, for 2767 images): 100% 2767/2767 [00:03<00:00, 764.53it/s]\n","Caching images (4.7GB): 100% 2767/2767 [03:44<00:00, 12.32it/s]\n","Caching labels (657 found, 27 missing, 8 empty, 0 duplicate, for 692 images): 100% 692/692 [00:00<00:00, 732.46it/s]\n","Caching images (1.7GB): 100% 692/692 [00:55<00:00, 12.38it/s]\n","Freezing the yolo branch\n","YMP Model Summary\n","----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","            Conv2d-1         [-1, 64, 224, 224]           9,408\n","       BatchNorm2d-2         [-1, 64, 224, 224]             128\n","              ReLU-3         [-1, 64, 224, 224]               0\n","         MaxPool2d-4         [-1, 64, 112, 112]               0\n","            Conv2d-5        [-1, 256, 112, 112]          16,384\n","       BatchNorm2d-6        [-1, 256, 112, 112]             512\n","              ReLU-7        [-1, 256, 112, 112]               0\n","            Conv2d-8        [-1, 256, 112, 112]          18,432\n","       BatchNorm2d-9        [-1, 256, 112, 112]             512\n","             ReLU-10        [-1, 256, 112, 112]               0\n","           Conv2d-11        [-1, 256, 112, 112]          65,536\n","      BatchNorm2d-12        [-1, 256, 112, 112]             512\n","           Conv2d-13        [-1, 256, 112, 112]          16,384\n","      BatchNorm2d-14        [-1, 256, 112, 112]             512\n","             ReLU-15        [-1, 256, 112, 112]               0\n","       Bottleneck-16        [-1, 256, 112, 112]               0\n","           Conv2d-17        [-1, 256, 112, 112]          65,536\n","      BatchNorm2d-18        [-1, 256, 112, 112]             512\n","             ReLU-19        [-1, 256, 112, 112]               0\n","           Conv2d-20        [-1, 256, 112, 112]          18,432\n","      BatchNorm2d-21        [-1, 256, 112, 112]             512\n","             ReLU-22        [-1, 256, 112, 112]               0\n","           Conv2d-23        [-1, 256, 112, 112]          65,536\n","      BatchNorm2d-24        [-1, 256, 112, 112]             512\n","             ReLU-25        [-1, 256, 112, 112]               0\n","       Bottleneck-26        [-1, 256, 112, 112]               0\n","           Conv2d-27        [-1, 256, 112, 112]          65,536\n","      BatchNorm2d-28        [-1, 256, 112, 112]             512\n","             ReLU-29        [-1, 256, 112, 112]               0\n","           Conv2d-30        [-1, 256, 112, 112]          18,432\n","      BatchNorm2d-31        [-1, 256, 112, 112]             512\n","             ReLU-32        [-1, 256, 112, 112]               0\n","           Conv2d-33        [-1, 256, 112, 112]          65,536\n","      BatchNorm2d-34        [-1, 256, 112, 112]             512\n","             ReLU-35        [-1, 256, 112, 112]               0\n","       Bottleneck-36        [-1, 256, 112, 112]               0\n","           Conv2d-37        [-1, 512, 112, 112]         131,072\n","      BatchNorm2d-38        [-1, 512, 112, 112]           1,024\n","             ReLU-39        [-1, 512, 112, 112]               0\n","           Conv2d-40          [-1, 512, 56, 56]          73,728\n","      BatchNorm2d-41          [-1, 512, 56, 56]           1,024\n","             ReLU-42          [-1, 512, 56, 56]               0\n","           Conv2d-43          [-1, 512, 56, 56]         262,144\n","      BatchNorm2d-44          [-1, 512, 56, 56]           1,024\n","           Conv2d-45          [-1, 512, 56, 56]         131,072\n","      BatchNorm2d-46          [-1, 512, 56, 56]           1,024\n","             ReLU-47          [-1, 512, 56, 56]               0\n","       Bottleneck-48          [-1, 512, 56, 56]               0\n","           Conv2d-49          [-1, 512, 56, 56]         262,144\n","      BatchNorm2d-50          [-1, 512, 56, 56]           1,024\n","             ReLU-51          [-1, 512, 56, 56]               0\n","           Conv2d-52          [-1, 512, 56, 56]          73,728\n","      BatchNorm2d-53          [-1, 512, 56, 56]           1,024\n","             ReLU-54          [-1, 512, 56, 56]               0\n","           Conv2d-55          [-1, 512, 56, 56]         262,144\n","      BatchNorm2d-56          [-1, 512, 56, 56]           1,024\n","             ReLU-57          [-1, 512, 56, 56]               0\n","       Bottleneck-58          [-1, 512, 56, 56]               0\n","           Conv2d-59          [-1, 512, 56, 56]         262,144\n","      BatchNorm2d-60          [-1, 512, 56, 56]           1,024\n","             ReLU-61          [-1, 512, 56, 56]               0\n","           Conv2d-62          [-1, 512, 56, 56]          73,728\n","      BatchNorm2d-63          [-1, 512, 56, 56]           1,024\n","             ReLU-64          [-1, 512, 56, 56]               0\n","           Conv2d-65          [-1, 512, 56, 56]         262,144\n","      BatchNorm2d-66          [-1, 512, 56, 56]           1,024\n","             ReLU-67          [-1, 512, 56, 56]               0\n","       Bottleneck-68          [-1, 512, 56, 56]               0\n","           Conv2d-69          [-1, 512, 56, 56]         262,144\n","      BatchNorm2d-70          [-1, 512, 56, 56]           1,024\n","             ReLU-71          [-1, 512, 56, 56]               0\n","           Conv2d-72          [-1, 512, 56, 56]          73,728\n","      BatchNorm2d-73          [-1, 512, 56, 56]           1,024\n","             ReLU-74          [-1, 512, 56, 56]               0\n","           Conv2d-75          [-1, 512, 56, 56]         262,144\n","      BatchNorm2d-76          [-1, 512, 56, 56]           1,024\n","             ReLU-77          [-1, 512, 56, 56]               0\n","       Bottleneck-78          [-1, 512, 56, 56]               0\n","           Conv2d-79         [-1, 1024, 56, 56]         524,288\n","      BatchNorm2d-80         [-1, 1024, 56, 56]           2,048\n","             ReLU-81         [-1, 1024, 56, 56]               0\n","           Conv2d-82         [-1, 1024, 28, 28]         294,912\n","      BatchNorm2d-83         [-1, 1024, 28, 28]           2,048\n","             ReLU-84         [-1, 1024, 28, 28]               0\n","           Conv2d-85         [-1, 1024, 28, 28]       1,048,576\n","      BatchNorm2d-86         [-1, 1024, 28, 28]           2,048\n","           Conv2d-87         [-1, 1024, 28, 28]         524,288\n","      BatchNorm2d-88         [-1, 1024, 28, 28]           2,048\n","             ReLU-89         [-1, 1024, 28, 28]               0\n","       Bottleneck-90         [-1, 1024, 28, 28]               0\n","           Conv2d-91         [-1, 1024, 28, 28]       1,048,576\n","      BatchNorm2d-92         [-1, 1024, 28, 28]           2,048\n","             ReLU-93         [-1, 1024, 28, 28]               0\n","           Conv2d-94         [-1, 1024, 28, 28]         294,912\n","      BatchNorm2d-95         [-1, 1024, 28, 28]           2,048\n","             ReLU-96         [-1, 1024, 28, 28]               0\n","           Conv2d-97         [-1, 1024, 28, 28]       1,048,576\n","      BatchNorm2d-98         [-1, 1024, 28, 28]           2,048\n","             ReLU-99         [-1, 1024, 28, 28]               0\n","      Bottleneck-100         [-1, 1024, 28, 28]               0\n","          Conv2d-101         [-1, 1024, 28, 28]       1,048,576\n","     BatchNorm2d-102         [-1, 1024, 28, 28]           2,048\n","            ReLU-103         [-1, 1024, 28, 28]               0\n","          Conv2d-104         [-1, 1024, 28, 28]         294,912\n","     BatchNorm2d-105         [-1, 1024, 28, 28]           2,048\n","            ReLU-106         [-1, 1024, 28, 28]               0\n","          Conv2d-107         [-1, 1024, 28, 28]       1,048,576\n","     BatchNorm2d-108         [-1, 1024, 28, 28]           2,048\n","            ReLU-109         [-1, 1024, 28, 28]               0\n","      Bottleneck-110         [-1, 1024, 28, 28]               0\n","          Conv2d-111         [-1, 1024, 28, 28]       1,048,576\n","     BatchNorm2d-112         [-1, 1024, 28, 28]           2,048\n","            ReLU-113         [-1, 1024, 28, 28]               0\n","          Conv2d-114         [-1, 1024, 28, 28]         294,912\n","     BatchNorm2d-115         [-1, 1024, 28, 28]           2,048\n","            ReLU-116         [-1, 1024, 28, 28]               0\n","          Conv2d-117         [-1, 1024, 28, 28]       1,048,576\n","     BatchNorm2d-118         [-1, 1024, 28, 28]           2,048\n","            ReLU-119         [-1, 1024, 28, 28]               0\n","      Bottleneck-120         [-1, 1024, 28, 28]               0\n","          Conv2d-121         [-1, 1024, 28, 28]       1,048,576\n","     BatchNorm2d-122         [-1, 1024, 28, 28]           2,048\n","            ReLU-123         [-1, 1024, 28, 28]               0\n","          Conv2d-124         [-1, 1024, 28, 28]         294,912\n","     BatchNorm2d-125         [-1, 1024, 28, 28]           2,048\n","            ReLU-126         [-1, 1024, 28, 28]               0\n","          Conv2d-127         [-1, 1024, 28, 28]       1,048,576\n","     BatchNorm2d-128         [-1, 1024, 28, 28]           2,048\n","            ReLU-129         [-1, 1024, 28, 28]               0\n","      Bottleneck-130         [-1, 1024, 28, 28]               0\n","          Conv2d-131         [-1, 1024, 28, 28]       1,048,576\n","     BatchNorm2d-132         [-1, 1024, 28, 28]           2,048\n","            ReLU-133         [-1, 1024, 28, 28]               0\n","          Conv2d-134         [-1, 1024, 28, 28]         294,912\n","     BatchNorm2d-135         [-1, 1024, 28, 28]           2,048\n","            ReLU-136         [-1, 1024, 28, 28]               0\n","          Conv2d-137         [-1, 1024, 28, 28]       1,048,576\n","     BatchNorm2d-138         [-1, 1024, 28, 28]           2,048\n","            ReLU-139         [-1, 1024, 28, 28]               0\n","      Bottleneck-140         [-1, 1024, 28, 28]               0\n","          Conv2d-141         [-1, 1024, 28, 28]       1,048,576\n","     BatchNorm2d-142         [-1, 1024, 28, 28]           2,048\n","            ReLU-143         [-1, 1024, 28, 28]               0\n","          Conv2d-144         [-1, 1024, 28, 28]         294,912\n","     BatchNorm2d-145         [-1, 1024, 28, 28]           2,048\n","            ReLU-146         [-1, 1024, 28, 28]               0\n","          Conv2d-147         [-1, 1024, 28, 28]       1,048,576\n","     BatchNorm2d-148         [-1, 1024, 28, 28]           2,048\n","            ReLU-149         [-1, 1024, 28, 28]               0\n","      Bottleneck-150         [-1, 1024, 28, 28]               0\n","          Conv2d-151         [-1, 1024, 28, 28]       1,048,576\n","     BatchNorm2d-152         [-1, 1024, 28, 28]           2,048\n","            ReLU-153         [-1, 1024, 28, 28]               0\n","          Conv2d-154         [-1, 1024, 28, 28]         294,912\n","     BatchNorm2d-155         [-1, 1024, 28, 28]           2,048\n","            ReLU-156         [-1, 1024, 28, 28]               0\n","          Conv2d-157         [-1, 1024, 28, 28]       1,048,576\n","     BatchNorm2d-158         [-1, 1024, 28, 28]           2,048\n","            ReLU-159         [-1, 1024, 28, 28]               0\n","      Bottleneck-160         [-1, 1024, 28, 28]               0\n","          Conv2d-161         [-1, 1024, 28, 28]       1,048,576\n","     BatchNorm2d-162         [-1, 1024, 28, 28]           2,048\n","            ReLU-163         [-1, 1024, 28, 28]               0\n","          Conv2d-164         [-1, 1024, 28, 28]         294,912\n","     BatchNorm2d-165         [-1, 1024, 28, 28]           2,048\n","            ReLU-166         [-1, 1024, 28, 28]               0\n","          Conv2d-167         [-1, 1024, 28, 28]       1,048,576\n","     BatchNorm2d-168         [-1, 1024, 28, 28]           2,048\n","            ReLU-169         [-1, 1024, 28, 28]               0\n","      Bottleneck-170         [-1, 1024, 28, 28]               0\n","          Conv2d-171         [-1, 1024, 28, 28]       1,048,576\n","     BatchNorm2d-172         [-1, 1024, 28, 28]           2,048\n","            ReLU-173         [-1, 1024, 28, 28]               0\n","          Conv2d-174         [-1, 1024, 28, 28]         294,912\n","     BatchNorm2d-175         [-1, 1024, 28, 28]           2,048\n","            ReLU-176         [-1, 1024, 28, 28]               0\n","          Conv2d-177         [-1, 1024, 28, 28]       1,048,576\n","     BatchNorm2d-178         [-1, 1024, 28, 28]           2,048\n","            ReLU-179         [-1, 1024, 28, 28]               0\n","      Bottleneck-180         [-1, 1024, 28, 28]               0\n","          Conv2d-181         [-1, 1024, 28, 28]       1,048,576\n","     BatchNorm2d-182         [-1, 1024, 28, 28]           2,048\n","            ReLU-183         [-1, 1024, 28, 28]               0\n","          Conv2d-184         [-1, 1024, 28, 28]         294,912\n","     BatchNorm2d-185         [-1, 1024, 28, 28]           2,048\n","            ReLU-186         [-1, 1024, 28, 28]               0\n","          Conv2d-187         [-1, 1024, 28, 28]       1,048,576\n","     BatchNorm2d-188         [-1, 1024, 28, 28]           2,048\n","            ReLU-189         [-1, 1024, 28, 28]               0\n","      Bottleneck-190         [-1, 1024, 28, 28]               0\n","          Conv2d-191         [-1, 1024, 28, 28]       1,048,576\n","     BatchNorm2d-192         [-1, 1024, 28, 28]           2,048\n","            ReLU-193         [-1, 1024, 28, 28]               0\n","          Conv2d-194         [-1, 1024, 28, 28]         294,912\n","     BatchNorm2d-195         [-1, 1024, 28, 28]           2,048\n","            ReLU-196         [-1, 1024, 28, 28]               0\n","          Conv2d-197         [-1, 1024, 28, 28]       1,048,576\n","     BatchNorm2d-198         [-1, 1024, 28, 28]           2,048\n","            ReLU-199         [-1, 1024, 28, 28]               0\n","      Bottleneck-200         [-1, 1024, 28, 28]               0\n","          Conv2d-201         [-1, 1024, 28, 28]       1,048,576\n","     BatchNorm2d-202         [-1, 1024, 28, 28]           2,048\n","            ReLU-203         [-1, 1024, 28, 28]               0\n","          Conv2d-204         [-1, 1024, 28, 28]         294,912\n","     BatchNorm2d-205         [-1, 1024, 28, 28]           2,048\n","            ReLU-206         [-1, 1024, 28, 28]               0\n","          Conv2d-207         [-1, 1024, 28, 28]       1,048,576\n","     BatchNorm2d-208         [-1, 1024, 28, 28]           2,048\n","            ReLU-209         [-1, 1024, 28, 28]               0\n","      Bottleneck-210         [-1, 1024, 28, 28]               0\n","          Conv2d-211         [-1, 1024, 28, 28]       1,048,576\n","     BatchNorm2d-212         [-1, 1024, 28, 28]           2,048\n","            ReLU-213         [-1, 1024, 28, 28]               0\n","          Conv2d-214         [-1, 1024, 28, 28]         294,912\n","     BatchNorm2d-215         [-1, 1024, 28, 28]           2,048\n","            ReLU-216         [-1, 1024, 28, 28]               0\n","          Conv2d-217         [-1, 1024, 28, 28]       1,048,576\n","     BatchNorm2d-218         [-1, 1024, 28, 28]           2,048\n","            ReLU-219         [-1, 1024, 28, 28]               0\n","      Bottleneck-220         [-1, 1024, 28, 28]               0\n","          Conv2d-221         [-1, 1024, 28, 28]       1,048,576\n","     BatchNorm2d-222         [-1, 1024, 28, 28]           2,048\n","            ReLU-223         [-1, 1024, 28, 28]               0\n","          Conv2d-224         [-1, 1024, 28, 28]         294,912\n","     BatchNorm2d-225         [-1, 1024, 28, 28]           2,048\n","            ReLU-226         [-1, 1024, 28, 28]               0\n","          Conv2d-227         [-1, 1024, 28, 28]       1,048,576\n","     BatchNorm2d-228         [-1, 1024, 28, 28]           2,048\n","            ReLU-229         [-1, 1024, 28, 28]               0\n","      Bottleneck-230         [-1, 1024, 28, 28]               0\n","          Conv2d-231         [-1, 1024, 28, 28]       1,048,576\n","     BatchNorm2d-232         [-1, 1024, 28, 28]           2,048\n","            ReLU-233         [-1, 1024, 28, 28]               0\n","          Conv2d-234         [-1, 1024, 28, 28]         294,912\n","     BatchNorm2d-235         [-1, 1024, 28, 28]           2,048\n","            ReLU-236         [-1, 1024, 28, 28]               0\n","          Conv2d-237         [-1, 1024, 28, 28]       1,048,576\n","     BatchNorm2d-238         [-1, 1024, 28, 28]           2,048\n","            ReLU-239         [-1, 1024, 28, 28]               0\n","      Bottleneck-240         [-1, 1024, 28, 28]               0\n","          Conv2d-241         [-1, 1024, 28, 28]       1,048,576\n","     BatchNorm2d-242         [-1, 1024, 28, 28]           2,048\n","            ReLU-243         [-1, 1024, 28, 28]               0\n","          Conv2d-244         [-1, 1024, 28, 28]         294,912\n","     BatchNorm2d-245         [-1, 1024, 28, 28]           2,048\n","            ReLU-246         [-1, 1024, 28, 28]               0\n","          Conv2d-247         [-1, 1024, 28, 28]       1,048,576\n","     BatchNorm2d-248         [-1, 1024, 28, 28]           2,048\n","            ReLU-249         [-1, 1024, 28, 28]               0\n","      Bottleneck-250         [-1, 1024, 28, 28]               0\n","          Conv2d-251         [-1, 1024, 28, 28]       1,048,576\n","     BatchNorm2d-252         [-1, 1024, 28, 28]           2,048\n","            ReLU-253         [-1, 1024, 28, 28]               0\n","          Conv2d-254         [-1, 1024, 28, 28]         294,912\n","     BatchNorm2d-255         [-1, 1024, 28, 28]           2,048\n","            ReLU-256         [-1, 1024, 28, 28]               0\n","          Conv2d-257         [-1, 1024, 28, 28]       1,048,576\n","     BatchNorm2d-258         [-1, 1024, 28, 28]           2,048\n","            ReLU-259         [-1, 1024, 28, 28]               0\n","      Bottleneck-260         [-1, 1024, 28, 28]               0\n","          Conv2d-261         [-1, 1024, 28, 28]       1,048,576\n","     BatchNorm2d-262         [-1, 1024, 28, 28]           2,048\n","            ReLU-263         [-1, 1024, 28, 28]               0\n","          Conv2d-264         [-1, 1024, 28, 28]         294,912\n","     BatchNorm2d-265         [-1, 1024, 28, 28]           2,048\n","            ReLU-266         [-1, 1024, 28, 28]               0\n","          Conv2d-267         [-1, 1024, 28, 28]       1,048,576\n","     BatchNorm2d-268         [-1, 1024, 28, 28]           2,048\n","            ReLU-269         [-1, 1024, 28, 28]               0\n","      Bottleneck-270         [-1, 1024, 28, 28]               0\n","          Conv2d-271         [-1, 1024, 28, 28]       1,048,576\n","     BatchNorm2d-272         [-1, 1024, 28, 28]           2,048\n","            ReLU-273         [-1, 1024, 28, 28]               0\n","          Conv2d-274         [-1, 1024, 28, 28]         294,912\n","     BatchNorm2d-275         [-1, 1024, 28, 28]           2,048\n","            ReLU-276         [-1, 1024, 28, 28]               0\n","          Conv2d-277         [-1, 1024, 28, 28]       1,048,576\n","     BatchNorm2d-278         [-1, 1024, 28, 28]           2,048\n","            ReLU-279         [-1, 1024, 28, 28]               0\n","      Bottleneck-280         [-1, 1024, 28, 28]               0\n","          Conv2d-281         [-1, 1024, 28, 28]       1,048,576\n","     BatchNorm2d-282         [-1, 1024, 28, 28]           2,048\n","            ReLU-283         [-1, 1024, 28, 28]               0\n","          Conv2d-284         [-1, 1024, 28, 28]         294,912\n","     BatchNorm2d-285         [-1, 1024, 28, 28]           2,048\n","            ReLU-286         [-1, 1024, 28, 28]               0\n","          Conv2d-287         [-1, 1024, 28, 28]       1,048,576\n","     BatchNorm2d-288         [-1, 1024, 28, 28]           2,048\n","            ReLU-289         [-1, 1024, 28, 28]               0\n","      Bottleneck-290         [-1, 1024, 28, 28]               0\n","          Conv2d-291         [-1, 1024, 28, 28]       1,048,576\n","     BatchNorm2d-292         [-1, 1024, 28, 28]           2,048\n","            ReLU-293         [-1, 1024, 28, 28]               0\n","          Conv2d-294         [-1, 1024, 28, 28]         294,912\n","     BatchNorm2d-295         [-1, 1024, 28, 28]           2,048\n","            ReLU-296         [-1, 1024, 28, 28]               0\n","          Conv2d-297         [-1, 1024, 28, 28]       1,048,576\n","     BatchNorm2d-298         [-1, 1024, 28, 28]           2,048\n","            ReLU-299         [-1, 1024, 28, 28]               0\n","      Bottleneck-300         [-1, 1024, 28, 28]               0\n","          Conv2d-301         [-1, 1024, 28, 28]       1,048,576\n","     BatchNorm2d-302         [-1, 1024, 28, 28]           2,048\n","            ReLU-303         [-1, 1024, 28, 28]               0\n","          Conv2d-304         [-1, 1024, 28, 28]         294,912\n","     BatchNorm2d-305         [-1, 1024, 28, 28]           2,048\n","            ReLU-306         [-1, 1024, 28, 28]               0\n","          Conv2d-307         [-1, 1024, 28, 28]       1,048,576\n","     BatchNorm2d-308         [-1, 1024, 28, 28]           2,048\n","            ReLU-309         [-1, 1024, 28, 28]               0\n","      Bottleneck-310         [-1, 1024, 28, 28]               0\n","          Conv2d-311         [-1, 2048, 28, 28]       2,097,152\n","     BatchNorm2d-312         [-1, 2048, 28, 28]           4,096\n","            ReLU-313         [-1, 2048, 28, 28]               0\n","          Conv2d-314         [-1, 2048, 14, 14]       1,179,648\n","     BatchNorm2d-315         [-1, 2048, 14, 14]           4,096\n","            ReLU-316         [-1, 2048, 14, 14]               0\n","          Conv2d-317         [-1, 2048, 14, 14]       4,194,304\n","     BatchNorm2d-318         [-1, 2048, 14, 14]           4,096\n","          Conv2d-319         [-1, 2048, 14, 14]       2,097,152\n","     BatchNorm2d-320         [-1, 2048, 14, 14]           4,096\n","            ReLU-321         [-1, 2048, 14, 14]               0\n","      Bottleneck-322         [-1, 2048, 14, 14]               0\n","          Conv2d-323         [-1, 2048, 14, 14]       4,194,304\n","     BatchNorm2d-324         [-1, 2048, 14, 14]           4,096\n","            ReLU-325         [-1, 2048, 14, 14]               0\n","          Conv2d-326         [-1, 2048, 14, 14]       1,179,648\n","     BatchNorm2d-327         [-1, 2048, 14, 14]           4,096\n","            ReLU-328         [-1, 2048, 14, 14]               0\n","          Conv2d-329         [-1, 2048, 14, 14]       4,194,304\n","     BatchNorm2d-330         [-1, 2048, 14, 14]           4,096\n","            ReLU-331         [-1, 2048, 14, 14]               0\n","      Bottleneck-332         [-1, 2048, 14, 14]               0\n","          Conv2d-333         [-1, 2048, 14, 14]       4,194,304\n","     BatchNorm2d-334         [-1, 2048, 14, 14]           4,096\n","            ReLU-335         [-1, 2048, 14, 14]               0\n","          Conv2d-336         [-1, 2048, 14, 14]       1,179,648\n","     BatchNorm2d-337         [-1, 2048, 14, 14]           4,096\n","            ReLU-338         [-1, 2048, 14, 14]               0\n","          Conv2d-339         [-1, 2048, 14, 14]       4,194,304\n","     BatchNorm2d-340         [-1, 2048, 14, 14]           4,096\n","            ReLU-341         [-1, 2048, 14, 14]               0\n","      Bottleneck-342         [-1, 2048, 14, 14]               0\n","          Conv2d-343        [-1, 256, 112, 112]         589,824\n","          Conv2d-344          [-1, 256, 56, 56]       1,179,648\n","          Conv2d-345          [-1, 256, 28, 28]       2,359,296\n","          Conv2d-346          [-1, 256, 14, 14]       4,718,592\n","            ReLU-347          [-1, 256, 14, 14]               0\n","          Conv2d-348          [-1, 256, 14, 14]         590,080\n","            ReLU-349          [-1, 256, 14, 14]               0\n","          Conv2d-350          [-1, 256, 14, 14]         590,080\n","ResidualConvUnit-351          [-1, 256, 14, 14]               0\n","FeatureFusionBlock-352          [-1, 256, 28, 28]               0\n","            ReLU-353          [-1, 256, 28, 28]               0\n","          Conv2d-354          [-1, 256, 28, 28]         590,080\n","            ReLU-355          [-1, 256, 28, 28]               0\n","          Conv2d-356          [-1, 256, 28, 28]         590,080\n","ResidualConvUnit-357          [-1, 256, 28, 28]               0\n","            ReLU-358          [-1, 256, 28, 28]               0\n","          Conv2d-359          [-1, 256, 28, 28]         590,080\n","            ReLU-360          [-1, 256, 28, 28]               0\n","          Conv2d-361          [-1, 256, 28, 28]         590,080\n","ResidualConvUnit-362          [-1, 256, 28, 28]               0\n","FeatureFusionBlock-363          [-1, 256, 56, 56]               0\n","            ReLU-364          [-1, 256, 56, 56]               0\n","          Conv2d-365          [-1, 256, 56, 56]         590,080\n","            ReLU-366          [-1, 256, 56, 56]               0\n","          Conv2d-367          [-1, 256, 56, 56]         590,080\n","ResidualConvUnit-368          [-1, 256, 56, 56]               0\n","            ReLU-369          [-1, 256, 56, 56]               0\n","          Conv2d-370          [-1, 256, 56, 56]         590,080\n","            ReLU-371          [-1, 256, 56, 56]               0\n","          Conv2d-372          [-1, 256, 56, 56]         590,080\n","ResidualConvUnit-373          [-1, 256, 56, 56]               0\n","FeatureFusionBlock-374        [-1, 256, 112, 112]               0\n","            ReLU-375        [-1, 256, 112, 112]               0\n","          Conv2d-376        [-1, 256, 112, 112]         590,080\n","            ReLU-377        [-1, 256, 112, 112]               0\n","          Conv2d-378        [-1, 256, 112, 112]         590,080\n","ResidualConvUnit-379        [-1, 256, 112, 112]               0\n","            ReLU-380        [-1, 256, 112, 112]               0\n","          Conv2d-381        [-1, 256, 112, 112]         590,080\n","            ReLU-382        [-1, 256, 112, 112]               0\n","          Conv2d-383        [-1, 256, 112, 112]         590,080\n","ResidualConvUnit-384        [-1, 256, 112, 112]               0\n","FeatureFusionBlock-385        [-1, 256, 224, 224]               0\n","          Conv2d-386        [-1, 128, 224, 224]         295,040\n","     Interpolate-387        [-1, 128, 448, 448]               0\n","          Conv2d-388         [-1, 32, 448, 448]          36,896\n","            ReLU-389         [-1, 32, 448, 448]               0\n","          Conv2d-390          [-1, 1, 448, 448]              33\n","            ReLU-391          [-1, 1, 448, 448]               0\n","          Conv2d-392        [-1, 256, 224, 224]           6,912\n","     BatchNorm2d-393        [-1, 256, 224, 224]             512\n","            ReLU-394        [-1, 256, 224, 224]               0\n","          Conv2d-395        [-1, 256, 112, 112]         589,824\n","     BatchNorm2d-396        [-1, 256, 112, 112]             512\n","            ReLU-397        [-1, 256, 112, 112]               0\n","          Conv2d-398          [-1, 256, 56, 56]         589,824\n","     BatchNorm2d-399          [-1, 256, 56, 56]             512\n","            ReLU-400          [-1, 256, 56, 56]               0\n","          Conv2d-401          [-1, 512, 28, 28]       1,179,648\n","     BatchNorm2d-402          [-1, 512, 28, 28]           1,024\n","            ReLU-403          [-1, 512, 28, 28]               0\n","          Conv2d-404         [-1, 1024, 14, 14]       4,718,592\n","     BatchNorm2d-405         [-1, 1024, 14, 14]           2,048\n","            ReLU-406         [-1, 1024, 14, 14]               0\n","          Conv2d-407         [-1, 1024, 14, 14]       2,097,152\n","     BatchNorm2d-408         [-1, 1024, 14, 14]           2,048\n","            ReLU-409         [-1, 1024, 14, 14]               0\n","          Conv2d-410           [-1, 27, 14, 14]          27,675\n","       YOLOLayer-411         [-1, 3, 14, 14, 9]               0\n","     Interpolate-412         [-1, 1024, 28, 28]               0\n","          Conv2d-413          [-1, 256, 28, 28]         262,144\n","     BatchNorm2d-414          [-1, 256, 28, 28]             512\n","            ReLU-415          [-1, 256, 28, 28]               0\n","          Conv2d-416          [-1, 512, 28, 28]         524,288\n","     BatchNorm2d-417          [-1, 512, 28, 28]           1,024\n","            ReLU-418          [-1, 512, 28, 28]               0\n","          Conv2d-419          [-1, 256, 28, 28]         196,608\n","     BatchNorm2d-420          [-1, 256, 28, 28]             512\n","            ReLU-421          [-1, 256, 28, 28]               0\n","          Conv2d-422          [-1, 512, 28, 28]       1,179,648\n","     BatchNorm2d-423          [-1, 512, 28, 28]           1,024\n","            ReLU-424          [-1, 512, 28, 28]               0\n","          Conv2d-425          [-1, 256, 28, 28]         131,072\n","     BatchNorm2d-426          [-1, 256, 28, 28]             512\n","            ReLU-427          [-1, 256, 28, 28]               0\n","          Conv2d-428          [-1, 512, 28, 28]       1,179,648\n","     BatchNorm2d-429          [-1, 512, 28, 28]           1,024\n","            ReLU-430          [-1, 512, 28, 28]               0\n","          Conv2d-431          [-1, 256, 28, 28]         131,072\n","     BatchNorm2d-432          [-1, 256, 28, 28]             512\n","            ReLU-433          [-1, 256, 28, 28]               0\n","          Conv2d-434          [-1, 512, 28, 28]       1,179,648\n","     BatchNorm2d-435          [-1, 512, 28, 28]           1,024\n","            ReLU-436          [-1, 512, 28, 28]               0\n","          Conv2d-437           [-1, 27, 28, 28]          13,851\n","       YOLOLayer-438         [-1, 3, 28, 28, 9]               0\n","          Conv2d-439          [-1, 256, 56, 56]         131,072\n","     BatchNorm2d-440          [-1, 256, 56, 56]             512\n","            ReLU-441          [-1, 256, 56, 56]               0\n","     Interpolate-442          [-1, 512, 56, 56]               0\n","          Conv2d-443          [-1, 128, 56, 56]          65,536\n","     BatchNorm2d-444          [-1, 128, 56, 56]             256\n","            ReLU-445          [-1, 128, 56, 56]               0\n","          Conv2d-446          [-1, 128, 56, 56]          49,152\n","     BatchNorm2d-447          [-1, 128, 56, 56]             256\n","            ReLU-448          [-1, 128, 56, 56]               0\n","          Conv2d-449          [-1, 256, 56, 56]         294,912\n","     BatchNorm2d-450          [-1, 256, 56, 56]             512\n","            ReLU-451          [-1, 256, 56, 56]               0\n","          Conv2d-452          [-1, 128, 56, 56]          32,768\n","     BatchNorm2d-453          [-1, 128, 56, 56]             256\n","            ReLU-454          [-1, 128, 56, 56]               0\n","          Conv2d-455          [-1, 256, 56, 56]         294,912\n","     BatchNorm2d-456          [-1, 256, 56, 56]             512\n","            ReLU-457          [-1, 256, 56, 56]               0\n","          Conv2d-458          [-1, 128, 56, 56]          32,768\n","     BatchNorm2d-459          [-1, 128, 56, 56]             256\n","            ReLU-460          [-1, 128, 56, 56]               0\n","          Conv2d-461          [-1, 256, 56, 56]         294,912\n","     BatchNorm2d-462          [-1, 256, 56, 56]             512\n","            ReLU-463          [-1, 256, 56, 56]               0\n","          Conv2d-464           [-1, 27, 56, 56]           6,939\n","       YOLOLayer-465         [-1, 3, 56, 56, 9]               0\n","================================================================\n","Total params: 119,409,234\n","Trainable params: 104,182,785\n","Non-trainable params: 15,226,449\n","----------------------------------------------------------------\n","Input size (MB): 2.30\n","Forward/backward pass size (MB): 4511.99\n","Params size (MB): 455.51\n","Estimated Total Size (MB): 4969.80\n","----------------------------------------------------------------\n","Image sizes 448 - 448 train, 448 test\n","Using 4 dataloader workers\n","Starting training for 300 epochs...\n","\n","            Epoch          gpu_mem             GIoU              obj              cls            total          targets          ImgSize RmseGradMeanLoss    SSIM_meanLoss\n","  0% 0/346 [00:00<?, ?it/s]/content/drive/My Drive/computer_vision/capstone_project/yolo_v3/utils/utils.py:613: UserWarning: This overload of nonzero is deprecated:\n","\tnonzero()\n","Consider using one of the following signatures instead:\n","\tnonzero(*, bool as_tuple) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:882.)\n","  valid = det.nonzero()\n","/usr/local/lib/python3.6/dist-packages/torch/cuda/memory.py:346: FutureWarning: torch.cuda.memory_cached has been renamed to torch.cuda.memory_reserved\n","  FutureWarning)\n","   188/299     14.6G                7             2.51             4.89             14.4               39              448             0.051                0.22:   100% 346/346 [00:21<05:40,  1.04s/it]               Class           Images          Targets                P                R          mAP@0.5               F1 RmseGradientLoss         SSIMLoss            DLoss        TotalLoss: 100% 87/87 [00:10<00:00,  2.03it/s]\n","                 all              692         3.06e+03                0                0                0                0             2.784             17.4             20.183             20.183\n","\n","            Epoch          gpu_mem             GIoU              obj              cls            total          targets          ImgSize RmseGradMeanLoss    SSIM_meanLoss\n","   189/299     14.6G             7             2.42             3.91             19.2               25.53               448               0.042            0.152: 100% 346/346 [02:16<00:00,  1.57s/it]\n","               Class           Images          Targets                P                R          mAP@0.5               F1 RmseGradientLoss         SSIMLoss            DLoss        TotalLoss: 100% 87/87 [00:12<00:00,  1.81it/s]\n","                 all              692         3.06e+03                0                0                0                2.736                           16.9              19.636              19.636\n","\n","            Epoch          gpu_mem             GIoU              obj              cls            total          targets          ImgSize RmseGradMeanLoss    SSIM_meanLoss\n","   190/299     14.6G             7             2.42             3.91             19.1               25.43               448               0.035            0.148: 100% 346/346 [02:16<00:00,  1.57s/it]\n","               Class           Images          Targets                P                R          mAP@0.5               F1 RmseGradientLoss         SSIMLoss            DLoss        TotalLoss: 100% 87/87 [00:12<00:00,  1.81it/s]\n","                 all              692         3.06e+03                0                0                0                2.733                           16.88              19.613              19.613\n"],"name":"stdout"}]}]}